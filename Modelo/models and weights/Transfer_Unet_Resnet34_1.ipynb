{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9297a132",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e308ad1e",
   "metadata": {},
   "source": [
    "# Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c1c484b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1159, 96, 128, 3)\n",
      "(1159, 96, 128, 3)\n",
      "(1159, 96, 128, 38)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage import transform\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import tensorflow as tf\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "\n",
    "imsize = (256,192)\n",
    "\n",
    "x1_train = []\n",
    "for archivo in range(587):\n",
    "    img = Image.open(os.path.join('dataset_sunrgbd/train_rgb',str(archivo)+'.jpg'))\n",
    "    img = cv2.resize(img_to_array(img), dsize=imsize)\n",
    "    x1_train.append(np.asarray(img))\n",
    "# x1_train = np.array(x1_train)\n",
    "# x1_train = x1_train/255.0\n",
    "# print(x1_train.shape)\n",
    "\n",
    "# x1_test = []\n",
    "for archivo in range(572):\n",
    "    img = Image.open(os.path.join('dataset_sunrgbd/test_rgb',str(archivo)+'.jpg'))\n",
    "    img = cv2.resize(img_to_array(img), dsize=imsize)\n",
    "    x1_train.append(np.asarray(img))\n",
    "x1_train = np.array(x1_train)\n",
    "x1_train = x1_train/255.0\n",
    "print(x1_train.shape)\n",
    "\n",
    "x2_train = []\n",
    "for archivo in range(587):\n",
    "    img = Image.open(os.path.join('dataset_sunrgbd/train_depth',str(archivo)+'.png'))\n",
    "    img = cv2.resize(cv2.cvtColor(img_to_array(img),cv2.COLOR_GRAY2RGB), dsize=imsize)\n",
    "#     img = cv2.cvtColor(img_to_array(img),cv2.COLOR_GRAY2RGB)\n",
    "    x2_train.append(np.asarray(img))\n",
    "# x2_train = np.array(x2_train)\n",
    "# x2_train = x2_train/26000.0\n",
    "# print(x2_train.shape)\n",
    "\n",
    "# x2_test = []\n",
    "for archivo in range(572):\n",
    "    img = Image.open(os.path.join('dataset_sunrgbd/test_depth',str(archivo)+'.png'))\n",
    "    img = cv2.resize(cv2.cvtColor(img_to_array(img),cv2.COLOR_GRAY2RGB), dsize=imsize)\n",
    "#     img = cv2.cvtColor(img_to_array(img),cv2.COLOR_GRAY2RGB)\n",
    "    x2_train.append(np.asarray(img))\n",
    "x2_train = np.array(x2_train)\n",
    "x2_train = x2_train/26000.0\n",
    "print(x2_train.shape)\n",
    "\n",
    "y_train = []\n",
    "for archivo in range(587):\n",
    "    img = np.load(os.path.join('dataset_sunrgbd/train_label',str(archivo)+'.npy'))\n",
    "    img = cv2.resize(img_to_array(img), dsize=imsize)\n",
    "    for i in range(0,img.shape[0]-1):\n",
    "        for j in range(0,img.shape[1]-1):\n",
    "            if img[i,j]%1 != 0:\n",
    "                img[i,j]=38\n",
    "    y_train.append(img)\n",
    "# y_train = np.array(y_train).astype('uint8')\n",
    "# y_train = tf.keras.utils.to_categorical(y_train, dtype='float32')\n",
    "# print(y_train.shape)\n",
    "\n",
    "# y_test = []\n",
    "for archivo in range(572):\n",
    "    img = np.load(os.path.join('dataset_sunrgbd/test_label',str(archivo)+'.npy'))\n",
    "    img = cv2.resize(img_to_array(img), dsize=imsize)\n",
    "    for i in range(0,img.shape[0]-1):\n",
    "        for j in range(0,img.shape[1]-1):\n",
    "            if img[i,j]%1 != 0:\n",
    "                img[i,j]=38\n",
    "    y_train.append(img)\n",
    "y_train = np.array(y_train).astype('uint8')\n",
    "y_train = tf.keras.utils.to_categorical(y_train, dtype='float32')\n",
    "y_train = y_train[:,:,:,:38]\n",
    "print(y_train.shape)\n",
    "\n",
    "del img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e6ba67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = np.array(list(zip(x1_train, x2_train)))\n",
    "del x1_train, x2_train\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x,y_train,test_size=0.3)\n",
    "\n",
    "x1_train, x2_train = x_train[:, 0], x_train[:, 1]\n",
    "x1_val, x2_val = x_val[:, 0], x_val[:, 1]\n",
    "\n",
    "del x_train, x_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711bb80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(list(zip(x1_val, x2_val)))\n",
    "del x1_val, x2_val\n",
    "\n",
    "x_test, x_val, y_test, y_val = train_test_split(x,y_train,test_size=0.3)\n",
    "del x\n",
    "\n",
    "x1_test, x2_test = x_test[:, 0], x_test[:, 1]\n",
    "x1_val, x2_val = x_val[:, 0], x_val[:, 1]\n",
    "\n",
    "del x_train, x_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b65a9c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_color(ax, color, title=\"Color\"):\n",
    "    \"\"\"Displays a color image from the NYU dataset.\"\"\"\n",
    "\n",
    "    ax.axis('off')\n",
    "    ax.set_title(title)\n",
    "    ax.imshow(color)\n",
    "\n",
    "def plot_depth(ax, depth, title=\"Depth\"):\n",
    "    \"\"\"Displays a depth map from the NYU dataset.\"\"\"\n",
    "\n",
    "    ax.axis('off')\n",
    "    ax.set_title(title)\n",
    "    ax.imshow(depth, cmap='Spectral')\n",
    "\n",
    "def plot_label(ax, labels, title=\"Label\"):\n",
    "    \"\"\"Displays a label map from the NYU dataset.\"\"\"\n",
    "\n",
    "    ax.axis('off')\n",
    "    ax.set_title(title)\n",
    "    ax.imshow(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d929fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x720 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(\"Labeled Dataset Sample\", figsize=(24, 10))\n",
    "\n",
    "for number in range(1):\n",
    "    fig = plt.figure(\"Labeled Dataset Sample\", figsize=(24, 10))\n",
    "    ax = fig.add_subplot(1, 3, 1)\n",
    "    plot_color(ax, x1_train[number])\n",
    "\n",
    "    ax = fig.add_subplot(1, 3, 2)\n",
    "    plot_depth(ax, x2_train[number])\n",
    "\n",
    "    ax = fig.add_subplot(1, 3, 3)\n",
    "    plot_label(ax, np.argmax(y_train[number],axis=-1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25458cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n"
     ]
    }
   ],
   "source": [
    "from segmentation_models import get_preprocessing\n",
    "\n",
    "BACKBONE = 'resnet34'\n",
    "preprocess_input = get_preprocessing(BACKBONE)\n",
    "\n",
    "\n",
    "x1_train = preprocess_input(x1_train)\n",
    "x2_train = preprocess_input(x2_train)\n",
    "x1_val = preprocess_input(x1_val)\n",
    "x2_val = preprocess_input(x2_val)\n",
    "# x1_test = preprocess_input(x1_test)\n",
    "# x2_test = preprocess_input(x2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c060103",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rotation_range=15,\n",
    "        shear_range=0.02,\n",
    "        zoom_range=[0.9, 1.25],\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        fill_mode=\"reflect\") #'nearest'\n",
    "val_datagen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d1c1636",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen.fit(x1_train)\n",
    "val_datagen.fit(x1_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "977047ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_datagen.flow([x1_train, x2_train], y_train, batch_size=8)\n",
    "validation = val_datagen.flow([x1_val, x2_val], y_val, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a23ec49",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a6affdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "data (InputLayer)               [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bn_data (BatchNormalization)    (None, None, None, 3 9           data[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, None, None, 3 0           bn_data[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv0 (Conv2D)                  (None, None, None, 6 9408        zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn0 (BatchNormalization)        (None, None, None, 6 256         conv0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu0 (Activation)              (None, None, None, 6 0           bn0[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, None, None, 6 0           relu0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pooling0 (MaxPooling2D)         (None, None, None, 6 0           zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn1 (BatchNormaliz (None, None, None, 6 256         pooling0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu1 (Activation) (None, None, None, 6 0           stage1_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, None, None, 6 0           stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv1 (Conv2D)     (None, None, None, 6 36864       zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn2 (BatchNormaliz (None, None, None, 6 256         stage1_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu2 (Activation) (None, None, None, 6 0           stage1_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, None, None, 6 0           stage1_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv2 (Conv2D)     (None, None, None, 6 36864       zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_sc (Conv2D)        (None, None, None, 6 4096        stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, None, None, 6 0           stage1_unit1_conv2[0][0]         \n",
      "                                                                 stage1_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn1 (BatchNormaliz (None, None, None, 6 256         add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu1 (Activation) (None, None, None, 6 0           stage1_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, None, None, 6 0           stage1_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv1 (Conv2D)     (None, None, None, 6 36864       zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn2 (BatchNormaliz (None, None, None, 6 256         stage1_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu2 (Activation) (None, None, None, 6 0           stage1_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPadding2D (None, None, None, 6 0           stage1_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv2 (Conv2D)     (None, None, None, 6 36864       zero_padding2d_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, None, None, 6 0           stage1_unit2_conv2[0][0]         \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_bn1 (BatchNormaliz (None, None, None, 6 256         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_relu1 (Activation) (None, None, None, 6 0           stage1_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPadding2D (None, None, None, 6 0           stage1_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_conv1 (Conv2D)     (None, None, None, 6 36864       zero_padding2d_6[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_bn2 (BatchNormaliz (None, None, None, 6 256         stage1_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_relu2 (Activation) (None, None, None, 6 0           stage1_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPadding2D (None, None, None, 6 0           stage1_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_conv2 (Conv2D)     (None, None, None, 6 36864       zero_padding2d_7[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, None, None, 6 0           stage1_unit3_conv2[0][0]         \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn1 (BatchNormaliz (None, None, None, 6 256         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu1 (Activation) (None, None, None, 6 0           stage2_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPadding2D (None, None, None, 6 0           stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv1 (Conv2D)     (None, None, None, 1 73728       zero_padding2d_8[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn2 (BatchNormaliz (None, None, None, 1 512         stage2_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu2 (Activation) (None, None, None, 1 0           stage2_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPadding2D (None, None, None, 1 0           stage2_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv2 (Conv2D)     (None, None, None, 1 147456      zero_padding2d_9[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_sc (Conv2D)        (None, None, None, 1 8192        stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, None, None, 1 0           stage2_unit1_conv2[0][0]         \n",
      "                                                                 stage2_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn1 (BatchNormaliz (None, None, None, 1 512         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu1 (Activation) (None, None, None, 1 0           stage2_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPadding2 (None, None, None, 1 0           stage2_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv1 (Conv2D)     (None, None, None, 1 147456      zero_padding2d_10[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn2 (BatchNormaliz (None, None, None, 1 512         stage2_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu2 (Activation) (None, None, None, 1 0           stage2_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPadding2 (None, None, None, 1 0           stage2_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv2 (Conv2D)     (None, None, None, 1 147456      zero_padding2d_11[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, None, None, 1 0           stage2_unit2_conv2[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_bn1 (BatchNormaliz (None, None, None, 1 512         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_relu1 (Activation) (None, None, None, 1 0           stage2_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPadding2 (None, None, None, 1 0           stage2_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_conv1 (Conv2D)     (None, None, None, 1 147456      zero_padding2d_12[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_bn2 (BatchNormaliz (None, None, None, 1 512         stage2_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_relu2 (Activation) (None, None, None, 1 0           stage2_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_13 (ZeroPadding2 (None, None, None, 1 0           stage2_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_conv2 (Conv2D)     (None, None, None, 1 147456      zero_padding2d_13[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, None, None, 1 0           stage2_unit3_conv2[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_bn1 (BatchNormaliz (None, None, None, 1 512         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_relu1 (Activation) (None, None, None, 1 0           stage2_unit4_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_14 (ZeroPadding2 (None, None, None, 1 0           stage2_unit4_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_conv1 (Conv2D)     (None, None, None, 1 147456      zero_padding2d_14[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_bn2 (BatchNormaliz (None, None, None, 1 512         stage2_unit4_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_relu2 (Activation) (None, None, None, 1 0           stage2_unit4_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_15 (ZeroPadding2 (None, None, None, 1 0           stage2_unit4_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_conv2 (Conv2D)     (None, None, None, 1 147456      zero_padding2d_15[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, None, None, 1 0           stage2_unit4_conv2[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn1 (BatchNormaliz (None, None, None, 1 512         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu1 (Activation) (None, None, None, 1 0           stage3_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_16 (ZeroPadding2 (None, None, None, 1 0           stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv1 (Conv2D)     (None, None, None, 2 294912      zero_padding2d_16[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn2 (BatchNormaliz (None, None, None, 2 1024        stage3_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu2 (Activation) (None, None, None, 2 0           stage3_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_17 (ZeroPadding2 (None, None, None, 2 0           stage3_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv2 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_17[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_sc (Conv2D)        (None, None, None, 2 32768       stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, None, None, 2 0           stage3_unit1_conv2[0][0]         \n",
      "                                                                 stage3_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn1 (BatchNormaliz (None, None, None, 2 1024        add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu1 (Activation) (None, None, None, 2 0           stage3_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_18 (ZeroPadding2 (None, None, None, 2 0           stage3_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv1 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_18[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn2 (BatchNormaliz (None, None, None, 2 1024        stage3_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu2 (Activation) (None, None, None, 2 0           stage3_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_19 (ZeroPadding2 (None, None, None, 2 0           stage3_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv2 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_19[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, None, None, 2 0           stage3_unit2_conv2[0][0]         \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_bn1 (BatchNormaliz (None, None, None, 2 1024        add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_relu1 (Activation) (None, None, None, 2 0           stage3_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_20 (ZeroPadding2 (None, None, None, 2 0           stage3_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_conv1 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_20[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_bn2 (BatchNormaliz (None, None, None, 2 1024        stage3_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_relu2 (Activation) (None, None, None, 2 0           stage3_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_21 (ZeroPadding2 (None, None, None, 2 0           stage3_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_conv2 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_21[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, None, None, 2 0           stage3_unit3_conv2[0][0]         \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_bn1 (BatchNormaliz (None, None, None, 2 1024        add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_relu1 (Activation) (None, None, None, 2 0           stage3_unit4_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_22 (ZeroPadding2 (None, None, None, 2 0           stage3_unit4_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_conv1 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_22[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_bn2 (BatchNormaliz (None, None, None, 2 1024        stage3_unit4_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_relu2 (Activation) (None, None, None, 2 0           stage3_unit4_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_23 (ZeroPadding2 (None, None, None, 2 0           stage3_unit4_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_conv2 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_23[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, None, None, 2 0           stage3_unit4_conv2[0][0]         \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_bn1 (BatchNormaliz (None, None, None, 2 1024        add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_relu1 (Activation) (None, None, None, 2 0           stage3_unit5_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_24 (ZeroPadding2 (None, None, None, 2 0           stage3_unit5_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_conv1 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_24[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_bn2 (BatchNormaliz (None, None, None, 2 1024        stage3_unit5_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_relu2 (Activation) (None, None, None, 2 0           stage3_unit5_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_25 (ZeroPadding2 (None, None, None, 2 0           stage3_unit5_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_conv2 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_25[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, None, None, 2 0           stage3_unit5_conv2[0][0]         \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_bn1 (BatchNormaliz (None, None, None, 2 1024        add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_relu1 (Activation) (None, None, None, 2 0           stage3_unit6_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_26 (ZeroPadding2 (None, None, None, 2 0           stage3_unit6_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_conv1 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_26[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_bn2 (BatchNormaliz (None, None, None, 2 1024        stage3_unit6_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_relu2 (Activation) (None, None, None, 2 0           stage3_unit6_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_27 (ZeroPadding2 (None, None, None, 2 0           stage3_unit6_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_conv2 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_27[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, None, None, 2 0           stage3_unit6_conv2[0][0]         \n",
      "                                                                 add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn1 (BatchNormaliz (None, None, None, 2 1024        add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu1 (Activation) (None, None, None, 2 0           stage4_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_28 (ZeroPadding2 (None, None, None, 2 0           stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv1 (Conv2D)     (None, None, None, 5 1179648     zero_padding2d_28[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn2 (BatchNormaliz (None, None, None, 5 2048        stage4_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu2 (Activation) (None, None, None, 5 0           stage4_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_29 (ZeroPadding2 (None, None, None, 5 0           stage4_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv2 (Conv2D)     (None, None, None, 5 2359296     zero_padding2d_29[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_sc (Conv2D)        (None, None, None, 5 131072      stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, None, None, 5 0           stage4_unit1_conv2[0][0]         \n",
      "                                                                 stage4_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn1 (BatchNormaliz (None, None, None, 5 2048        add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu1 (Activation) (None, None, None, 5 0           stage4_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_30 (ZeroPadding2 (None, None, None, 5 0           stage4_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv1 (Conv2D)     (None, None, None, 5 2359296     zero_padding2d_30[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn2 (BatchNormaliz (None, None, None, 5 2048        stage4_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu2 (Activation) (None, None, None, 5 0           stage4_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_31 (ZeroPadding2 (None, None, None, 5 0           stage4_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv2 (Conv2D)     (None, None, None, 5 2359296     zero_padding2d_31[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, None, None, 5 0           stage4_unit2_conv2[0][0]         \n",
      "                                                                 add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_bn1 (BatchNormaliz (None, None, None, 5 2048        add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_relu1 (Activation) (None, None, None, 5 0           stage4_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_32 (ZeroPadding2 (None, None, None, 5 0           stage4_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_conv1 (Conv2D)     (None, None, None, 5 2359296     zero_padding2d_32[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_bn2 (BatchNormaliz (None, None, None, 5 2048        stage4_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_relu2 (Activation) (None, None, None, 5 0           stage4_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_33 (ZeroPadding2 (None, None, None, 5 0           stage4_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_conv2 (Conv2D)     (None, None, None, 5 2359296     zero_padding2d_33[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, None, None, 5 0           stage4_unit3_conv2[0][0]         \n",
      "                                                                 add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bn1 (BatchNormalization)        (None, None, None, 5 2048        add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, None, None, 5 0           bn1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0_upsampling (UpSa (None, None, None, 5 0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0_concat (Concaten (None, None, None, 7 0           decoder_stage0_upsampling[0][0]  \n",
      "                                                                 stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0a_conv (Conv2D)   (None, None, None, 2 1769472     decoder_stage0_concat[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0a_bn (BatchNormal (None, None, None, 2 1024        decoder_stage0a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0a_relu (Activatio (None, None, None, 2 0           decoder_stage0a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0b_conv (Conv2D)   (None, None, None, 2 589824      decoder_stage0a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0b_bn (BatchNormal (None, None, None, 2 1024        decoder_stage0b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0b_relu (Activatio (None, None, None, 2 0           decoder_stage0b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1_upsampling (UpSa (None, None, None, 2 0           decoder_stage0b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1_concat (Concaten (None, None, None, 3 0           decoder_stage1_upsampling[0][0]  \n",
      "                                                                 stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1a_conv (Conv2D)   (None, None, None, 1 442368      decoder_stage1_concat[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1a_bn (BatchNormal (None, None, None, 1 512         decoder_stage1a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1a_relu (Activatio (None, None, None, 1 0           decoder_stage1a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1b_conv (Conv2D)   (None, None, None, 1 147456      decoder_stage1a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1b_bn (BatchNormal (None, None, None, 1 512         decoder_stage1b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1b_relu (Activatio (None, None, None, 1 0           decoder_stage1b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2_upsampling (UpSa (None, None, None, 1 0           decoder_stage1b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2_concat (Concaten (None, None, None, 1 0           decoder_stage2_upsampling[0][0]  \n",
      "                                                                 stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2a_conv (Conv2D)   (None, None, None, 6 110592      decoder_stage2_concat[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2a_bn (BatchNormal (None, None, None, 6 256         decoder_stage2a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2a_relu (Activatio (None, None, None, 6 0           decoder_stage2a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2b_conv (Conv2D)   (None, None, None, 6 36864       decoder_stage2a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2b_bn (BatchNormal (None, None, None, 6 256         decoder_stage2b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2b_relu (Activatio (None, None, None, 6 0           decoder_stage2b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3_upsampling (UpSa (None, None, None, 6 0           decoder_stage2b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3_concat (Concaten (None, None, None, 1 0           decoder_stage3_upsampling[0][0]  \n",
      "                                                                 relu0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3a_conv (Conv2D)   (None, None, None, 3 36864       decoder_stage3_concat[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3a_bn (BatchNormal (None, None, None, 3 128         decoder_stage3a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3a_relu (Activatio (None, None, None, 3 0           decoder_stage3a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3b_conv (Conv2D)   (None, None, None, 3 9216        decoder_stage3a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3b_bn (BatchNormal (None, None, None, 3 128         decoder_stage3b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3b_relu (Activatio (None, None, None, 3 0           decoder_stage3b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4_upsampling (UpSa (None, None, None, 3 0           decoder_stage3b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4a_conv (Conv2D)   (None, None, None, 1 4608        decoder_stage4_upsampling[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4a_bn (BatchNormal (None, None, None, 1 64          decoder_stage4a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4a_relu (Activatio (None, None, None, 1 0           decoder_stage4a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4b_conv (Conv2D)   (None, None, None, 1 2304        decoder_stage4a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4b_bn (BatchNormal (None, None, None, 1 64          decoder_stage4b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4b_relu (Activatio (None, None, None, 1 0           decoder_stage4b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "final_conv (Conv2D)             (None, None, None, 3 4350        decoder_stage4b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Activation)            (None, None, None, 3 0           final_conv[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 24,460,359\n",
      "Trainable params: 3,171,265\n",
      "Non-trainable params: 21,289,094\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from segmentation_models import Unet\n",
    "from segmentation_models.utils import set_trainable\n",
    "import segmentation_models as sm\n",
    "\n",
    "\n",
    "sm.set_framework('tf.keras')\n",
    "sm.framework()\n",
    "\n",
    "pretrained_model_1 = Unet(backbone_name='resnet34', encoder_weights='imagenet', encoder_freeze=True, classes=30, activation='softmax', input_shape=(None, None, 3))\n",
    "pretrained_model_1.summary()\n",
    "for layer in pretrained_model_1.layers:\n",
    "    layer._name += '_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "229a1c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "data (InputLayer)               [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bn_data (BatchNormalization)    (None, None, None, 3 9           data[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_34 (ZeroPadding2 (None, None, None, 3 0           bn_data[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv0 (Conv2D)                  (None, None, None, 6 9408        zero_padding2d_34[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "bn0 (BatchNormalization)        (None, None, None, 6 256         conv0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu0 (Activation)              (None, None, None, 6 0           bn0[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_35 (ZeroPadding2 (None, None, None, 6 0           relu0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pooling0 (MaxPooling2D)         (None, None, None, 6 0           zero_padding2d_35[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn1 (BatchNormaliz (None, None, None, 6 256         pooling0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu1 (Activation) (None, None, None, 6 0           stage1_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_36 (ZeroPadding2 (None, None, None, 6 0           stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv1 (Conv2D)     (None, None, None, 6 36864       zero_padding2d_36[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn2 (BatchNormaliz (None, None, None, 6 256         stage1_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu2 (Activation) (None, None, None, 6 0           stage1_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_37 (ZeroPadding2 (None, None, None, 6 0           stage1_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv2 (Conv2D)     (None, None, None, 6 36864       zero_padding2d_37[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_sc (Conv2D)        (None, None, None, 6 4096        stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, None, None, 6 0           stage1_unit1_conv2[0][0]         \n",
      "                                                                 stage1_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn1 (BatchNormaliz (None, None, None, 6 256         add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu1 (Activation) (None, None, None, 6 0           stage1_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_38 (ZeroPadding2 (None, None, None, 6 0           stage1_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv1 (Conv2D)     (None, None, None, 6 36864       zero_padding2d_38[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn2 (BatchNormaliz (None, None, None, 6 256         stage1_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu2 (Activation) (None, None, None, 6 0           stage1_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_39 (ZeroPadding2 (None, None, None, 6 0           stage1_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv2 (Conv2D)     (None, None, None, 6 36864       zero_padding2d_39[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, None, None, 6 0           stage1_unit2_conv2[0][0]         \n",
      "                                                                 add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_bn1 (BatchNormaliz (None, None, None, 6 256         add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_relu1 (Activation) (None, None, None, 6 0           stage1_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_40 (ZeroPadding2 (None, None, None, 6 0           stage1_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_conv1 (Conv2D)     (None, None, None, 6 36864       zero_padding2d_40[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_bn2 (BatchNormaliz (None, None, None, 6 256         stage1_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_relu2 (Activation) (None, None, None, 6 0           stage1_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_41 (ZeroPadding2 (None, None, None, 6 0           stage1_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_conv2 (Conv2D)     (None, None, None, 6 36864       zero_padding2d_41[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, None, None, 6 0           stage1_unit3_conv2[0][0]         \n",
      "                                                                 add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn1 (BatchNormaliz (None, None, None, 6 256         add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu1 (Activation) (None, None, None, 6 0           stage2_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_42 (ZeroPadding2 (None, None, None, 6 0           stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv1 (Conv2D)     (None, None, None, 1 73728       zero_padding2d_42[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn2 (BatchNormaliz (None, None, None, 1 512         stage2_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu2 (Activation) (None, None, None, 1 0           stage2_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_43 (ZeroPadding2 (None, None, None, 1 0           stage2_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv2 (Conv2D)     (None, None, None, 1 147456      zero_padding2d_43[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_sc (Conv2D)        (None, None, None, 1 8192        stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, None, None, 1 0           stage2_unit1_conv2[0][0]         \n",
      "                                                                 stage2_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn1 (BatchNormaliz (None, None, None, 1 512         add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu1 (Activation) (None, None, None, 1 0           stage2_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_44 (ZeroPadding2 (None, None, None, 1 0           stage2_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv1 (Conv2D)     (None, None, None, 1 147456      zero_padding2d_44[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn2 (BatchNormaliz (None, None, None, 1 512         stage2_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu2 (Activation) (None, None, None, 1 0           stage2_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_45 (ZeroPadding2 (None, None, None, 1 0           stage2_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv2 (Conv2D)     (None, None, None, 1 147456      zero_padding2d_45[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, None, None, 1 0           stage2_unit2_conv2[0][0]         \n",
      "                                                                 add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_bn1 (BatchNormaliz (None, None, None, 1 512         add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_relu1 (Activation) (None, None, None, 1 0           stage2_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_46 (ZeroPadding2 (None, None, None, 1 0           stage2_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_conv1 (Conv2D)     (None, None, None, 1 147456      zero_padding2d_46[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_bn2 (BatchNormaliz (None, None, None, 1 512         stage2_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_relu2 (Activation) (None, None, None, 1 0           stage2_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_47 (ZeroPadding2 (None, None, None, 1 0           stage2_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_conv2 (Conv2D)     (None, None, None, 1 147456      zero_padding2d_47[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, None, None, 1 0           stage2_unit3_conv2[0][0]         \n",
      "                                                                 add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_bn1 (BatchNormaliz (None, None, None, 1 512         add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_relu1 (Activation) (None, None, None, 1 0           stage2_unit4_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_48 (ZeroPadding2 (None, None, None, 1 0           stage2_unit4_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_conv1 (Conv2D)     (None, None, None, 1 147456      zero_padding2d_48[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_bn2 (BatchNormaliz (None, None, None, 1 512         stage2_unit4_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_relu2 (Activation) (None, None, None, 1 0           stage2_unit4_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_49 (ZeroPadding2 (None, None, None, 1 0           stage2_unit4_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_conv2 (Conv2D)     (None, None, None, 1 147456      zero_padding2d_49[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, None, None, 1 0           stage2_unit4_conv2[0][0]         \n",
      "                                                                 add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn1 (BatchNormaliz (None, None, None, 1 512         add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu1 (Activation) (None, None, None, 1 0           stage3_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_50 (ZeroPadding2 (None, None, None, 1 0           stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv1 (Conv2D)     (None, None, None, 2 294912      zero_padding2d_50[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn2 (BatchNormaliz (None, None, None, 2 1024        stage3_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu2 (Activation) (None, None, None, 2 0           stage3_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_51 (ZeroPadding2 (None, None, None, 2 0           stage3_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv2 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_51[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_sc (Conv2D)        (None, None, None, 2 32768       stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, None, None, 2 0           stage3_unit1_conv2[0][0]         \n",
      "                                                                 stage3_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn1 (BatchNormaliz (None, None, None, 2 1024        add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu1 (Activation) (None, None, None, 2 0           stage3_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_52 (ZeroPadding2 (None, None, None, 2 0           stage3_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv1 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_52[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn2 (BatchNormaliz (None, None, None, 2 1024        stage3_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu2 (Activation) (None, None, None, 2 0           stage3_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_53 (ZeroPadding2 (None, None, None, 2 0           stage3_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv2 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_53[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, None, None, 2 0           stage3_unit2_conv2[0][0]         \n",
      "                                                                 add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_bn1 (BatchNormaliz (None, None, None, 2 1024        add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_relu1 (Activation) (None, None, None, 2 0           stage3_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_54 (ZeroPadding2 (None, None, None, 2 0           stage3_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_conv1 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_54[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_bn2 (BatchNormaliz (None, None, None, 2 1024        stage3_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_relu2 (Activation) (None, None, None, 2 0           stage3_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_55 (ZeroPadding2 (None, None, None, 2 0           stage3_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_conv2 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_55[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, None, None, 2 0           stage3_unit3_conv2[0][0]         \n",
      "                                                                 add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_bn1 (BatchNormaliz (None, None, None, 2 1024        add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_relu1 (Activation) (None, None, None, 2 0           stage3_unit4_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_56 (ZeroPadding2 (None, None, None, 2 0           stage3_unit4_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_conv1 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_56[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_bn2 (BatchNormaliz (None, None, None, 2 1024        stage3_unit4_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_relu2 (Activation) (None, None, None, 2 0           stage3_unit4_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_57 (ZeroPadding2 (None, None, None, 2 0           stage3_unit4_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_conv2 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_57[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, None, None, 2 0           stage3_unit4_conv2[0][0]         \n",
      "                                                                 add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_bn1 (BatchNormaliz (None, None, None, 2 1024        add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_relu1 (Activation) (None, None, None, 2 0           stage3_unit5_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_58 (ZeroPadding2 (None, None, None, 2 0           stage3_unit5_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_conv1 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_58[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_bn2 (BatchNormaliz (None, None, None, 2 1024        stage3_unit5_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_relu2 (Activation) (None, None, None, 2 0           stage3_unit5_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_59 (ZeroPadding2 (None, None, None, 2 0           stage3_unit5_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_conv2 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_59[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, None, None, 2 0           stage3_unit5_conv2[0][0]         \n",
      "                                                                 add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_bn1 (BatchNormaliz (None, None, None, 2 1024        add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_relu1 (Activation) (None, None, None, 2 0           stage3_unit6_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_60 (ZeroPadding2 (None, None, None, 2 0           stage3_unit6_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_conv1 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_60[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_bn2 (BatchNormaliz (None, None, None, 2 1024        stage3_unit6_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_relu2 (Activation) (None, None, None, 2 0           stage3_unit6_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_61 (ZeroPadding2 (None, None, None, 2 0           stage3_unit6_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_conv2 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_61[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, None, None, 2 0           stage3_unit6_conv2[0][0]         \n",
      "                                                                 add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn1 (BatchNormaliz (None, None, None, 2 1024        add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu1 (Activation) (None, None, None, 2 0           stage4_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_62 (ZeroPadding2 (None, None, None, 2 0           stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv1 (Conv2D)     (None, None, None, 5 1179648     zero_padding2d_62[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn2 (BatchNormaliz (None, None, None, 5 2048        stage4_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu2 (Activation) (None, None, None, 5 0           stage4_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_63 (ZeroPadding2 (None, None, None, 5 0           stage4_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv2 (Conv2D)     (None, None, None, 5 2359296     zero_padding2d_63[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_sc (Conv2D)        (None, None, None, 5 131072      stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, None, None, 5 0           stage4_unit1_conv2[0][0]         \n",
      "                                                                 stage4_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn1 (BatchNormaliz (None, None, None, 5 2048        add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu1 (Activation) (None, None, None, 5 0           stage4_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_64 (ZeroPadding2 (None, None, None, 5 0           stage4_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv1 (Conv2D)     (None, None, None, 5 2359296     zero_padding2d_64[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn2 (BatchNormaliz (None, None, None, 5 2048        stage4_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu2 (Activation) (None, None, None, 5 0           stage4_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_65 (ZeroPadding2 (None, None, None, 5 0           stage4_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv2 (Conv2D)     (None, None, None, 5 2359296     zero_padding2d_65[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, None, None, 5 0           stage4_unit2_conv2[0][0]         \n",
      "                                                                 add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_bn1 (BatchNormaliz (None, None, None, 5 2048        add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_relu1 (Activation) (None, None, None, 5 0           stage4_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_66 (ZeroPadding2 (None, None, None, 5 0           stage4_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_conv1 (Conv2D)     (None, None, None, 5 2359296     zero_padding2d_66[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_bn2 (BatchNormaliz (None, None, None, 5 2048        stage4_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_relu2 (Activation) (None, None, None, 5 0           stage4_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_67 (ZeroPadding2 (None, None, None, 5 0           stage4_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_conv2 (Conv2D)     (None, None, None, 5 2359296     zero_padding2d_67[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, None, None, 5 0           stage4_unit3_conv2[0][0]         \n",
      "                                                                 add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bn1 (BatchNormalization)        (None, None, None, 5 2048        add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, None, None, 5 0           bn1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0_upsampling (UpSa (None, None, None, 5 0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0_concat (Concaten (None, None, None, 7 0           decoder_stage0_upsampling[0][0]  \n",
      "                                                                 stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0a_conv (Conv2D)   (None, None, None, 2 1769472     decoder_stage0_concat[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0a_bn (BatchNormal (None, None, None, 2 1024        decoder_stage0a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0a_relu (Activatio (None, None, None, 2 0           decoder_stage0a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0b_conv (Conv2D)   (None, None, None, 2 589824      decoder_stage0a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0b_bn (BatchNormal (None, None, None, 2 1024        decoder_stage0b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0b_relu (Activatio (None, None, None, 2 0           decoder_stage0b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1_upsampling (UpSa (None, None, None, 2 0           decoder_stage0b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1_concat (Concaten (None, None, None, 3 0           decoder_stage1_upsampling[0][0]  \n",
      "                                                                 stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1a_conv (Conv2D)   (None, None, None, 1 442368      decoder_stage1_concat[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1a_bn (BatchNormal (None, None, None, 1 512         decoder_stage1a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1a_relu (Activatio (None, None, None, 1 0           decoder_stage1a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1b_conv (Conv2D)   (None, None, None, 1 147456      decoder_stage1a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1b_bn (BatchNormal (None, None, None, 1 512         decoder_stage1b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1b_relu (Activatio (None, None, None, 1 0           decoder_stage1b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2_upsampling (UpSa (None, None, None, 1 0           decoder_stage1b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2_concat (Concaten (None, None, None, 1 0           decoder_stage2_upsampling[0][0]  \n",
      "                                                                 stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2a_conv (Conv2D)   (None, None, None, 6 110592      decoder_stage2_concat[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2a_bn (BatchNormal (None, None, None, 6 256         decoder_stage2a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2a_relu (Activatio (None, None, None, 6 0           decoder_stage2a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2b_conv (Conv2D)   (None, None, None, 6 36864       decoder_stage2a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2b_bn (BatchNormal (None, None, None, 6 256         decoder_stage2b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2b_relu (Activatio (None, None, None, 6 0           decoder_stage2b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3_upsampling (UpSa (None, None, None, 6 0           decoder_stage2b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3_concat (Concaten (None, None, None, 1 0           decoder_stage3_upsampling[0][0]  \n",
      "                                                                 relu0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3a_conv (Conv2D)   (None, None, None, 3 36864       decoder_stage3_concat[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3a_bn (BatchNormal (None, None, None, 3 128         decoder_stage3a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3a_relu (Activatio (None, None, None, 3 0           decoder_stage3a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3b_conv (Conv2D)   (None, None, None, 3 9216        decoder_stage3a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3b_bn (BatchNormal (None, None, None, 3 128         decoder_stage3b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3b_relu (Activatio (None, None, None, 3 0           decoder_stage3b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4_upsampling (UpSa (None, None, None, 3 0           decoder_stage3b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4a_conv (Conv2D)   (None, None, None, 1 4608        decoder_stage4_upsampling[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4a_bn (BatchNormal (None, None, None, 1 64          decoder_stage4a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4a_relu (Activatio (None, None, None, 1 0           decoder_stage4a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4b_conv (Conv2D)   (None, None, None, 1 2304        decoder_stage4a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4b_bn (BatchNormal (None, None, None, 1 64          decoder_stage4b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4b_relu (Activatio (None, None, None, 1 0           decoder_stage4b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "final_conv (Conv2D)             (None, None, None, 3 4350        decoder_stage4b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Activation)            (None, None, None, 3 0           final_conv[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 24,460,359\n",
      "Trainable params: 3,171,265\n",
      "Non-trainable params: 21,289,094\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pretrained_model_2 = Unet(backbone_name='resnet34', encoder_weights='imagenet', encoder_freeze=True, classes=30, activation='softmax', input_shape=(None, None, 3))\n",
    "pretrained_model_2.summary()\n",
    "for layer in pretrained_model_2.layers:\n",
    "    layer._name += '_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f4cd473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_1 layer output shape:  (None, None, None, 256)\n",
      "model_2 layer output shape:  (None, None, None, 256)\n"
     ]
    }
   ],
   "source": [
    "#last layers add_ and add_31 for 34,50 add_32 and add_65 for 101\n",
    "rgb_last = pretrained_model_1.get_layer('add_12_1')\n",
    "depth_last = pretrained_model_2.get_layer('add_28_2')\n",
    "print('model_1 layer output shape: ', rgb_last.output_shape)\n",
    "print('model_2 layer output shape: ', depth_last.output_shape)\n",
    "output_1 = rgb_last.output\n",
    "output_2 = depth_last.output\n",
    "\n",
    "# Middle layers unit6 for 34, 50 and unit23 for 101 relu2 for 34 and relu3 for 50, 101\n",
    "rgb_stage_1 = pretrained_model_1.get_layer('stage1_unit3_relu2_1') \n",
    "depth_stage_1 = pretrained_model_2.get_layer('stage1_unit3_relu2_2')\n",
    "rgb_stage_2 = pretrained_model_1.get_layer('stage2_unit4_relu2_1')\n",
    "depth_stage_2 = pretrained_model_2.get_layer('stage2_unit4_relu2_2')\n",
    "rgb_stage_3 = pretrained_model_1.get_layer('stage3_unit6_relu2_1')\n",
    "depth_stage_3 = pretrained_model_2.get_layer('stage3_unit6_relu2_2')\n",
    "# rgb_stage_4 = pretrained_model_1.get_layer('stage4_unit3_relu2_1')\n",
    "# depth_stage_4 = pretrained_model_2.get_layer('stage4_unit3_relu2_2')\n",
    "\n",
    "rgb_fusion_1 = rgb_stage_1.output\n",
    "depth_fusion_1 = depth_stage_1.output\n",
    "rgb_fusion_2 = rgb_stage_2.output\n",
    "depth_fusion_2 = depth_stage_2.output\n",
    "rgb_fusion_3 = rgb_stage_3.output\n",
    "depth_fusion_3 = depth_stage_3.output\n",
    "# rgb_fusion_4 = rgb_stage_4.output\n",
    "# depth_fusion_4 = depth_stage_4.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47e8e8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgbd_fusion(input_r,input_d,reshape_size,label):\n",
    "    r = tf.keras.layers.GlobalAveragePooling2D()(input_r)\n",
    "    r = tf.keras.layers.Reshape((1,1,reshape_size))(r)\n",
    "    r = tf.keras.layers.Conv2D(32,kernel_size=(1,1),strides=(1,1),activation='relu')(r)\n",
    "    r = tf.keras.layers.Conv2D(reshape_size,kernel_size=(1,1),strides=(1,1),activation='sigmoid')(r)\n",
    "    m_1 = tf.keras.layers.Multiply()([input_r,r])\n",
    "    \n",
    "    d = tf.keras.layers.GlobalAveragePooling2D()(input_d)\n",
    "    d = tf.keras.layers.Reshape((1,1,reshape_size))(d)\n",
    "    d = tf.keras.layers.Conv2D(32,kernel_size=(1,1),strides=(1,1),activation='relu')(d)\n",
    "    d = tf.keras.layers.Conv2D(reshape_size,kernel_size=(1,1),strides=(1,1),activation='sigmoid')(d)\n",
    "    m_2 = tf.keras.layers.Multiply()([input_d,d])\n",
    "    name = 'fusion' + label\n",
    "    last = tf.keras.layers.Add(name=name)([m_1,m_2])\n",
    "    \n",
    "    return last\n",
    "\n",
    "def decode_layer(input_de,input_ad,filters):\n",
    "    x = tf.keras.layers.UpSampling2D(size=(2,2), interpolation=\"nearest\")(input_de)\n",
    "    x = tf.keras.layers.Concatenate()([x,input_ad])\n",
    "    x = tf.keras.layers.Conv2D(filters,kernel_size=(3,3),activation='relu', padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.activations.relu(x)\n",
    "    x = tf.keras.layers.Conv2D(filters,kernel_size=(3,3),activation='relu', padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.activations.relu(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def last_decode_layer(input_de,filters):\n",
    "    x = tf.keras.layers.UpSampling2D(size=(2,2), interpolation=\"nearest\")(input_de)\n",
    "    x = tf.keras.layers.Conv2D(filters,kernel_size=(3,3),activation='relu', padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.activations.relu(x)\n",
    "    x = tf.keras.layers.Conv2D(filters,kernel_size=(3,3),activation='relu', padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.activations.relu(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fbcb7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None, None, 64)\n",
      "(None, None, None, 128)\n",
      "(None, None, None, 256)\n",
      "(None, None, None, 256)\n"
     ]
    }
   ],
   "source": [
    "print(rgb_fusion_1.shape)\n",
    "print(rgb_fusion_2.shape)\n",
    "print(rgb_fusion_3.shape)\n",
    "# print(rgb_fusion_4.shape)\n",
    "print(output_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c95ee02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None, None, 64)\n",
      "(None, None, None, 128)\n",
      "(None, None, None, 256)\n",
      "(None, None, None, 256)\n"
     ]
    }
   ],
   "source": [
    "fusion_1 = rgbd_fusion(rgb_fusion_1,depth_fusion_1,64,'_1')\n",
    "print(fusion_1.shape)\n",
    "fusion_2 = rgbd_fusion(rgb_fusion_2,depth_fusion_2,128,'_2')\n",
    "print(fusion_2.shape)\n",
    "fusion_3 = rgbd_fusion(rgb_fusion_3,depth_fusion_3,256,'_3')\n",
    "print(fusion_3.shape)\n",
    "# fusion_4 = rgbd_fusion(rgb_fusion_4,depth_fusion_4,512,'_4')\n",
    "# print(fusion_4.shape)\n",
    "fusion_last = rgbd_fusion(output_1, output_2,256,'_last') #512 for 34 and 2048 for 101\n",
    "print(fusion_last.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d1d1468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"myModel\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "data_1 (InputLayer)             [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "data_2 (InputLayer)             [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bn_data_1 (BatchNormalization)  (None, None, None, 3 9           data_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bn_data_2 (BatchNormalization)  (None, None, None, 3 9           data_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, None, None, 3 0           bn_data_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_34_2 (ZeroPaddin (None, None, None, 3 0           bn_data_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv0_1 (Conv2D)                (None, None, None, 6 9408        zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv0_2 (Conv2D)                (None, None, None, 6 9408        zero_padding2d_34_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bn0_1 (BatchNormalization)      (None, None, None, 6 256         conv0_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn0_2 (BatchNormalization)      (None, None, None, 6 256         conv0_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "relu0_1 (Activation)            (None, None, None, 6 0           bn0_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu0_2 (Activation)            (None, None, None, 6 0           bn0_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1_1 (ZeroPadding (None, None, None, 6 0           relu0_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_35_2 (ZeroPaddin (None, None, None, 6 0           relu0_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "pooling0_1 (MaxPooling2D)       (None, None, None, 6 0           zero_padding2d_1_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "pooling0_2 (MaxPooling2D)       (None, None, None, 6 0           zero_padding2d_35_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn1_1 (BatchNormal (None, None, None, 6 256         pooling0_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn1_2 (BatchNormal (None, None, None, 6 256         pooling0_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu1_1 (Activatio (None, None, None, 6 0           stage1_unit1_bn1_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu1_2 (Activatio (None, None, None, 6 0           stage1_unit1_bn1_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2_1 (ZeroPadding (None, None, None, 6 0           stage1_unit1_relu1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_36_2 (ZeroPaddin (None, None, None, 6 0           stage1_unit1_relu1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv1_1 (Conv2D)   (None, None, None, 6 36864       zero_padding2d_2_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv1_2 (Conv2D)   (None, None, None, 6 36864       zero_padding2d_36_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn2_1 (BatchNormal (None, None, None, 6 256         stage1_unit1_conv1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn2_2 (BatchNormal (None, None, None, 6 256         stage1_unit1_conv1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu2_1 (Activatio (None, None, None, 6 0           stage1_unit1_bn2_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu2_2 (Activatio (None, None, None, 6 0           stage1_unit1_bn2_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3_1 (ZeroPadding (None, None, None, 6 0           stage1_unit1_relu2_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_37_2 (ZeroPaddin (None, None, None, 6 0           stage1_unit1_relu2_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv2_1 (Conv2D)   (None, None, None, 6 36864       zero_padding2d_3_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_sc_1 (Conv2D)      (None, None, None, 6 4096        stage1_unit1_relu1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv2_2 (Conv2D)   (None, None, None, 6 36864       zero_padding2d_37_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_sc_2 (Conv2D)      (None, None, None, 6 4096        stage1_unit1_relu1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, None, None, 6 0           stage1_unit1_conv2_1[0][0]       \n",
      "                                                                 stage1_unit1_sc_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_16_2 (Add)                  (None, None, None, 6 0           stage1_unit1_conv2_2[0][0]       \n",
      "                                                                 stage1_unit1_sc_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn1_1 (BatchNormal (None, None, None, 6 256         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn1_2 (BatchNormal (None, None, None, 6 256         add_16_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu1_1 (Activatio (None, None, None, 6 0           stage1_unit2_bn1_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu1_2 (Activatio (None, None, None, 6 0           stage1_unit2_bn1_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4_1 (ZeroPadding (None, None, None, 6 0           stage1_unit2_relu1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_38_2 (ZeroPaddin (None, None, None, 6 0           stage1_unit2_relu1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv1_1 (Conv2D)   (None, None, None, 6 36864       zero_padding2d_4_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv1_2 (Conv2D)   (None, None, None, 6 36864       zero_padding2d_38_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn2_1 (BatchNormal (None, None, None, 6 256         stage1_unit2_conv1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn2_2 (BatchNormal (None, None, None, 6 256         stage1_unit2_conv1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu2_1 (Activatio (None, None, None, 6 0           stage1_unit2_bn2_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu2_2 (Activatio (None, None, None, 6 0           stage1_unit2_bn2_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_5_1 (ZeroPadding (None, None, None, 6 0           stage1_unit2_relu2_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_39_2 (ZeroPaddin (None, None, None, 6 0           stage1_unit2_relu2_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv2_1 (Conv2D)   (None, None, None, 6 36864       zero_padding2d_5_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv2_2 (Conv2D)   (None, None, None, 6 36864       zero_padding2d_39_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_1_1 (Add)                   (None, None, None, 6 0           stage1_unit2_conv2_1[0][0]       \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_17_2 (Add)                  (None, None, None, 6 0           stage1_unit2_conv2_2[0][0]       \n",
      "                                                                 add_16_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_bn1_1 (BatchNormal (None, None, None, 6 256         add_1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_bn1_2 (BatchNormal (None, None, None, 6 256         add_17_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_relu1_1 (Activatio (None, None, None, 6 0           stage1_unit3_bn1_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_relu1_2 (Activatio (None, None, None, 6 0           stage1_unit3_bn1_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_6_1 (ZeroPadding (None, None, None, 6 0           stage1_unit3_relu1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_40_2 (ZeroPaddin (None, None, None, 6 0           stage1_unit3_relu1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_conv1_1 (Conv2D)   (None, None, None, 6 36864       zero_padding2d_6_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_conv1_2 (Conv2D)   (None, None, None, 6 36864       zero_padding2d_40_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_bn2_1 (BatchNormal (None, None, None, 6 256         stage1_unit3_conv1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_bn2_2 (BatchNormal (None, None, None, 6 256         stage1_unit3_conv1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_relu2_1 (Activatio (None, None, None, 6 0           stage1_unit3_bn2_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_relu2_2 (Activatio (None, None, None, 6 0           stage1_unit3_bn2_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_7_1 (ZeroPadding (None, None, None, 6 0           stage1_unit3_relu2_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_41_2 (ZeroPaddin (None, None, None, 6 0           stage1_unit3_relu2_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_conv2_1 (Conv2D)   (None, None, None, 6 36864       zero_padding2d_7_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_conv2_2 (Conv2D)   (None, None, None, 6 36864       zero_padding2d_41_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_2_1 (Add)                   (None, None, None, 6 0           stage1_unit3_conv2_1[0][0]       \n",
      "                                                                 add_1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_18_2 (Add)                  (None, None, None, 6 0           stage1_unit3_conv2_2[0][0]       \n",
      "                                                                 add_17_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn1_1 (BatchNormal (None, None, None, 6 256         add_2_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn1_2 (BatchNormal (None, None, None, 6 256         add_18_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu1_1 (Activatio (None, None, None, 6 0           stage2_unit1_bn1_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu1_2 (Activatio (None, None, None, 6 0           stage2_unit1_bn1_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_8_1 (ZeroPadding (None, None, None, 6 0           stage2_unit1_relu1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_42_2 (ZeroPaddin (None, None, None, 6 0           stage2_unit1_relu1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv1_1 (Conv2D)   (None, None, None, 1 73728       zero_padding2d_8_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv1_2 (Conv2D)   (None, None, None, 1 73728       zero_padding2d_42_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn2_1 (BatchNormal (None, None, None, 1 512         stage2_unit1_conv1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn2_2 (BatchNormal (None, None, None, 1 512         stage2_unit1_conv1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu2_1 (Activatio (None, None, None, 1 0           stage2_unit1_bn2_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu2_2 (Activatio (None, None, None, 1 0           stage2_unit1_bn2_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_9_1 (ZeroPadding (None, None, None, 1 0           stage2_unit1_relu2_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_43_2 (ZeroPaddin (None, None, None, 1 0           stage2_unit1_relu2_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv2_1 (Conv2D)   (None, None, None, 1 147456      zero_padding2d_9_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_sc_1 (Conv2D)      (None, None, None, 1 8192        stage2_unit1_relu1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv2_2 (Conv2D)   (None, None, None, 1 147456      zero_padding2d_43_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_sc_2 (Conv2D)      (None, None, None, 1 8192        stage2_unit1_relu1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_3_1 (Add)                   (None, None, None, 1 0           stage2_unit1_conv2_1[0][0]       \n",
      "                                                                 stage2_unit1_sc_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_19_2 (Add)                  (None, None, None, 1 0           stage2_unit1_conv2_2[0][0]       \n",
      "                                                                 stage2_unit1_sc_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn1_1 (BatchNormal (None, None, None, 1 512         add_3_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn1_2 (BatchNormal (None, None, None, 1 512         add_19_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu1_1 (Activatio (None, None, None, 1 0           stage2_unit2_bn1_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu1_2 (Activatio (None, None, None, 1 0           stage2_unit2_bn1_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_10_1 (ZeroPaddin (None, None, None, 1 0           stage2_unit2_relu1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_44_2 (ZeroPaddin (None, None, None, 1 0           stage2_unit2_relu1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv1_1 (Conv2D)   (None, None, None, 1 147456      zero_padding2d_10_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv1_2 (Conv2D)   (None, None, None, 1 147456      zero_padding2d_44_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn2_1 (BatchNormal (None, None, None, 1 512         stage2_unit2_conv1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn2_2 (BatchNormal (None, None, None, 1 512         stage2_unit2_conv1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu2_1 (Activatio (None, None, None, 1 0           stage2_unit2_bn2_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu2_2 (Activatio (None, None, None, 1 0           stage2_unit2_bn2_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_11_1 (ZeroPaddin (None, None, None, 1 0           stage2_unit2_relu2_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_45_2 (ZeroPaddin (None, None, None, 1 0           stage2_unit2_relu2_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv2_1 (Conv2D)   (None, None, None, 1 147456      zero_padding2d_11_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv2_2 (Conv2D)   (None, None, None, 1 147456      zero_padding2d_45_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_4_1 (Add)                   (None, None, None, 1 0           stage2_unit2_conv2_1[0][0]       \n",
      "                                                                 add_3_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_20_2 (Add)                  (None, None, None, 1 0           stage2_unit2_conv2_2[0][0]       \n",
      "                                                                 add_19_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_bn1_1 (BatchNormal (None, None, None, 1 512         add_4_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_bn1_2 (BatchNormal (None, None, None, 1 512         add_20_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_relu1_1 (Activatio (None, None, None, 1 0           stage2_unit3_bn1_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_relu1_2 (Activatio (None, None, None, 1 0           stage2_unit3_bn1_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_12_1 (ZeroPaddin (None, None, None, 1 0           stage2_unit3_relu1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_46_2 (ZeroPaddin (None, None, None, 1 0           stage2_unit3_relu1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_conv1_1 (Conv2D)   (None, None, None, 1 147456      zero_padding2d_12_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_conv1_2 (Conv2D)   (None, None, None, 1 147456      zero_padding2d_46_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_bn2_1 (BatchNormal (None, None, None, 1 512         stage2_unit3_conv1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_bn2_2 (BatchNormal (None, None, None, 1 512         stage2_unit3_conv1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_relu2_1 (Activatio (None, None, None, 1 0           stage2_unit3_bn2_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_relu2_2 (Activatio (None, None, None, 1 0           stage2_unit3_bn2_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_13_1 (ZeroPaddin (None, None, None, 1 0           stage2_unit3_relu2_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_47_2 (ZeroPaddin (None, None, None, 1 0           stage2_unit3_relu2_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_conv2_1 (Conv2D)   (None, None, None, 1 147456      zero_padding2d_13_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_conv2_2 (Conv2D)   (None, None, None, 1 147456      zero_padding2d_47_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_5_1 (Add)                   (None, None, None, 1 0           stage2_unit3_conv2_1[0][0]       \n",
      "                                                                 add_4_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_21_2 (Add)                  (None, None, None, 1 0           stage2_unit3_conv2_2[0][0]       \n",
      "                                                                 add_20_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_bn1_1 (BatchNormal (None, None, None, 1 512         add_5_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_bn1_2 (BatchNormal (None, None, None, 1 512         add_21_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_relu1_1 (Activatio (None, None, None, 1 0           stage2_unit4_bn1_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_relu1_2 (Activatio (None, None, None, 1 0           stage2_unit4_bn1_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_14_1 (ZeroPaddin (None, None, None, 1 0           stage2_unit4_relu1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_48_2 (ZeroPaddin (None, None, None, 1 0           stage2_unit4_relu1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_conv1_1 (Conv2D)   (None, None, None, 1 147456      zero_padding2d_14_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_conv1_2 (Conv2D)   (None, None, None, 1 147456      zero_padding2d_48_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_bn2_1 (BatchNormal (None, None, None, 1 512         stage2_unit4_conv1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_bn2_2 (BatchNormal (None, None, None, 1 512         stage2_unit4_conv1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_relu2_1 (Activatio (None, None, None, 1 0           stage2_unit4_bn2_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_relu2_2 (Activatio (None, None, None, 1 0           stage2_unit4_bn2_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_15_1 (ZeroPaddin (None, None, None, 1 0           stage2_unit4_relu2_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_49_2 (ZeroPaddin (None, None, None, 1 0           stage2_unit4_relu2_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_conv2_1 (Conv2D)   (None, None, None, 1 147456      zero_padding2d_15_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_conv2_2 (Conv2D)   (None, None, None, 1 147456      zero_padding2d_49_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_6_1 (Add)                   (None, None, None, 1 0           stage2_unit4_conv2_1[0][0]       \n",
      "                                                                 add_5_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_22_2 (Add)                  (None, None, None, 1 0           stage2_unit4_conv2_2[0][0]       \n",
      "                                                                 add_21_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn1_1 (BatchNormal (None, None, None, 1 512         add_6_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn1_2 (BatchNormal (None, None, None, 1 512         add_22_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu1_1 (Activatio (None, None, None, 1 0           stage3_unit1_bn1_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu1_2 (Activatio (None, None, None, 1 0           stage3_unit1_bn1_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_16_1 (ZeroPaddin (None, None, None, 1 0           stage3_unit1_relu1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_50_2 (ZeroPaddin (None, None, None, 1 0           stage3_unit1_relu1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv1_1 (Conv2D)   (None, None, None, 2 294912      zero_padding2d_16_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv1_2 (Conv2D)   (None, None, None, 2 294912      zero_padding2d_50_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn2_1 (BatchNormal (None, None, None, 2 1024        stage3_unit1_conv1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn2_2 (BatchNormal (None, None, None, 2 1024        stage3_unit1_conv1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu2_1 (Activatio (None, None, None, 2 0           stage3_unit1_bn2_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu2_2 (Activatio (None, None, None, 2 0           stage3_unit1_bn2_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_17_1 (ZeroPaddin (None, None, None, 2 0           stage3_unit1_relu2_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_51_2 (ZeroPaddin (None, None, None, 2 0           stage3_unit1_relu2_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv2_1 (Conv2D)   (None, None, None, 2 589824      zero_padding2d_17_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_sc_1 (Conv2D)      (None, None, None, 2 32768       stage3_unit1_relu1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv2_2 (Conv2D)   (None, None, None, 2 589824      zero_padding2d_51_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_sc_2 (Conv2D)      (None, None, None, 2 32768       stage3_unit1_relu1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_7_1 (Add)                   (None, None, None, 2 0           stage3_unit1_conv2_1[0][0]       \n",
      "                                                                 stage3_unit1_sc_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_23_2 (Add)                  (None, None, None, 2 0           stage3_unit1_conv2_2[0][0]       \n",
      "                                                                 stage3_unit1_sc_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn1_1 (BatchNormal (None, None, None, 2 1024        add_7_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn1_2 (BatchNormal (None, None, None, 2 1024        add_23_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu1_1 (Activatio (None, None, None, 2 0           stage3_unit2_bn1_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu1_2 (Activatio (None, None, None, 2 0           stage3_unit2_bn1_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_18_1 (ZeroPaddin (None, None, None, 2 0           stage3_unit2_relu1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_52_2 (ZeroPaddin (None, None, None, 2 0           stage3_unit2_relu1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv1_1 (Conv2D)   (None, None, None, 2 589824      zero_padding2d_18_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv1_2 (Conv2D)   (None, None, None, 2 589824      zero_padding2d_52_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn2_1 (BatchNormal (None, None, None, 2 1024        stage3_unit2_conv1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn2_2 (BatchNormal (None, None, None, 2 1024        stage3_unit2_conv1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu2_1 (Activatio (None, None, None, 2 0           stage3_unit2_bn2_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu2_2 (Activatio (None, None, None, 2 0           stage3_unit2_bn2_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_19_1 (ZeroPaddin (None, None, None, 2 0           stage3_unit2_relu2_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_53_2 (ZeroPaddin (None, None, None, 2 0           stage3_unit2_relu2_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv2_1 (Conv2D)   (None, None, None, 2 589824      zero_padding2d_19_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv2_2 (Conv2D)   (None, None, None, 2 589824      zero_padding2d_53_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_8_1 (Add)                   (None, None, None, 2 0           stage3_unit2_conv2_1[0][0]       \n",
      "                                                                 add_7_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_24_2 (Add)                  (None, None, None, 2 0           stage3_unit2_conv2_2[0][0]       \n",
      "                                                                 add_23_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_bn1_1 (BatchNormal (None, None, None, 2 1024        add_8_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_bn1_2 (BatchNormal (None, None, None, 2 1024        add_24_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_relu1_1 (Activatio (None, None, None, 2 0           stage3_unit3_bn1_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_relu1_2 (Activatio (None, None, None, 2 0           stage3_unit3_bn1_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_20_1 (ZeroPaddin (None, None, None, 2 0           stage3_unit3_relu1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_54_2 (ZeroPaddin (None, None, None, 2 0           stage3_unit3_relu1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_conv1_1 (Conv2D)   (None, None, None, 2 589824      zero_padding2d_20_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_conv1_2 (Conv2D)   (None, None, None, 2 589824      zero_padding2d_54_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_bn2_1 (BatchNormal (None, None, None, 2 1024        stage3_unit3_conv1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_bn2_2 (BatchNormal (None, None, None, 2 1024        stage3_unit3_conv1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_relu2_1 (Activatio (None, None, None, 2 0           stage3_unit3_bn2_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_relu2_2 (Activatio (None, None, None, 2 0           stage3_unit3_bn2_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_21_1 (ZeroPaddin (None, None, None, 2 0           stage3_unit3_relu2_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_55_2 (ZeroPaddin (None, None, None, 2 0           stage3_unit3_relu2_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_conv2_1 (Conv2D)   (None, None, None, 2 589824      zero_padding2d_21_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_conv2_2 (Conv2D)   (None, None, None, 2 589824      zero_padding2d_55_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_9_1 (Add)                   (None, None, None, 2 0           stage3_unit3_conv2_1[0][0]       \n",
      "                                                                 add_8_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_25_2 (Add)                  (None, None, None, 2 0           stage3_unit3_conv2_2[0][0]       \n",
      "                                                                 add_24_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_bn1_1 (BatchNormal (None, None, None, 2 1024        add_9_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_bn1_2 (BatchNormal (None, None, None, 2 1024        add_25_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_relu1_1 (Activatio (None, None, None, 2 0           stage3_unit4_bn1_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_relu1_2 (Activatio (None, None, None, 2 0           stage3_unit4_bn1_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_22_1 (ZeroPaddin (None, None, None, 2 0           stage3_unit4_relu1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_56_2 (ZeroPaddin (None, None, None, 2 0           stage3_unit4_relu1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_conv1_1 (Conv2D)   (None, None, None, 2 589824      zero_padding2d_22_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_conv1_2 (Conv2D)   (None, None, None, 2 589824      zero_padding2d_56_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_bn2_1 (BatchNormal (None, None, None, 2 1024        stage3_unit4_conv1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_bn2_2 (BatchNormal (None, None, None, 2 1024        stage3_unit4_conv1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_relu2_1 (Activatio (None, None, None, 2 0           stage3_unit4_bn2_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_relu2_2 (Activatio (None, None, None, 2 0           stage3_unit4_bn2_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_23_1 (ZeroPaddin (None, None, None, 2 0           stage3_unit4_relu2_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_57_2 (ZeroPaddin (None, None, None, 2 0           stage3_unit4_relu2_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_conv2_1 (Conv2D)   (None, None, None, 2 589824      zero_padding2d_23_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_conv2_2 (Conv2D)   (None, None, None, 2 589824      zero_padding2d_57_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_10_1 (Add)                  (None, None, None, 2 0           stage3_unit4_conv2_1[0][0]       \n",
      "                                                                 add_9_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_26_2 (Add)                  (None, None, None, 2 0           stage3_unit4_conv2_2[0][0]       \n",
      "                                                                 add_25_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_bn1_1 (BatchNormal (None, None, None, 2 1024        add_10_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_bn1_2 (BatchNormal (None, None, None, 2 1024        add_26_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_relu1_1 (Activatio (None, None, None, 2 0           stage3_unit5_bn1_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_relu1_2 (Activatio (None, None, None, 2 0           stage3_unit5_bn1_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_24_1 (ZeroPaddin (None, None, None, 2 0           stage3_unit5_relu1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_58_2 (ZeroPaddin (None, None, None, 2 0           stage3_unit5_relu1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_conv1_1 (Conv2D)   (None, None, None, 2 589824      zero_padding2d_24_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_conv1_2 (Conv2D)   (None, None, None, 2 589824      zero_padding2d_58_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_bn2_1 (BatchNormal (None, None, None, 2 1024        stage3_unit5_conv1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_bn2_2 (BatchNormal (None, None, None, 2 1024        stage3_unit5_conv1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_relu2_1 (Activatio (None, None, None, 2 0           stage3_unit5_bn2_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_relu2_2 (Activatio (None, None, None, 2 0           stage3_unit5_bn2_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_25_1 (ZeroPaddin (None, None, None, 2 0           stage3_unit5_relu2_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_59_2 (ZeroPaddin (None, None, None, 2 0           stage3_unit5_relu2_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_conv2_1 (Conv2D)   (None, None, None, 2 589824      zero_padding2d_25_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_conv2_2 (Conv2D)   (None, None, None, 2 589824      zero_padding2d_59_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_11_1 (Add)                  (None, None, None, 2 0           stage3_unit5_conv2_1[0][0]       \n",
      "                                                                 add_10_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_27_2 (Add)                  (None, None, None, 2 0           stage3_unit5_conv2_2[0][0]       \n",
      "                                                                 add_26_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_bn1_1 (BatchNormal (None, None, None, 2 1024        add_11_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_bn1_2 (BatchNormal (None, None, None, 2 1024        add_27_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_relu1_1 (Activatio (None, None, None, 2 0           stage3_unit6_bn1_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_relu1_2 (Activatio (None, None, None, 2 0           stage3_unit6_bn1_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_26_1 (ZeroPaddin (None, None, None, 2 0           stage3_unit6_relu1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_60_2 (ZeroPaddin (None, None, None, 2 0           stage3_unit6_relu1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_conv1_1 (Conv2D)   (None, None, None, 2 589824      zero_padding2d_26_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_conv1_2 (Conv2D)   (None, None, None, 2 589824      zero_padding2d_60_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_bn2_1 (BatchNormal (None, None, None, 2 1024        stage3_unit6_conv1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_bn2_2 (BatchNormal (None, None, None, 2 1024        stage3_unit6_conv1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_relu2_1 (Activatio (None, None, None, 2 0           stage3_unit6_bn2_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_relu2_2 (Activatio (None, None, None, 2 0           stage3_unit6_bn2_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_27_1 (ZeroPaddin (None, None, None, 2 0           stage3_unit6_relu2_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_61_2 (ZeroPaddin (None, None, None, 2 0           stage3_unit6_relu2_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_conv2_1 (Conv2D)   (None, None, None, 2 589824      zero_padding2d_27_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_conv2_2 (Conv2D)   (None, None, None, 2 589824      zero_padding2d_61_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_12_1 (Add)                  (None, None, None, 2 0           stage3_unit6_conv2_1[0][0]       \n",
      "                                                                 add_11_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_28_2 (Add)                  (None, None, None, 2 0           stage3_unit6_conv2_2[0][0]       \n",
      "                                                                 add_27_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_6 (Glo (None, 256)          0           add_12_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_7 (Glo (None, 256)          0           add_28_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_4 (Glo (None, 256)          0           stage3_unit6_relu2_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_5 (Glo (None, 256)          0           stage3_unit6_relu2_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 1, 1, 256)    0           global_average_pooling2d_6[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 1, 1, 256)    0           global_average_pooling2d_7[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 1, 1, 256)    0           global_average_pooling2d_4[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 1, 1, 256)    0           global_average_pooling2d_5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 1, 1, 32)     8224        reshape_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 1, 1, 32)     8224        reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 1, 1, 32)     8224        reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 1, 1, 32)     8224        reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 1, 1, 256)    8448        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 1, 1, 256)    8448        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 1, 1, 256)    8448        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 1, 1, 256)    8448        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, None, None, 2 0           add_12_1[0][0]                   \n",
      "                                                                 conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_7 (Multiply)           (None, None, None, 2 0           add_28_2[0][0]                   \n",
      "                                                                 conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, None, None, 2 0           stage3_unit6_relu2_1[0][0]       \n",
      "                                                                 conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, None, None, 2 0           stage3_unit6_relu2_2[0][0]       \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fusion_last (Add)               (None, None, None, 2 0           multiply_6[0][0]                 \n",
      "                                                                 multiply_7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "fusion_3 (Add)                  (None, None, None, 2 0           multiply_4[0][0]                 \n",
      "                                                                 multiply_5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, None, None, 2 0           fusion_last[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, None, None, 2 0           fusion_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, None, None, 5 0           up_sampling2d_1[0][0]            \n",
      "                                                                 up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, None, None, 2 1179904     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 128)          0           stage2_unit4_relu2_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 128)          0           stage2_unit4_relu2_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, None, None, 2 1024        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 1, 1, 128)    0           global_average_pooling2d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 1, 1, 128)    0           global_average_pooling2d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu (TFOpLambda)         (None, None, None, 2 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 1, 1, 32)     4128        reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 1, 1, 32)     4128        reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, None, None, 2 590080      tf.nn.relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 1, 1, 128)    4224        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 1, 1, 128)    4224        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, None, 2 1024        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, None, None, 1 0           stage2_unit4_relu2_1[0][0]       \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, None, None, 1 0           stage2_unit4_relu2_2[0][0]       \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1 (TFOpLambda)       (None, None, None, 2 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fusion_2 (Add)                  (None, None, None, 1 0           multiply_2[0][0]                 \n",
      "                                                                 multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, None, None, 2 0           tf.nn.relu_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, None, None, 1 0           fusion_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, None, 3 0           up_sampling2d_3[0][0]            \n",
      "                                                                 up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, None, None, 2 884992      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 64)           0           stage1_unit3_relu2_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 64)           0           stage1_unit3_relu2_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, None, 2 1024        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 1, 1, 64)     0           global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 1, 64)     0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_2 (TFOpLambda)       (None, None, None, 2 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 1, 1, 32)     2080        reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 1, 1, 32)     2080        reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, None, None, 2 590080      tf.nn.relu_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 1, 1, 64)     2112        conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 1, 1, 64)     2112        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, None, 2 1024        conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, None, None, 6 0           stage1_unit3_relu2_1[0][0]       \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, None, None, 6 0           stage1_unit3_relu2_2[0][0]       \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_3 (TFOpLambda)       (None, None, None, 2 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fusion_1 (Add)                  (None, None, None, 6 0           multiply[0][0]                   \n",
      "                                                                 multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, None, None, 2 0           tf.nn.relu_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, None, None, 6 0           fusion_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, None, None, 3 0           up_sampling2d_5[0][0]            \n",
      "                                                                 up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, None, None, 1 368768      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, None, None, 1 512         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_4 (TFOpLambda)       (None, None, None, 1 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, None, None, 1 147584      tf.nn.relu_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, None, None, 1 512         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_5 (TFOpLambda)       (None, None, None, 1 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2D)  (None, None, None, 1 0           tf.nn.relu_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, None, None, 6 73792       up_sampling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, None, None, 6 256         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_6 (TFOpLambda)       (None, None, None, 6 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, None, None, 6 36928       tf.nn.relu_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, None, None, 6 256         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_7 (TFOpLambda)       (None, None, None, 6 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "last_layer (Conv2D)             (None, None, None, 3 2470        tf.nn.relu_7[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 20,335,928\n",
      "Trainable params: 3,986,604\n",
      "Non-trainable params: 16,349,324\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# xr = decode_layer(fusion_last,tf.keras.layers.UpSampling2D(size=(2,2), interpolation=\"nearest\")(fusion_4),512)\n",
    "xr = decode_layer(fusion_last,tf.keras.layers.UpSampling2D(size=(2,2), interpolation=\"nearest\")(fusion_3),256)\n",
    "xr = decode_layer(xr,tf.keras.layers.UpSampling2D(size=(2,2), interpolation=\"nearest\")(fusion_2),256)\n",
    "xr = decode_layer(xr,tf.keras.layers.UpSampling2D(size=(2,2), interpolation=\"nearest\")(fusion_1),128)\n",
    "xr = last_decode_layer(xr,64)\n",
    "\n",
    "xr = tf.keras.layers.Conv2D(38, kernel_size=(1, 1), activation='softmax', padding='same', name='last_layer')(xr)\n",
    "\n",
    "model = tf.keras.Model(inputs=[pretrained_model_1.input, pretrained_model_2.input], outputs=xr, name='myModel')\n",
    "# encoder_fusion = tf.keras.Model(inputs=[pretrained_model_1.input, pretrained_model_2.input], outputs=fusion)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff17209f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " layer output shape:  (None, None, None, 38)\n"
     ]
    }
   ],
   "source": [
    "stage_fusion = model.get_layer('last_layer')\n",
    "print(' layer output shape: ', stage_fusion.output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16196da",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5638d4db",
   "metadata": {},
   "source": [
    "## Plot Training accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "419d06c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_acc(history, title=\"Model Accuracy\"):\n",
    "    \"\"\"Imprime una grfica mostrando la accuracy por epoch obtenida en un entrenamiento\"\"\"\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_loss(history, title=\"Model Loss\"):\n",
    "    \"\"\"Imprime una grfica mostrando la prdida por epoch obtenida en un entrenamiento\"\"\"\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'], loc='upper right')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_compare_losses(history1, history2, name1=\"Red 1\",\n",
    "                        name2=\"Red 2\", title=\"Graph title\"):\n",
    "    \"\"\"Compara losses de dos entrenamientos con nombres name1 y name2\"\"\"\n",
    "    plt.plot(history1.history['loss'], color=\"green\")\n",
    "    plt.plot(history1.history['val_loss'], 'r--', color=\"green\")\n",
    "    plt.plot(history2.history['loss'], color=\"blue\")\n",
    "    plt.plot(history2.history['val_loss'], 'r--', color=\"blue\")\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train ' + name1, 'Val ' + name1, \n",
    "                'Train ' + name2, 'Val ' + name2],\n",
    "               loc='upper right')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_compare_accs(history1, history2, name1=\"Red 1\",\n",
    "                      name2=\"Red 2\", title=\"Graph title\"):\n",
    "    \"\"\"Compara accuracies de dos entrenamientos con nombres name1 y name2\"\"\"\n",
    "    plt.plot(history1.history['accuracy'], color=\"green\")\n",
    "    plt.plot(history1.history['val_accuracy'], 'r--', color=\"green\")\n",
    "    plt.plot(history2.history['accuracy'], color=\"blue\")\n",
    "    plt.plot(history2.history['val_accuracy'], 'r--', color=\"blue\")\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train ' + name1, 'Val ' + name1, \n",
    "                'Train ' + name2, 'Val ' + name2], \n",
    "               loc='lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cb0290",
   "metadata": {},
   "source": [
    "## metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e69cf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
    "    return score\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "def bce_logdice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n",
    "\n",
    "def weighted_bce_loss(y_true, y_pred, weight):\n",
    "    epsilon = 1e-7\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    logit_y_pred = K.log(y_pred / (1. - y_pred))\n",
    "    loss = weight * (logit_y_pred * (1. - y_true) + \n",
    "                     K.log(1. + K.exp(-K.abs(logit_y_pred))) + K.maximum(-logit_y_pred, 0.))\n",
    "    return K.sum(loss) / K.sum(weight)\n",
    "\n",
    "def weighted_dice_loss(y_true, y_pred, weight):\n",
    "    smooth = 1.\n",
    "    w, m1, m2 = weight, y_true, y_pred\n",
    "    intersection = (m1 * m2)\n",
    "    score = (2. * K.sum(w * intersection) + smooth) / (K.sum(w * m1) + K.sum(w * m2) + smooth)\n",
    "    loss = 1. - K.sum(score)\n",
    "    return loss\n",
    "\n",
    "def weighted_bce_dice_loss(y_true, y_pred):\n",
    "    y_true = K.cast(y_true, 'float32')\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    # if we want to get same size of output, kernel size must be odd\n",
    "    averaged_mask = K.pool2d(\n",
    "            y_true, pool_size=(50, 50), strides=(1, 1), padding='same', pool_mode='avg')\n",
    "    weight = K.ones_like(averaged_mask)\n",
    "    w0 = K.sum(weight)\n",
    "    weight = 5. * K.exp(-5. * K.abs(averaged_mask - 0.5))\n",
    "    w1 = K.sum(weight)\n",
    "    weight *= (w0 / w1)\n",
    "    loss = weighted_bce_loss(y_true, y_pred, weight) + dice_loss(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "def true_positive_rate(y_true, y_pred):\n",
    "    return K.sum(K.flatten(y_true)*K.flatten(K.round(y_pred)))/K.sum(y_true)\n",
    "#seg_model.compile(optimizer=Adam(1e-4, decay=1e-6), loss=dice_p_bce, metrics=[dice_coef, 'binary_accuracy', true_positive_rate])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7f89d6",
   "metadata": {},
   "source": [
    "## callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d3cab9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "import math\n",
    "weight_path=\"{}_best_weights.hdf5\".format('seg_model_2')\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min', save_weights_only = True)\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.5, \n",
    "                                   patience=, \n",
    "                                   verbose=1, min_delta=0.0001, cooldown=2, min_lr=0.1e-7)\n",
    "\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.00001\n",
    "    if epoch >= 5:\n",
    "        initial_lrate = 0.000005\n",
    "        print('New lr is: ', initial_lrate)\n",
    "    if epoch >= 10:\n",
    "        initial_lrate = 0.0000025\n",
    "        print('New lr is: ', initial_lrate)\n",
    "    if epoch >= 30:\n",
    "        initial_lrate = 0.000001\n",
    "        print('New lr is: ', initial_lrate)\n",
    "    if epoch >= 60:\n",
    "        initial_lrate = 0.000005\n",
    "        print('New lr is: ', initial_lrate)\n",
    "    return initial_lrate\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "\n",
    "early = EarlyStopping(monitor=\"val_loss\",\n",
    "                      patience=10) # probably needs to be more patient, but kaggle time is limited\n",
    "\n",
    "callbacks_list = [checkpoint, early, lrate]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fd22e1",
   "metadata": {},
   "source": [
    "## Model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51ea1ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "116/116 [==============================] - 43s 282ms/step - loss: 3.7577 - dice_coef: 0.0153 - accuracy: 0.0640 - true_positive_rate: 0.0079 - iou_score: 0.0062 - val_loss: 3.5682 - val_dice_coef: 0.0000e+00 - val_accuracy: 0.2196 - val_true_positive_rate: 0.0000e+00 - val_iou_score: 0.0044\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.56823, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 2/1000\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 3.2484 - dice_coef: 0.1002 - accuracy: 0.1920 - true_positive_rate: 0.0540 - iou_score: 0.0127 - val_loss: 3.5667 - val_dice_coef: 0.0000e+00 - val_accuracy: 0.2398 - val_true_positive_rate: 0.0000e+00 - val_iou_score: 0.0045\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.56823 to 3.56673, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 3/1000\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 3.0106 - dice_coef: 0.1635 - accuracy: 0.3073 - true_positive_rate: 0.0917 - iou_score: 0.0171 - val_loss: 3.5631 - val_dice_coef: 0.0000e+00 - val_accuracy: 0.2020 - val_true_positive_rate: 0.0000e+00 - val_iou_score: 0.0044\n",
      "\n",
      "Epoch 00003: val_loss improved from 3.56673 to 3.56311, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 4/1000\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 2.8367 - dice_coef: 0.2027 - accuracy: 0.3686 - true_positive_rate: 0.1165 - iou_score: 0.0200 - val_loss: 3.4848 - val_dice_coef: 0.0281 - val_accuracy: 0.2242 - val_true_positive_rate: 0.0148 - val_iou_score: 0.0068\n",
      "\n",
      "Epoch 00004: val_loss improved from 3.56311 to 3.48477, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 5/1000\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 2.7122 - dice_coef: 0.2352 - accuracy: 0.4063 - true_positive_rate: 0.1383 - iou_score: 0.0224 - val_loss: 3.3061 - val_dice_coef: 0.0964 - val_accuracy: 0.2673 - val_true_positive_rate: 0.0547 - val_iou_score: 0.0102\n",
      "\n",
      "Epoch 00005: val_loss improved from 3.48477 to 3.30607, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 6/1000\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 2.6355 - dice_coef: 0.2520 - accuracy: 0.4260 - true_positive_rate: 0.1502 - iou_score: 0.0237 - val_loss: 3.1671 - val_dice_coef: 0.1105 - val_accuracy: 0.2875 - val_true_positive_rate: 0.0626 - val_iou_score: 0.0114\n",
      "\n",
      "Epoch 00006: val_loss improved from 3.30607 to 3.16711, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 7/1000\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 2.5936 - dice_coef: 0.2647 - accuracy: 0.4368 - true_positive_rate: 0.1592 - iou_score: 0.0246 - val_loss: 2.9584 - val_dice_coef: 0.1378 - val_accuracy: 0.3413 - val_true_positive_rate: 0.0782 - val_iou_score: 0.0140\n",
      "\n",
      "Epoch 00007: val_loss improved from 3.16711 to 2.95837, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 8/1000\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 2.5513 - dice_coef: 0.2705 - accuracy: 0.4441 - true_positive_rate: 0.1635 - iou_score: 0.0253 - val_loss: 2.7247 - val_dice_coef: 0.1994 - val_accuracy: 0.4018 - val_true_positive_rate: 0.1167 - val_iou_score: 0.0185\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.95837 to 2.72473, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 9/1000\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 2.5054 - dice_coef: 0.2805 - accuracy: 0.4533 - true_positive_rate: 0.1707 - iou_score: 0.0261 - val_loss: 2.5047 - val_dice_coef: 0.2742 - val_accuracy: 0.4542 - val_true_positive_rate: 0.1675 - val_iou_score: 0.0240\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.72473 to 2.50474, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 10/1000\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 2.4619 - dice_coef: 0.2911 - accuracy: 0.4612 - true_positive_rate: 0.1785 - iou_score: 0.0269 - val_loss: 2.3829 - val_dice_coef: 0.3273 - val_accuracy: 0.4822 - val_true_positive_rate: 0.2082 - val_iou_score: 0.0284\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.50474 to 2.38294, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 11/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 2.4361 - dice_coef: 0.2984 - accuracy: 0.4664 - true_positive_rate: 0.1841 - iou_score: 0.0274 - val_loss: 2.3425 - val_dice_coef: 0.3467 - val_accuracy: 0.4917 - val_true_positive_rate: 0.2224 - val_iou_score: 0.0301\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.38294 to 2.34248, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 12/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 2.4224 - dice_coef: 0.3003 - accuracy: 0.4694 - true_positive_rate: 0.1857 - iou_score: 0.0277 - val_loss: 2.3213 - val_dice_coef: 0.3638 - val_accuracy: 0.4958 - val_true_positive_rate: 0.2377 - val_iou_score: 0.0314\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.34248 to 2.32133, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 13/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 2.3924 - dice_coef: 0.3075 - accuracy: 0.4742 - true_positive_rate: 0.1907 - iou_score: 0.0283 - val_loss: 2.2986 - val_dice_coef: 0.3675 - val_accuracy: 0.5000 - val_true_positive_rate: 0.2411 - val_iou_score: 0.0318\n",
      "\n",
      "Epoch 00013: val_loss improved from 2.32133 to 2.29863, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 14/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 2.3821 - dice_coef: 0.3090 - accuracy: 0.4758 - true_positive_rate: 0.1921 - iou_score: 0.0284 - val_loss: 2.2848 - val_dice_coef: 0.3736 - val_accuracy: 0.5026 - val_true_positive_rate: 0.2466 - val_iou_score: 0.0326\n",
      "\n",
      "Epoch 00014: val_loss improved from 2.29863 to 2.28480, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 15/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "116/116 [==============================] - 28s 244ms/step - loss: 2.3690 - dice_coef: 0.3119 - accuracy: 0.4785 - true_positive_rate: 0.1946 - iou_score: 0.0287 - val_loss: 2.2787 - val_dice_coef: 0.3798 - val_accuracy: 0.5044 - val_true_positive_rate: 0.2521 - val_iou_score: 0.0327\n",
      "\n",
      "Epoch 00015: val_loss improved from 2.28480 to 2.27872, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 16/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "116/116 [==============================] - 29s 246ms/step - loss: 2.3572 - dice_coef: 0.3152 - accuracy: 0.4774 - true_positive_rate: 0.1970 - iou_score: 0.0289 - val_loss: 2.2621 - val_dice_coef: 0.3795 - val_accuracy: 0.5070 - val_true_positive_rate: 0.2515 - val_iou_score: 0.0330\n",
      "\n",
      "Epoch 00016: val_loss improved from 2.27872 to 2.26215, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 17/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 2.3296 - dice_coef: 0.3210 - accuracy: 0.4830 - true_positive_rate: 0.2013 - iou_score: 0.0297 - val_loss: 2.2409 - val_dice_coef: 0.3804 - val_accuracy: 0.5095 - val_true_positive_rate: 0.2514 - val_iou_score: 0.0334\n",
      "\n",
      "Epoch 00017: val_loss improved from 2.26215 to 2.24088, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 18/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "116/116 [==============================] - 28s 246ms/step - loss: 2.3117 - dice_coef: 0.3245 - accuracy: 0.4858 - true_positive_rate: 0.2041 - iou_score: 0.0298 - val_loss: 2.2263 - val_dice_coef: 0.3832 - val_accuracy: 0.5123 - val_true_positive_rate: 0.2542 - val_iou_score: 0.0333\n",
      "\n",
      "Epoch 00018: val_loss improved from 2.24088 to 2.22626, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 19/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 2.3071 - dice_coef: 0.3258 - accuracy: 0.4886 - true_positive_rate: 0.2054 - iou_score: 0.0298 - val_loss: 2.2125 - val_dice_coef: 0.3850 - val_accuracy: 0.5138 - val_true_positive_rate: 0.2561 - val_iou_score: 0.0336\n",
      "\n",
      "Epoch 00019: val_loss improved from 2.22626 to 2.21248, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 20/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 2.2811 - dice_coef: 0.3329 - accuracy: 0.4906 - true_positive_rate: 0.2108 - iou_score: 0.0305 - val_loss: 2.1993 - val_dice_coef: 0.3939 - val_accuracy: 0.5155 - val_true_positive_rate: 0.2638 - val_iou_score: 0.0343\n",
      "\n",
      "Epoch 00020: val_loss improved from 2.21248 to 2.19931, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 21/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 2.2784 - dice_coef: 0.3360 - accuracy: 0.4915 - true_positive_rate: 0.2134 - iou_score: 0.0306 - val_loss: 2.1900 - val_dice_coef: 0.3958 - val_accuracy: 0.5171 - val_true_positive_rate: 0.2649 - val_iou_score: 0.0343\n",
      "\n",
      "Epoch 00021: val_loss improved from 2.19931 to 2.19001, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 22/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 2.2655 - dice_coef: 0.3376 - accuracy: 0.4927 - true_positive_rate: 0.2145 - iou_score: 0.0308 - val_loss: 2.1790 - val_dice_coef: 0.3940 - val_accuracy: 0.5197 - val_true_positive_rate: 0.2640 - val_iou_score: 0.0344\n",
      "\n",
      "Epoch 00022: val_loss improved from 2.19001 to 2.17895, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 23/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 2.2495 - dice_coef: 0.3404 - accuracy: 0.4951 - true_positive_rate: 0.2170 - iou_score: 0.0311 - val_loss: 2.1648 - val_dice_coef: 0.4015 - val_accuracy: 0.5208 - val_true_positive_rate: 0.2712 - val_iou_score: 0.0351\n",
      "\n",
      "Epoch 00023: val_loss improved from 2.17895 to 2.16485, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 24/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 2.2283 - dice_coef: 0.3457 - accuracy: 0.4972 - true_positive_rate: 0.2212 - iou_score: 0.0315 - val_loss: 2.1487 - val_dice_coef: 0.4023 - val_accuracy: 0.5230 - val_true_positive_rate: 0.2726 - val_iou_score: 0.0350\n",
      "\n",
      "Epoch 00024: val_loss improved from 2.16485 to 2.14870, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 25/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 2.2144 - dice_coef: 0.3499 - accuracy: 0.5001 - true_positive_rate: 0.2246 - iou_score: 0.0317 - val_loss: 2.1435 - val_dice_coef: 0.4075 - val_accuracy: 0.5247 - val_true_positive_rate: 0.2758 - val_iou_score: 0.0358\n",
      "\n",
      "Epoch 00025: val_loss improved from 2.14870 to 2.14348, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 26/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 2.1999 - dice_coef: 0.3525 - accuracy: 0.5023 - true_positive_rate: 0.2266 - iou_score: 0.0321 - val_loss: 2.1334 - val_dice_coef: 0.4053 - val_accuracy: 0.5267 - val_true_positive_rate: 0.2736 - val_iou_score: 0.0358\n",
      "\n",
      "Epoch 00026: val_loss improved from 2.14348 to 2.13335, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 27/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 2.1979 - dice_coef: 0.3545 - accuracy: 0.5020 - true_positive_rate: 0.2287 - iou_score: 0.0322 - val_loss: 2.1166 - val_dice_coef: 0.4083 - val_accuracy: 0.5288 - val_true_positive_rate: 0.2768 - val_iou_score: 0.0359\n",
      "\n",
      "Epoch 00027: val_loss improved from 2.13335 to 2.11664, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 28/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 2.1807 - dice_coef: 0.3586 - accuracy: 0.5042 - true_positive_rate: 0.2318 - iou_score: 0.0326 - val_loss: 2.1102 - val_dice_coef: 0.4138 - val_accuracy: 0.5288 - val_true_positive_rate: 0.2823 - val_iou_score: 0.0359\n",
      "\n",
      "Epoch 00028: val_loss improved from 2.11664 to 2.11017, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 29/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 2.1673 - dice_coef: 0.3610 - accuracy: 0.5076 - true_positive_rate: 0.2339 - iou_score: 0.0328 - val_loss: 2.1023 - val_dice_coef: 0.4151 - val_accuracy: 0.5301 - val_true_positive_rate: 0.2831 - val_iou_score: 0.0359\n",
      "\n",
      "Epoch 00029: val_loss improved from 2.11017 to 2.10235, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 30/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 2.1647 - dice_coef: 0.3627 - accuracy: 0.5067 - true_positive_rate: 0.2357 - iou_score: 0.0330 - val_loss: 2.0925 - val_dice_coef: 0.4184 - val_accuracy: 0.5320 - val_true_positive_rate: 0.2859 - val_iou_score: 0.0366\n",
      "\n",
      "Epoch 00030: val_loss improved from 2.10235 to 2.09249, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 31/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 2.1481 - dice_coef: 0.3667 - accuracy: 0.5093 - true_positive_rate: 0.2388 - iou_score: 0.0332 - val_loss: 2.0841 - val_dice_coef: 0.4161 - val_accuracy: 0.5324 - val_true_positive_rate: 0.2841 - val_iou_score: 0.0367\n",
      "\n",
      "Epoch 00031: val_loss improved from 2.09249 to 2.08409, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 32/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 2.1482 - dice_coef: 0.3665 - accuracy: 0.5098 - true_positive_rate: 0.2389 - iou_score: 0.0334 - val_loss: 2.0843 - val_dice_coef: 0.4184 - val_accuracy: 0.5320 - val_true_positive_rate: 0.2868 - val_iou_score: 0.0360\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 2.08409\n",
      "Epoch 33/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 2.1402 - dice_coef: 0.3701 - accuracy: 0.5097 - true_positive_rate: 0.2417 - iou_score: 0.0336 - val_loss: 2.0770 - val_dice_coef: 0.4161 - val_accuracy: 0.5332 - val_true_positive_rate: 0.2853 - val_iou_score: 0.0364\n",
      "\n",
      "Epoch 00033: val_loss improved from 2.08409 to 2.07697, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 34/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 2.1366 - dice_coef: 0.3685 - accuracy: 0.5103 - true_positive_rate: 0.2405 - iou_score: 0.0335 - val_loss: 2.0728 - val_dice_coef: 0.4188 - val_accuracy: 0.5336 - val_true_positive_rate: 0.2866 - val_iou_score: 0.0367\n",
      "\n",
      "Epoch 00034: val_loss improved from 2.07697 to 2.07285, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 35/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 2.1215 - dice_coef: 0.3719 - accuracy: 0.5135 - true_positive_rate: 0.2428 - iou_score: 0.0339 - val_loss: 2.0680 - val_dice_coef: 0.4209 - val_accuracy: 0.5345 - val_true_positive_rate: 0.2890 - val_iou_score: 0.0368\n",
      "\n",
      "Epoch 00035: val_loss improved from 2.07285 to 2.06804, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 36/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 2.1183 - dice_coef: 0.3746 - accuracy: 0.5124 - true_positive_rate: 0.2455 - iou_score: 0.0339 - val_loss: 2.0654 - val_dice_coef: 0.4227 - val_accuracy: 0.5352 - val_true_positive_rate: 0.2908 - val_iou_score: 0.0371\n",
      "\n",
      "Epoch 00036: val_loss improved from 2.06804 to 2.06540, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 37/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 2.1202 - dice_coef: 0.3732 - accuracy: 0.5106 - true_positive_rate: 0.2441 - iou_score: 0.0338 - val_loss: 2.0611 - val_dice_coef: 0.4221 - val_accuracy: 0.5360 - val_true_positive_rate: 0.2902 - val_iou_score: 0.0372\n",
      "\n",
      "Epoch 00037: val_loss improved from 2.06540 to 2.06106, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 38/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 2.1175 - dice_coef: 0.3749 - accuracy: 0.5112 - true_positive_rate: 0.2459 - iou_score: 0.0339 - val_loss: 2.0564 - val_dice_coef: 0.4238 - val_accuracy: 0.5361 - val_true_positive_rate: 0.2918 - val_iou_score: 0.0371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00038: val_loss improved from 2.06106 to 2.05639, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 39/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 2.1142 - dice_coef: 0.3743 - accuracy: 0.5143 - true_positive_rate: 0.2457 - iou_score: 0.0341 - val_loss: 2.0576 - val_dice_coef: 0.4218 - val_accuracy: 0.5362 - val_true_positive_rate: 0.2896 - val_iou_score: 0.0367\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 2.05639\n",
      "Epoch 40/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "116/116 [==============================] - 28s 246ms/step - loss: 2.1128 - dice_coef: 0.3762 - accuracy: 0.5139 - true_positive_rate: 0.2473 - iou_score: 0.0340 - val_loss: 2.0523 - val_dice_coef: 0.4223 - val_accuracy: 0.5366 - val_true_positive_rate: 0.2902 - val_iou_score: 0.0368\n",
      "\n",
      "Epoch 00040: val_loss improved from 2.05639 to 2.05229, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 41/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 2.0966 - dice_coef: 0.3780 - accuracy: 0.5161 - true_positive_rate: 0.2485 - iou_score: 0.0343 - val_loss: 2.0416 - val_dice_coef: 0.4244 - val_accuracy: 0.5385 - val_true_positive_rate: 0.2927 - val_iou_score: 0.0372\n",
      "\n",
      "Epoch 00041: val_loss improved from 2.05229 to 2.04165, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 42/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 2.0987 - dice_coef: 0.3802 - accuracy: 0.5151 - true_positive_rate: 0.2502 - iou_score: 0.0344 - val_loss: 2.0406 - val_dice_coef: 0.4271 - val_accuracy: 0.5384 - val_true_positive_rate: 0.2947 - val_iou_score: 0.0373\n",
      "\n",
      "Epoch 00042: val_loss improved from 2.04165 to 2.04060, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 43/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 2.0863 - dice_coef: 0.3821 - accuracy: 0.5175 - true_positive_rate: 0.2517 - iou_score: 0.0345 - val_loss: 2.0389 - val_dice_coef: 0.4269 - val_accuracy: 0.5385 - val_true_positive_rate: 0.2944 - val_iou_score: 0.0373\n",
      "\n",
      "Epoch 00043: val_loss improved from 2.04060 to 2.03887, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 44/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 2.0826 - dice_coef: 0.3853 - accuracy: 0.5166 - true_positive_rate: 0.2544 - iou_score: 0.0347 - val_loss: 2.0357 - val_dice_coef: 0.4288 - val_accuracy: 0.5391 - val_true_positive_rate: 0.2966 - val_iou_score: 0.0375\n",
      "\n",
      "Epoch 00044: val_loss improved from 2.03887 to 2.03567, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 45/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 2.0840 - dice_coef: 0.3842 - accuracy: 0.5166 - true_positive_rate: 0.2538 - iou_score: 0.0346 - val_loss: 2.0308 - val_dice_coef: 0.4285 - val_accuracy: 0.5392 - val_true_positive_rate: 0.2974 - val_iou_score: 0.0370\n",
      "\n",
      "Epoch 00045: val_loss improved from 2.03567 to 2.03078, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 46/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 2.0968 - dice_coef: 0.3787 - accuracy: 0.5136 - true_positive_rate: 0.2498 - iou_score: 0.0342 - val_loss: 2.0287 - val_dice_coef: 0.4290 - val_accuracy: 0.5400 - val_true_positive_rate: 0.2973 - val_iou_score: 0.0376\n",
      "\n",
      "Epoch 00046: val_loss improved from 2.03078 to 2.02872, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 47/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 2.0739 - dice_coef: 0.3809 - accuracy: 0.5175 - true_positive_rate: 0.2511 - iou_score: 0.0347 - val_loss: 2.0271 - val_dice_coef: 0.4294 - val_accuracy: 0.5404 - val_true_positive_rate: 0.2985 - val_iou_score: 0.0375\n",
      "\n",
      "Epoch 00047: val_loss improved from 2.02872 to 2.02715, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 48/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 2.0649 - dice_coef: 0.3873 - accuracy: 0.5193 - true_positive_rate: 0.2562 - iou_score: 0.0351 - val_loss: 2.0201 - val_dice_coef: 0.4311 - val_accuracy: 0.5413 - val_true_positive_rate: 0.2980 - val_iou_score: 0.0376\n",
      "\n",
      "Epoch 00048: val_loss improved from 2.02715 to 2.02007, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 49/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "116/116 [==============================] - 29s 246ms/step - loss: 2.0619 - dice_coef: 0.3875 - accuracy: 0.5207 - true_positive_rate: 0.2567 - iou_score: 0.0352 - val_loss: 2.0198 - val_dice_coef: 0.4309 - val_accuracy: 0.5412 - val_true_positive_rate: 0.2983 - val_iou_score: 0.0375\n",
      "\n",
      "Epoch 00049: val_loss improved from 2.02007 to 2.01982, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 50/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 2.0751 - dice_coef: 0.3844 - accuracy: 0.5186 - true_positive_rate: 0.2545 - iou_score: 0.0346 - val_loss: 2.0135 - val_dice_coef: 0.4320 - val_accuracy: 0.5421 - val_true_positive_rate: 0.3003 - val_iou_score: 0.0376\n",
      "\n",
      "Epoch 00050: val_loss improved from 2.01982 to 2.01346, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 51/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 2.0559 - dice_coef: 0.3889 - accuracy: 0.5217 - true_positive_rate: 0.2580 - iou_score: 0.0351 - val_loss: 2.0089 - val_dice_coef: 0.4320 - val_accuracy: 0.5428 - val_true_positive_rate: 0.2999 - val_iou_score: 0.0375\n",
      "\n",
      "Epoch 00051: val_loss improved from 2.01346 to 2.00888, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 52/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 2.0676 - dice_coef: 0.3883 - accuracy: 0.5187 - true_positive_rate: 0.2577 - iou_score: 0.0350 - val_loss: 2.0056 - val_dice_coef: 0.4340 - val_accuracy: 0.5429 - val_true_positive_rate: 0.3020 - val_iou_score: 0.0381\n",
      "\n",
      "Epoch 00052: val_loss improved from 2.00888 to 2.00556, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 53/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "116/116 [==============================] - 29s 246ms/step - loss: 2.0449 - dice_coef: 0.3919 - accuracy: 0.5246 - true_positive_rate: 0.2608 - iou_score: 0.0353 - val_loss: 2.0048 - val_dice_coef: 0.4357 - val_accuracy: 0.5427 - val_true_positive_rate: 0.3036 - val_iou_score: 0.0381\n",
      "\n",
      "Epoch 00053: val_loss improved from 2.00556 to 2.00484, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 54/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 2.0520 - dice_coef: 0.3901 - accuracy: 0.5181 - true_positive_rate: 0.2590 - iou_score: 0.0352 - val_loss: 2.0030 - val_dice_coef: 0.4355 - val_accuracy: 0.5428 - val_true_positive_rate: 0.3036 - val_iou_score: 0.0378\n",
      "\n",
      "Epoch 00054: val_loss improved from 2.00484 to 2.00304, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 55/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 2.0412 - dice_coef: 0.3922 - accuracy: 0.5227 - true_positive_rate: 0.2609 - iou_score: 0.0355 - val_loss: 2.0003 - val_dice_coef: 0.4337 - val_accuracy: 0.5433 - val_true_positive_rate: 0.3014 - val_iou_score: 0.0376\n",
      "\n",
      "Epoch 00055: val_loss improved from 2.00304 to 2.00025, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 56/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 2.0285 - dice_coef: 0.3959 - accuracy: 0.5232 - true_positive_rate: 0.2640 - iou_score: 0.0356 - val_loss: 1.9929 - val_dice_coef: 0.4366 - val_accuracy: 0.5441 - val_true_positive_rate: 0.3043 - val_iou_score: 0.0383\n",
      "\n",
      "Epoch 00056: val_loss improved from 2.00025 to 1.99291, saving model to seg_model_2_best_weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 2.0368 - dice_coef: 0.3928 - accuracy: 0.5229 - true_positive_rate: 0.2615 - iou_score: 0.0354 - val_loss: 1.9924 - val_dice_coef: 0.4377 - val_accuracy: 0.5443 - val_true_positive_rate: 0.3052 - val_iou_score: 0.0382\n",
      "\n",
      "Epoch 00057: val_loss improved from 1.99291 to 1.99243, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 58/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "116/116 [==============================] - 29s 246ms/step - loss: 2.0357 - dice_coef: 0.3935 - accuracy: 0.5211 - true_positive_rate: 0.2621 - iou_score: 0.0354 - val_loss: 1.9862 - val_dice_coef: 0.4387 - val_accuracy: 0.5454 - val_true_positive_rate: 0.3070 - val_iou_score: 0.0383\n",
      "\n",
      "Epoch 00058: val_loss improved from 1.99243 to 1.98622, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 59/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 2.0342 - dice_coef: 0.3941 - accuracy: 0.5219 - true_positive_rate: 0.2628 - iou_score: 0.0354 - val_loss: 1.9835 - val_dice_coef: 0.4379 - val_accuracy: 0.5458 - val_true_positive_rate: 0.3057 - val_iou_score: 0.0382\n",
      "\n",
      "Epoch 00059: val_loss improved from 1.98622 to 1.98345, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 60/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 2.0189 - dice_coef: 0.3980 - accuracy: 0.5259 - true_positive_rate: 0.2658 - iou_score: 0.0358 - val_loss: 1.9816 - val_dice_coef: 0.4377 - val_accuracy: 0.5465 - val_true_positive_rate: 0.3061 - val_iou_score: 0.0378\n",
      "\n",
      "Epoch 00060: val_loss improved from 1.98345 to 1.98163, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 61/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 2.0149 - dice_coef: 0.3978 - accuracy: 0.5268 - true_positive_rate: 0.2662 - iou_score: 0.0359 - val_loss: 1.9624 - val_dice_coef: 0.4361 - val_accuracy: 0.5486 - val_true_positive_rate: 0.3033 - val_iou_score: 0.0380\n",
      "\n",
      "Epoch 00061: val_loss improved from 1.98163 to 1.96242, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 62/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 2.0072 - dice_coef: 0.3986 - accuracy: 0.5258 - true_positive_rate: 0.2673 - iou_score: 0.0359 - val_loss: 1.9486 - val_dice_coef: 0.4497 - val_accuracy: 0.5490 - val_true_positive_rate: 0.3181 - val_iou_score: 0.0394\n",
      "\n",
      "Epoch 00062: val_loss improved from 1.96242 to 1.94859, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 63/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 29s 246ms/step - loss: 1.9823 - dice_coef: 0.4073 - accuracy: 0.5283 - true_positive_rate: 0.2745 - iou_score: 0.0365 - val_loss: 1.9413 - val_dice_coef: 0.4596 - val_accuracy: 0.5516 - val_true_positive_rate: 0.3297 - val_iou_score: 0.0404\n",
      "\n",
      "Epoch 00063: val_loss improved from 1.94859 to 1.94132, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 64/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.9656 - dice_coef: 0.4068 - accuracy: 0.5304 - true_positive_rate: 0.2741 - iou_score: 0.0367 - val_loss: 1.9224 - val_dice_coef: 0.4612 - val_accuracy: 0.5530 - val_true_positive_rate: 0.3318 - val_iou_score: 0.0403\n",
      "\n",
      "Epoch 00064: val_loss improved from 1.94132 to 1.92235, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 65/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.9567 - dice_coef: 0.4081 - accuracy: 0.5330 - true_positive_rate: 0.2761 - iou_score: 0.0368 - val_loss: 1.9013 - val_dice_coef: 0.4579 - val_accuracy: 0.5556 - val_true_positive_rate: 0.3265 - val_iou_score: 0.0398\n",
      "\n",
      "Epoch 00065: val_loss improved from 1.92235 to 1.90132, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 66/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.9224 - dice_coef: 0.4203 - accuracy: 0.5379 - true_positive_rate: 0.2861 - iou_score: 0.0378 - val_loss: 1.8860 - val_dice_coef: 0.4629 - val_accuracy: 0.5566 - val_true_positive_rate: 0.3339 - val_iou_score: 0.0402\n",
      "\n",
      "Epoch 00066: val_loss improved from 1.90132 to 1.88595, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 67/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.9115 - dice_coef: 0.4237 - accuracy: 0.5383 - true_positive_rate: 0.2899 - iou_score: 0.0379 - val_loss: 1.8943 - val_dice_coef: 0.4689 - val_accuracy: 0.5554 - val_true_positive_rate: 0.3396 - val_iou_score: 0.0407\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1.88595\n",
      "Epoch 68/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.8977 - dice_coef: 0.4242 - accuracy: 0.5398 - true_positive_rate: 0.2901 - iou_score: 0.0383 - val_loss: 1.8651 - val_dice_coef: 0.4662 - val_accuracy: 0.5596 - val_true_positive_rate: 0.3353 - val_iou_score: 0.0410\n",
      "\n",
      "Epoch 00068: val_loss improved from 1.88595 to 1.86512, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 69/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 246ms/step - loss: 1.8708 - dice_coef: 0.4320 - accuracy: 0.5429 - true_positive_rate: 0.2968 - iou_score: 0.0388 - val_loss: 1.8574 - val_dice_coef: 0.4767 - val_accuracy: 0.5598 - val_true_positive_rate: 0.3482 - val_iou_score: 0.0421\n",
      "\n",
      "Epoch 00069: val_loss improved from 1.86512 to 1.85744, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 70/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.8645 - dice_coef: 0.4320 - accuracy: 0.5436 - true_positive_rate: 0.2977 - iou_score: 0.0389 - val_loss: 1.8444 - val_dice_coef: 0.4702 - val_accuracy: 0.5590 - val_true_positive_rate: 0.3404 - val_iou_score: 0.0408\n",
      "\n",
      "Epoch 00070: val_loss improved from 1.85744 to 1.84444, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 71/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.8555 - dice_coef: 0.4336 - accuracy: 0.5444 - true_positive_rate: 0.2989 - iou_score: 0.0387 - val_loss: 1.8198 - val_dice_coef: 0.4696 - val_accuracy: 0.5623 - val_true_positive_rate: 0.3400 - val_iou_score: 0.0411\n",
      "\n",
      "Epoch 00071: val_loss improved from 1.84444 to 1.81985, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 72/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.8338 - dice_coef: 0.4410 - accuracy: 0.5471 - true_positive_rate: 0.3053 - iou_score: 0.0396 - val_loss: 1.8157 - val_dice_coef: 0.4755 - val_accuracy: 0.5642 - val_true_positive_rate: 0.3462 - val_iou_score: 0.0420\n",
      "\n",
      "Epoch 00072: val_loss improved from 1.81985 to 1.81565, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 73/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.8265 - dice_coef: 0.4431 - accuracy: 0.5488 - true_positive_rate: 0.3082 - iou_score: 0.0397 - val_loss: 1.8175 - val_dice_coef: 0.4756 - val_accuracy: 0.5646 - val_true_positive_rate: 0.3450 - val_iou_score: 0.0414\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1.81565\n",
      "Epoch 74/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.8090 - dice_coef: 0.4473 - accuracy: 0.5501 - true_positive_rate: 0.3119 - iou_score: 0.0402 - val_loss: 1.8117 - val_dice_coef: 0.4776 - val_accuracy: 0.5637 - val_true_positive_rate: 0.3506 - val_iou_score: 0.0421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00074: val_loss improved from 1.81565 to 1.81167, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 75/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.8042 - dice_coef: 0.4442 - accuracy: 0.5505 - true_positive_rate: 0.3095 - iou_score: 0.0398 - val_loss: 1.8142 - val_dice_coef: 0.4806 - val_accuracy: 0.5644 - val_true_positive_rate: 0.3519 - val_iou_score: 0.0417\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1.81167\n",
      "Epoch 76/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.7922 - dice_coef: 0.4491 - accuracy: 0.5526 - true_positive_rate: 0.3140 - iou_score: 0.0400 - val_loss: 1.7877 - val_dice_coef: 0.4830 - val_accuracy: 0.5672 - val_true_positive_rate: 0.3552 - val_iou_score: 0.0428\n",
      "\n",
      "Epoch 00076: val_loss improved from 1.81167 to 1.78771, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 77/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.7790 - dice_coef: 0.4525 - accuracy: 0.5528 - true_positive_rate: 0.3175 - iou_score: 0.0404 - val_loss: 1.7801 - val_dice_coef: 0.4894 - val_accuracy: 0.5672 - val_true_positive_rate: 0.3627 - val_iou_score: 0.0430\n",
      "\n",
      "Epoch 00077: val_loss improved from 1.78771 to 1.78010, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 78/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.7690 - dice_coef: 0.4520 - accuracy: 0.5545 - true_positive_rate: 0.3169 - iou_score: 0.0404 - val_loss: 1.7619 - val_dice_coef: 0.4859 - val_accuracy: 0.5698 - val_true_positive_rate: 0.3583 - val_iou_score: 0.0424\n",
      "\n",
      "Epoch 00078: val_loss improved from 1.78010 to 1.76194, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 79/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 246ms/step - loss: 1.7488 - dice_coef: 0.4573 - accuracy: 0.5596 - true_positive_rate: 0.3221 - iou_score: 0.0411 - val_loss: 1.7692 - val_dice_coef: 0.4895 - val_accuracy: 0.5682 - val_true_positive_rate: 0.3626 - val_iou_score: 0.0428\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1.76194\n",
      "Epoch 80/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.7332 - dice_coef: 0.4621 - accuracy: 0.5605 - true_positive_rate: 0.3268 - iou_score: 0.0414 - val_loss: 1.7441 - val_dice_coef: 0.4852 - val_accuracy: 0.5706 - val_true_positive_rate: 0.3570 - val_iou_score: 0.0426\n",
      "\n",
      "Epoch 00080: val_loss improved from 1.76194 to 1.74409, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 81/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.7278 - dice_coef: 0.4648 - accuracy: 0.5605 - true_positive_rate: 0.3295 - iou_score: 0.0416 - val_loss: 1.7500 - val_dice_coef: 0.4952 - val_accuracy: 0.5721 - val_true_positive_rate: 0.3680 - val_iou_score: 0.0440\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 1.74409\n",
      "Epoch 82/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.7147 - dice_coef: 0.4668 - accuracy: 0.5638 - true_positive_rate: 0.3310 - iou_score: 0.0420 - val_loss: 1.7407 - val_dice_coef: 0.4863 - val_accuracy: 0.5717 - val_true_positive_rate: 0.3574 - val_iou_score: 0.0423\n",
      "\n",
      "Epoch 00082: val_loss improved from 1.74409 to 1.74071, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 83/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.6998 - dice_coef: 0.4713 - accuracy: 0.5678 - true_positive_rate: 0.3354 - iou_score: 0.0423 - val_loss: 1.7321 - val_dice_coef: 0.4853 - val_accuracy: 0.5712 - val_true_positive_rate: 0.3567 - val_iou_score: 0.0428\n",
      "\n",
      "Epoch 00083: val_loss improved from 1.74071 to 1.73211, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 84/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.6952 - dice_coef: 0.4735 - accuracy: 0.5664 - true_positive_rate: 0.3386 - iou_score: 0.0424 - val_loss: 1.7254 - val_dice_coef: 0.4988 - val_accuracy: 0.5734 - val_true_positive_rate: 0.3728 - val_iou_score: 0.0441\n",
      "\n",
      "Epoch 00084: val_loss improved from 1.73211 to 1.72544, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 85/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.6834 - dice_coef: 0.4759 - accuracy: 0.5668 - true_positive_rate: 0.3409 - iou_score: 0.0427 - val_loss: 1.7128 - val_dice_coef: 0.4991 - val_accuracy: 0.5738 - val_true_positive_rate: 0.3736 - val_iou_score: 0.0437\n",
      "\n",
      "Epoch 00085: val_loss improved from 1.72544 to 1.71276, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 86/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.6798 - dice_coef: 0.4734 - accuracy: 0.5679 - true_positive_rate: 0.3385 - iou_score: 0.0425 - val_loss: 1.7045 - val_dice_coef: 0.4944 - val_accuracy: 0.5754 - val_true_positive_rate: 0.3683 - val_iou_score: 0.0434\n",
      "\n",
      "Epoch 00086: val_loss improved from 1.71276 to 1.70453, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 87/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.6667 - dice_coef: 0.4779 - accuracy: 0.5670 - true_positive_rate: 0.3428 - iou_score: 0.0429 - val_loss: 1.7063 - val_dice_coef: 0.5050 - val_accuracy: 0.5749 - val_true_positive_rate: 0.3812 - val_iou_score: 0.0444\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 1.70453\n",
      "Epoch 88/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.6537 - dice_coef: 0.4813 - accuracy: 0.5704 - true_positive_rate: 0.3461 - iou_score: 0.0433 - val_loss: 1.7069 - val_dice_coef: 0.5044 - val_accuracy: 0.5742 - val_true_positive_rate: 0.3817 - val_iou_score: 0.0449\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 1.70453\n",
      "Epoch 89/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.6385 - dice_coef: 0.4856 - accuracy: 0.5748 - true_positive_rate: 0.3503 - iou_score: 0.0435 - val_loss: 1.7228 - val_dice_coef: 0.5097 - val_accuracy: 0.5728 - val_true_positive_rate: 0.3879 - val_iou_score: 0.0456\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 1.70453\n",
      "Epoch 90/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.6439 - dice_coef: 0.4865 - accuracy: 0.5722 - true_positive_rate: 0.3516 - iou_score: 0.0436 - val_loss: 1.6754 - val_dice_coef: 0.4978 - val_accuracy: 0.5762 - val_true_positive_rate: 0.3714 - val_iou_score: 0.0441\n",
      "\n",
      "Epoch 00090: val_loss improved from 1.70453 to 1.67544, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 91/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.6251 - dice_coef: 0.4872 - accuracy: 0.5736 - true_positive_rate: 0.3525 - iou_score: 0.0439 - val_loss: 1.6837 - val_dice_coef: 0.5054 - val_accuracy: 0.5749 - val_true_positive_rate: 0.3812 - val_iou_score: 0.0448\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 1.67544\n",
      "Epoch 92/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.6173 - dice_coef: 0.4922 - accuracy: 0.5764 - true_positive_rate: 0.3571 - iou_score: 0.0443 - val_loss: 1.6734 - val_dice_coef: 0.5061 - val_accuracy: 0.5771 - val_true_positive_rate: 0.3828 - val_iou_score: 0.0443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00092: val_loss improved from 1.67544 to 1.67337, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 93/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.5992 - dice_coef: 0.4965 - accuracy: 0.5800 - true_positive_rate: 0.3607 - iou_score: 0.0447 - val_loss: 1.6670 - val_dice_coef: 0.5036 - val_accuracy: 0.5775 - val_true_positive_rate: 0.3787 - val_iou_score: 0.0447\n",
      "\n",
      "Epoch 00093: val_loss improved from 1.67337 to 1.66702, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 94/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 246ms/step - loss: 1.5849 - dice_coef: 0.4986 - accuracy: 0.5816 - true_positive_rate: 0.3637 - iou_score: 0.0448 - val_loss: 1.6804 - val_dice_coef: 0.5123 - val_accuracy: 0.5777 - val_true_positive_rate: 0.3904 - val_iou_score: 0.0452\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 1.66702\n",
      "Epoch 95/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.5851 - dice_coef: 0.4978 - accuracy: 0.5797 - true_positive_rate: 0.3636 - iou_score: 0.0448 - val_loss: 1.6514 - val_dice_coef: 0.5119 - val_accuracy: 0.5776 - val_true_positive_rate: 0.3895 - val_iou_score: 0.0455\n",
      "\n",
      "Epoch 00095: val_loss improved from 1.66702 to 1.65142, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 96/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.5781 - dice_coef: 0.5033 - accuracy: 0.5828 - true_positive_rate: 0.3691 - iou_score: 0.0453 - val_loss: 1.6452 - val_dice_coef: 0.5082 - val_accuracy: 0.5774 - val_true_positive_rate: 0.3848 - val_iou_score: 0.0447\n",
      "\n",
      "Epoch 00096: val_loss improved from 1.65142 to 1.64521, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 97/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.5677 - dice_coef: 0.5062 - accuracy: 0.5844 - true_positive_rate: 0.3714 - iou_score: 0.0458 - val_loss: 1.6481 - val_dice_coef: 0.5090 - val_accuracy: 0.5777 - val_true_positive_rate: 0.3872 - val_iou_score: 0.0451\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 1.64521\n",
      "Epoch 98/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.5529 - dice_coef: 0.5084 - accuracy: 0.5865 - true_positive_rate: 0.3739 - iou_score: 0.0460 - val_loss: 1.6373 - val_dice_coef: 0.5150 - val_accuracy: 0.5782 - val_true_positive_rate: 0.3929 - val_iou_score: 0.0458\n",
      "\n",
      "Epoch 00098: val_loss improved from 1.64521 to 1.63732, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 99/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.5316 - dice_coef: 0.5135 - accuracy: 0.5918 - true_positive_rate: 0.3786 - iou_score: 0.0463 - val_loss: 1.6415 - val_dice_coef: 0.5153 - val_accuracy: 0.5785 - val_true_positive_rate: 0.3953 - val_iou_score: 0.0453\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 1.63732\n",
      "Epoch 100/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.5341 - dice_coef: 0.5150 - accuracy: 0.5915 - true_positive_rate: 0.3807 - iou_score: 0.0467 - val_loss: 1.6256 - val_dice_coef: 0.5123 - val_accuracy: 0.5787 - val_true_positive_rate: 0.3903 - val_iou_score: 0.0454\n",
      "\n",
      "Epoch 00100: val_loss improved from 1.63732 to 1.62556, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 101/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.5243 - dice_coef: 0.5158 - accuracy: 0.5917 - true_positive_rate: 0.3819 - iou_score: 0.0468 - val_loss: 1.6214 - val_dice_coef: 0.5117 - val_accuracy: 0.5801 - val_true_positive_rate: 0.3896 - val_iou_score: 0.0457\n",
      "\n",
      "Epoch 00101: val_loss improved from 1.62556 to 1.62141, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 102/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.5198 - dice_coef: 0.5177 - accuracy: 0.5931 - true_positive_rate: 0.3848 - iou_score: 0.0468 - val_loss: 1.6292 - val_dice_coef: 0.5155 - val_accuracy: 0.5797 - val_true_positive_rate: 0.3937 - val_iou_score: 0.0459\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 1.62141\n",
      "Epoch 103/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.5160 - dice_coef: 0.5170 - accuracy: 0.5914 - true_positive_rate: 0.3835 - iou_score: 0.0468 - val_loss: 1.6358 - val_dice_coef: 0.5244 - val_accuracy: 0.5792 - val_true_positive_rate: 0.4078 - val_iou_score: 0.0471\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 1.62141\n",
      "Epoch 104/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.5057 - dice_coef: 0.5205 - accuracy: 0.5944 - true_positive_rate: 0.3869 - iou_score: 0.0470 - val_loss: 1.6123 - val_dice_coef: 0.5214 - val_accuracy: 0.5805 - val_true_positive_rate: 0.4030 - val_iou_score: 0.0467\n",
      "\n",
      "Epoch 00104: val_loss improved from 1.62141 to 1.61228, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 105/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.4953 - dice_coef: 0.5264 - accuracy: 0.5983 - true_positive_rate: 0.3929 - iou_score: 0.0477 - val_loss: 1.6151 - val_dice_coef: 0.5230 - val_accuracy: 0.5796 - val_true_positive_rate: 0.4051 - val_iou_score: 0.0471\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 1.61228\n",
      "Epoch 106/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 29s 246ms/step - loss: 1.4924 - dice_coef: 0.5257 - accuracy: 0.5957 - true_positive_rate: 0.3937 - iou_score: 0.0479 - val_loss: 1.6067 - val_dice_coef: 0.5197 - val_accuracy: 0.5799 - val_true_positive_rate: 0.4002 - val_iou_score: 0.0464\n",
      "\n",
      "Epoch 00106: val_loss improved from 1.61228 to 1.60669, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 107/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.4767 - dice_coef: 0.5293 - accuracy: 0.5967 - true_positive_rate: 0.3972 - iou_score: 0.0481 - val_loss: 1.5810 - val_dice_coef: 0.5141 - val_accuracy: 0.5798 - val_true_positive_rate: 0.3927 - val_iou_score: 0.0460\n",
      "\n",
      "Epoch 00107: val_loss improved from 1.60669 to 1.58103, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 108/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.4679 - dice_coef: 0.5303 - accuracy: 0.6014 - true_positive_rate: 0.3975 - iou_score: 0.0482 - val_loss: 1.6000 - val_dice_coef: 0.5188 - val_accuracy: 0.5796 - val_true_positive_rate: 0.4014 - val_iou_score: 0.0472\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 1.58103\n",
      "Epoch 109/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.4653 - dice_coef: 0.5333 - accuracy: 0.5995 - true_positive_rate: 0.4010 - iou_score: 0.0483 - val_loss: 1.6148 - val_dice_coef: 0.5222 - val_accuracy: 0.5772 - val_true_positive_rate: 0.4066 - val_iou_score: 0.0471\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 1.58103\n",
      "Epoch 110/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.4597 - dice_coef: 0.5354 - accuracy: 0.6036 - true_positive_rate: 0.4037 - iou_score: 0.0484 - val_loss: 1.5999 - val_dice_coef: 0.5244 - val_accuracy: 0.5787 - val_true_positive_rate: 0.4080 - val_iou_score: 0.0468\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 1.58103\n",
      "Epoch 111/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 28s 245ms/step - loss: 1.4489 - dice_coef: 0.5356 - accuracy: 0.6026 - true_positive_rate: 0.4045 - iou_score: 0.0487 - val_loss: 1.5884 - val_dice_coef: 0.5297 - val_accuracy: 0.5817 - val_true_positive_rate: 0.4155 - val_iou_score: 0.0471\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 1.58103\n",
      "Epoch 112/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.4434 - dice_coef: 0.5396 - accuracy: 0.6055 - true_positive_rate: 0.4081 - iou_score: 0.0492 - val_loss: 1.5698 - val_dice_coef: 0.5165 - val_accuracy: 0.5793 - val_true_positive_rate: 0.3980 - val_iou_score: 0.0467\n",
      "\n",
      "Epoch 00112: val_loss improved from 1.58103 to 1.56977, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 113/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.4325 - dice_coef: 0.5426 - accuracy: 0.6072 - true_positive_rate: 0.4112 - iou_score: 0.0494 - val_loss: 1.5802 - val_dice_coef: 0.5285 - val_accuracy: 0.5821 - val_true_positive_rate: 0.4136 - val_iou_score: 0.0476\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 1.56977\n",
      "Epoch 114/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.4399 - dice_coef: 0.5382 - accuracy: 0.6044 - true_positive_rate: 0.4073 - iou_score: 0.0490 - val_loss: 1.5776 - val_dice_coef: 0.5263 - val_accuracy: 0.5809 - val_true_positive_rate: 0.4105 - val_iou_score: 0.0475\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 1.56977\n",
      "Epoch 115/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.4271 - dice_coef: 0.5465 - accuracy: 0.6067 - true_positive_rate: 0.4160 - iou_score: 0.0497 - val_loss: 1.5669 - val_dice_coef: 0.5287 - val_accuracy: 0.5810 - val_true_positive_rate: 0.4150 - val_iou_score: 0.0478\n",
      "\n",
      "Epoch 00115: val_loss improved from 1.56977 to 1.56688, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 116/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.4250 - dice_coef: 0.5453 - accuracy: 0.6062 - true_positive_rate: 0.4154 - iou_score: 0.0498 - val_loss: 1.5498 - val_dice_coef: 0.5240 - val_accuracy: 0.5802 - val_true_positive_rate: 0.4088 - val_iou_score: 0.0472\n",
      "\n",
      "Epoch 00116: val_loss improved from 1.56688 to 1.54977, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 117/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.4110 - dice_coef: 0.5482 - accuracy: 0.6107 - true_positive_rate: 0.4181 - iou_score: 0.0499 - val_loss: 1.5605 - val_dice_coef: 0.5251 - val_accuracy: 0.5799 - val_true_positive_rate: 0.4094 - val_iou_score: 0.0471\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 1.54977\n",
      "Epoch 118/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.4044 - dice_coef: 0.5491 - accuracy: 0.6104 - true_positive_rate: 0.4193 - iou_score: 0.0501 - val_loss: 1.5613 - val_dice_coef: 0.5311 - val_accuracy: 0.5817 - val_true_positive_rate: 0.4164 - val_iou_score: 0.0479\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 1.54977\n",
      "Epoch 119/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.3969 - dice_coef: 0.5538 - accuracy: 0.6120 - true_positive_rate: 0.4246 - iou_score: 0.0506 - val_loss: 1.5643 - val_dice_coef: 0.5330 - val_accuracy: 0.5805 - val_true_positive_rate: 0.4200 - val_iou_score: 0.0483\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 1.54977\n",
      "Epoch 120/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.3896 - dice_coef: 0.5553 - accuracy: 0.6137 - true_positive_rate: 0.4250 - iou_score: 0.0511 - val_loss: 1.5537 - val_dice_coef: 0.5305 - val_accuracy: 0.5805 - val_true_positive_rate: 0.4175 - val_iou_score: 0.0483\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 1.54977\n",
      "Epoch 121/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.3928 - dice_coef: 0.5542 - accuracy: 0.6125 - true_positive_rate: 0.4260 - iou_score: 0.0508 - val_loss: 1.5470 - val_dice_coef: 0.5260 - val_accuracy: 0.5804 - val_true_positive_rate: 0.4109 - val_iou_score: 0.0481\n",
      "\n",
      "Epoch 00121: val_loss improved from 1.54977 to 1.54696, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 122/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.3788 - dice_coef: 0.5581 - accuracy: 0.6160 - true_positive_rate: 0.4289 - iou_score: 0.0511 - val_loss: 1.5437 - val_dice_coef: 0.5313 - val_accuracy: 0.5802 - val_true_positive_rate: 0.4216 - val_iou_score: 0.0490\n",
      "\n",
      "Epoch 00122: val_loss improved from 1.54696 to 1.54375, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 123/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.3720 - dice_coef: 0.5599 - accuracy: 0.6166 - true_positive_rate: 0.4312 - iou_score: 0.0513 - val_loss: 1.5324 - val_dice_coef: 0.5251 - val_accuracy: 0.5796 - val_true_positive_rate: 0.4107 - val_iou_score: 0.0478\n",
      "\n",
      "Epoch 00123: val_loss improved from 1.54375 to 1.53236, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 124/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.3625 - dice_coef: 0.5628 - accuracy: 0.6199 - true_positive_rate: 0.4355 - iou_score: 0.0518 - val_loss: 1.5598 - val_dice_coef: 0.5319 - val_accuracy: 0.5815 - val_true_positive_rate: 0.4205 - val_iou_score: 0.0483\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 1.53236\n",
      "Epoch 125/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 246ms/step - loss: 1.3494 - dice_coef: 0.5691 - accuracy: 0.6222 - true_positive_rate: 0.4406 - iou_score: 0.0525 - val_loss: 1.5528 - val_dice_coef: 0.5401 - val_accuracy: 0.5827 - val_true_positive_rate: 0.4313 - val_iou_score: 0.0493\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 1.53236\n",
      "Epoch 126/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 29s 246ms/step - loss: 1.3551 - dice_coef: 0.5649 - accuracy: 0.6202 - true_positive_rate: 0.4375 - iou_score: 0.0522 - val_loss: 1.5479 - val_dice_coef: 0.5355 - val_accuracy: 0.5798 - val_true_positive_rate: 0.4270 - val_iou_score: 0.0491\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 1.53236\n",
      "Epoch 127/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.3487 - dice_coef: 0.5678 - accuracy: 0.6216 - true_positive_rate: 0.4408 - iou_score: 0.0524 - val_loss: 1.5273 - val_dice_coef: 0.5298 - val_accuracy: 0.5787 - val_true_positive_rate: 0.4189 - val_iou_score: 0.0481\n",
      "\n",
      "Epoch 00127: val_loss improved from 1.53236 to 1.52726, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 128/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.3521 - dice_coef: 0.5633 - accuracy: 0.6187 - true_positive_rate: 0.4359 - iou_score: 0.0517 - val_loss: 1.5374 - val_dice_coef: 0.5349 - val_accuracy: 0.5812 - val_true_positive_rate: 0.4245 - val_iou_score: 0.0488\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 1.52726\n",
      "Epoch 129/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.3325 - dice_coef: 0.5726 - accuracy: 0.6252 - true_positive_rate: 0.4461 - iou_score: 0.0528 - val_loss: 1.5410 - val_dice_coef: 0.5374 - val_accuracy: 0.5797 - val_true_positive_rate: 0.4293 - val_iou_score: 0.0499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00129: val_loss did not improve from 1.52726\n",
      "Epoch 130/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.3202 - dice_coef: 0.5765 - accuracy: 0.6268 - true_positive_rate: 0.4501 - iou_score: 0.0535 - val_loss: 1.5257 - val_dice_coef: 0.5364 - val_accuracy: 0.5817 - val_true_positive_rate: 0.4278 - val_iou_score: 0.0490\n",
      "\n",
      "Epoch 00130: val_loss improved from 1.52726 to 1.52565, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 131/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.3113 - dice_coef: 0.5801 - accuracy: 0.6284 - true_positive_rate: 0.4541 - iou_score: 0.0537 - val_loss: 1.5307 - val_dice_coef: 0.5349 - val_accuracy: 0.5793 - val_true_positive_rate: 0.4260 - val_iou_score: 0.0491\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 1.52565\n",
      "Epoch 132/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.3218 - dice_coef: 0.5769 - accuracy: 0.6254 - true_positive_rate: 0.4524 - iou_score: 0.0534 - val_loss: 1.5246 - val_dice_coef: 0.5334 - val_accuracy: 0.5781 - val_true_positive_rate: 0.4244 - val_iou_score: 0.0488\n",
      "\n",
      "Epoch 00132: val_loss improved from 1.52565 to 1.52462, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 133/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 246ms/step - loss: 1.3083 - dice_coef: 0.5810 - accuracy: 0.6287 - true_positive_rate: 0.4556 - iou_score: 0.0540 - val_loss: 1.5242 - val_dice_coef: 0.5425 - val_accuracy: 0.5830 - val_true_positive_rate: 0.4366 - val_iou_score: 0.0498\n",
      "\n",
      "Epoch 00133: val_loss improved from 1.52462 to 1.52423, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 134/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.3133 - dice_coef: 0.5758 - accuracy: 0.6265 - true_positive_rate: 0.4508 - iou_score: 0.0531 - val_loss: 1.5254 - val_dice_coef: 0.5366 - val_accuracy: 0.5785 - val_true_positive_rate: 0.4326 - val_iou_score: 0.0496\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 1.52423\n",
      "Epoch 135/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.2971 - dice_coef: 0.5841 - accuracy: 0.6331 - true_positive_rate: 0.4594 - iou_score: 0.0544 - val_loss: 1.5170 - val_dice_coef: 0.5352 - val_accuracy: 0.5787 - val_true_positive_rate: 0.4274 - val_iou_score: 0.0493\n",
      "\n",
      "Epoch 00135: val_loss improved from 1.52423 to 1.51703, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 136/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.3026 - dice_coef: 0.5836 - accuracy: 0.6310 - true_positive_rate: 0.4599 - iou_score: 0.0541 - val_loss: 1.5125 - val_dice_coef: 0.5389 - val_accuracy: 0.5805 - val_true_positive_rate: 0.4343 - val_iou_score: 0.0497\n",
      "\n",
      "Epoch 00136: val_loss improved from 1.51703 to 1.51251, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 137/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.2953 - dice_coef: 0.5839 - accuracy: 0.6319 - true_positive_rate: 0.4600 - iou_score: 0.0544 - val_loss: 1.5219 - val_dice_coef: 0.5401 - val_accuracy: 0.5794 - val_true_positive_rate: 0.4362 - val_iou_score: 0.0498\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 1.51251\n",
      "Epoch 138/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.2922 - dice_coef: 0.5843 - accuracy: 0.6320 - true_positive_rate: 0.4606 - iou_score: 0.0542 - val_loss: 1.4978 - val_dice_coef: 0.5362 - val_accuracy: 0.5786 - val_true_positive_rate: 0.4295 - val_iou_score: 0.0493\n",
      "\n",
      "Epoch 00138: val_loss improved from 1.51251 to 1.49777, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 139/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 29s 246ms/step - loss: 1.2848 - dice_coef: 0.5871 - accuracy: 0.6326 - true_positive_rate: 0.4640 - iou_score: 0.0546 - val_loss: 1.4976 - val_dice_coef: 0.5344 - val_accuracy: 0.5780 - val_true_positive_rate: 0.4284 - val_iou_score: 0.0496\n",
      "\n",
      "Epoch 00139: val_loss improved from 1.49777 to 1.49763, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 140/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.2692 - dice_coef: 0.5920 - accuracy: 0.6376 - true_positive_rate: 0.4686 - iou_score: 0.0553 - val_loss: 1.4916 - val_dice_coef: 0.5417 - val_accuracy: 0.5821 - val_true_positive_rate: 0.4378 - val_iou_score: 0.0500\n",
      "\n",
      "Epoch 00140: val_loss improved from 1.49763 to 1.49165, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 141/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.2694 - dice_coef: 0.5930 - accuracy: 0.6362 - true_positive_rate: 0.4706 - iou_score: 0.0553 - val_loss: 1.5107 - val_dice_coef: 0.5410 - val_accuracy: 0.5815 - val_true_positive_rate: 0.4360 - val_iou_score: 0.0499\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 1.49165\n",
      "Epoch 142/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.2636 - dice_coef: 0.5939 - accuracy: 0.6367 - true_positive_rate: 0.4717 - iou_score: 0.0557 - val_loss: 1.4884 - val_dice_coef: 0.5398 - val_accuracy: 0.5795 - val_true_positive_rate: 0.4366 - val_iou_score: 0.0504\n",
      "\n",
      "Epoch 00142: val_loss improved from 1.49165 to 1.48843, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 143/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.2508 - dice_coef: 0.5978 - accuracy: 0.6409 - true_positive_rate: 0.4754 - iou_score: 0.0562 - val_loss: 1.5030 - val_dice_coef: 0.5419 - val_accuracy: 0.5803 - val_true_positive_rate: 0.4389 - val_iou_score: 0.0505\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 1.48843\n",
      "Epoch 144/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.2666 - dice_coef: 0.5915 - accuracy: 0.6361 - true_positive_rate: 0.4694 - iou_score: 0.0553 - val_loss: 1.4912 - val_dice_coef: 0.5377 - val_accuracy: 0.5792 - val_true_positive_rate: 0.4337 - val_iou_score: 0.0503\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 1.48843\n",
      "Epoch 145/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.2545 - dice_coef: 0.5974 - accuracy: 0.6391 - true_positive_rate: 0.4766 - iou_score: 0.0558 - val_loss: 1.4956 - val_dice_coef: 0.5378 - val_accuracy: 0.5793 - val_true_positive_rate: 0.4340 - val_iou_score: 0.0498\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 1.48843\n",
      "Epoch 146/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.2445 - dice_coef: 0.5987 - accuracy: 0.6413 - true_positive_rate: 0.4775 - iou_score: 0.0562 - val_loss: 1.4828 - val_dice_coef: 0.5378 - val_accuracy: 0.5782 - val_true_positive_rate: 0.4340 - val_iou_score: 0.0502\n",
      "\n",
      "Epoch 00146: val_loss improved from 1.48843 to 1.48280, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 147/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.2284 - dice_coef: 0.6053 - accuracy: 0.6457 - true_positive_rate: 0.4850 - iou_score: 0.0572 - val_loss: 1.5082 - val_dice_coef: 0.5469 - val_accuracy: 0.5814 - val_true_positive_rate: 0.4468 - val_iou_score: 0.0514\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 1.48280\n",
      "Epoch 148/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 28s 245ms/step - loss: 1.2368 - dice_coef: 0.6017 - accuracy: 0.6415 - true_positive_rate: 0.4817 - iou_score: 0.0565 - val_loss: 1.4965 - val_dice_coef: 0.5430 - val_accuracy: 0.5801 - val_true_positive_rate: 0.4418 - val_iou_score: 0.0510\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 1.48280\n",
      "Epoch 149/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.2263 - dice_coef: 0.6037 - accuracy: 0.6431 - true_positive_rate: 0.4830 - iou_score: 0.0572 - val_loss: 1.4861 - val_dice_coef: 0.5384 - val_accuracy: 0.5799 - val_true_positive_rate: 0.4352 - val_iou_score: 0.0500\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 1.48280\n",
      "Epoch 150/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.2230 - dice_coef: 0.6071 - accuracy: 0.6460 - true_positive_rate: 0.4872 - iou_score: 0.0574 - val_loss: 1.4881 - val_dice_coef: 0.5442 - val_accuracy: 0.5801 - val_true_positive_rate: 0.4449 - val_iou_score: 0.0508\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 1.48280\n",
      "Epoch 151/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.2239 - dice_coef: 0.6068 - accuracy: 0.6452 - true_positive_rate: 0.4870 - iou_score: 0.0574 - val_loss: 1.4783 - val_dice_coef: 0.5414 - val_accuracy: 0.5792 - val_true_positive_rate: 0.4416 - val_iou_score: 0.0504\n",
      "\n",
      "Epoch 00151: val_loss improved from 1.48280 to 1.47834, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 152/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.2025 - dice_coef: 0.6142 - accuracy: 0.6520 - true_positive_rate: 0.4947 - iou_score: 0.0586 - val_loss: 1.4809 - val_dice_coef: 0.5449 - val_accuracy: 0.5810 - val_true_positive_rate: 0.4450 - val_iou_score: 0.0511\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 1.47834\n",
      "Epoch 153/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.2144 - dice_coef: 0.6087 - accuracy: 0.6480 - true_positive_rate: 0.4904 - iou_score: 0.0574 - val_loss: 1.4916 - val_dice_coef: 0.5447 - val_accuracy: 0.5801 - val_true_positive_rate: 0.4454 - val_iou_score: 0.0514\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 1.47834\n",
      "Epoch 154/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.2042 - dice_coef: 0.6131 - accuracy: 0.6496 - true_positive_rate: 0.4953 - iou_score: 0.0581 - val_loss: 1.4796 - val_dice_coef: 0.5419 - val_accuracy: 0.5793 - val_true_positive_rate: 0.4410 - val_iou_score: 0.0510\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 1.47834\n",
      "Epoch 155/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.1961 - dice_coef: 0.6154 - accuracy: 0.6525 - true_positive_rate: 0.4972 - iou_score: 0.0586 - val_loss: 1.4671 - val_dice_coef: 0.5387 - val_accuracy: 0.5783 - val_true_positive_rate: 0.4379 - val_iou_score: 0.0504\n",
      "\n",
      "Epoch 00155: val_loss improved from 1.47834 to 1.46715, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 156/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.1995 - dice_coef: 0.6140 - accuracy: 0.6507 - true_positive_rate: 0.4964 - iou_score: 0.0584 - val_loss: 1.4764 - val_dice_coef: 0.5431 - val_accuracy: 0.5795 - val_true_positive_rate: 0.4438 - val_iou_score: 0.0511\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 1.46715\n",
      "Epoch 157/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.1945 - dice_coef: 0.6173 - accuracy: 0.6516 - true_positive_rate: 0.5004 - iou_score: 0.0586 - val_loss: 1.4803 - val_dice_coef: 0.5427 - val_accuracy: 0.5783 - val_true_positive_rate: 0.4439 - val_iou_score: 0.0513\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 1.46715\n",
      "Epoch 158/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.2047 - dice_coef: 0.6132 - accuracy: 0.6487 - true_positive_rate: 0.4962 - iou_score: 0.0583 - val_loss: 1.4769 - val_dice_coef: 0.5451 - val_accuracy: 0.5802 - val_true_positive_rate: 0.4474 - val_iou_score: 0.0515\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 1.46715\n",
      "Epoch 159/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.1896 - dice_coef: 0.6174 - accuracy: 0.6530 - true_positive_rate: 0.4998 - iou_score: 0.0588 - val_loss: 1.4808 - val_dice_coef: 0.5445 - val_accuracy: 0.5791 - val_true_positive_rate: 0.4469 - val_iou_score: 0.0517\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 1.46715\n",
      "Epoch 160/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.1820 - dice_coef: 0.6185 - accuracy: 0.6531 - true_positive_rate: 0.5017 - iou_score: 0.0591 - val_loss: 1.4796 - val_dice_coef: 0.5457 - val_accuracy: 0.5793 - val_true_positive_rate: 0.4499 - val_iou_score: 0.0521\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 1.46715\n",
      "Epoch 161/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.1624 - dice_coef: 0.6268 - accuracy: 0.6592 - true_positive_rate: 0.5100 - iou_score: 0.0603 - val_loss: 1.4761 - val_dice_coef: 0.5432 - val_accuracy: 0.5776 - val_true_positive_rate: 0.4456 - val_iou_score: 0.0516\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 1.46715\n",
      "Epoch 162/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.1725 - dice_coef: 0.6226 - accuracy: 0.6554 - true_positive_rate: 0.5072 - iou_score: 0.0600 - val_loss: 1.4523 - val_dice_coef: 0.5392 - val_accuracy: 0.5782 - val_true_positive_rate: 0.4401 - val_iou_score: 0.0511\n",
      "\n",
      "Epoch 00162: val_loss improved from 1.46715 to 1.45231, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 163/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 244ms/step - loss: 1.1670 - dice_coef: 0.6256 - accuracy: 0.6565 - true_positive_rate: 0.5112 - iou_score: 0.0601 - val_loss: 1.4537 - val_dice_coef: 0.5431 - val_accuracy: 0.5781 - val_true_positive_rate: 0.4467 - val_iou_score: 0.0513\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 1.45231\n",
      "Epoch 164/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.1722 - dice_coef: 0.6231 - accuracy: 0.6566 - true_positive_rate: 0.5074 - iou_score: 0.0599 - val_loss: 1.4915 - val_dice_coef: 0.5472 - val_accuracy: 0.5795 - val_true_positive_rate: 0.4503 - val_iou_score: 0.0524\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 1.45231\n",
      "Epoch 165/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.1611 - dice_coef: 0.6267 - accuracy: 0.6597 - true_positive_rate: 0.5125 - iou_score: 0.0601 - val_loss: 1.4639 - val_dice_coef: 0.5436 - val_accuracy: 0.5795 - val_true_positive_rate: 0.4454 - val_iou_score: 0.0516\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 1.45231\n",
      "Epoch 166/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.1542 - dice_coef: 0.6278 - accuracy: 0.6606 - true_positive_rate: 0.5132 - iou_score: 0.0604 - val_loss: 1.4569 - val_dice_coef: 0.5479 - val_accuracy: 0.5814 - val_true_positive_rate: 0.4513 - val_iou_score: 0.0527\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 1.45231\n",
      "Epoch 167/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 28s 245ms/step - loss: 1.1458 - dice_coef: 0.6325 - accuracy: 0.6612 - true_positive_rate: 0.5195 - iou_score: 0.0612 - val_loss: 1.4731 - val_dice_coef: 0.5462 - val_accuracy: 0.5785 - val_true_positive_rate: 0.4504 - val_iou_score: 0.0522\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 1.45231\n",
      "Epoch 168/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.1403 - dice_coef: 0.6352 - accuracy: 0.6648 - true_positive_rate: 0.5217 - iou_score: 0.0617 - val_loss: 1.4518 - val_dice_coef: 0.5378 - val_accuracy: 0.5750 - val_true_positive_rate: 0.4413 - val_iou_score: 0.0514\n",
      "\n",
      "Epoch 00168: val_loss improved from 1.45231 to 1.45184, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 169/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.1449 - dice_coef: 0.6322 - accuracy: 0.6621 - true_positive_rate: 0.5187 - iou_score: 0.0612 - val_loss: 1.4618 - val_dice_coef: 0.5485 - val_accuracy: 0.5796 - val_true_positive_rate: 0.4541 - val_iou_score: 0.0533\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 1.45184\n",
      "Epoch 170/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.1369 - dice_coef: 0.6369 - accuracy: 0.6636 - true_positive_rate: 0.5241 - iou_score: 0.0615 - val_loss: 1.4652 - val_dice_coef: 0.5441 - val_accuracy: 0.5777 - val_true_positive_rate: 0.4488 - val_iou_score: 0.0522\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 1.45184\n",
      "Epoch 171/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.1433 - dice_coef: 0.6323 - accuracy: 0.6636 - true_positive_rate: 0.5195 - iou_score: 0.0614 - val_loss: 1.4640 - val_dice_coef: 0.5463 - val_accuracy: 0.5784 - val_true_positive_rate: 0.4519 - val_iou_score: 0.0520\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 1.45184\n",
      "Epoch 172/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.1333 - dice_coef: 0.6363 - accuracy: 0.6650 - true_positive_rate: 0.5230 - iou_score: 0.0620 - val_loss: 1.4519 - val_dice_coef: 0.5465 - val_accuracy: 0.5803 - val_true_positive_rate: 0.4524 - val_iou_score: 0.0522\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 1.45184\n",
      "Epoch 173/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 244ms/step - loss: 1.1291 - dice_coef: 0.6371 - accuracy: 0.6662 - true_positive_rate: 0.5244 - iou_score: 0.0621 - val_loss: 1.4663 - val_dice_coef: 0.5492 - val_accuracy: 0.5791 - val_true_positive_rate: 0.4567 - val_iou_score: 0.0532\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 1.45184\n",
      "Epoch 174/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.1127 - dice_coef: 0.6443 - accuracy: 0.6710 - true_positive_rate: 0.5326 - iou_score: 0.0627 - val_loss: 1.4736 - val_dice_coef: 0.5520 - val_accuracy: 0.5799 - val_true_positive_rate: 0.4596 - val_iou_score: 0.0534\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 1.45184\n",
      "Epoch 175/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.1189 - dice_coef: 0.6411 - accuracy: 0.6665 - true_positive_rate: 0.5303 - iou_score: 0.0624 - val_loss: 1.4593 - val_dice_coef: 0.5449 - val_accuracy: 0.5763 - val_true_positive_rate: 0.4519 - val_iou_score: 0.0526\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 1.45184\n",
      "Epoch 176/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.1131 - dice_coef: 0.6432 - accuracy: 0.6702 - true_positive_rate: 0.5313 - iou_score: 0.0625 - val_loss: 1.4478 - val_dice_coef: 0.5420 - val_accuracy: 0.5767 - val_true_positive_rate: 0.4489 - val_iou_score: 0.0521\n",
      "\n",
      "Epoch 00176: val_loss improved from 1.45184 to 1.44776, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 177/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.1114 - dice_coef: 0.6446 - accuracy: 0.6702 - true_positive_rate: 0.5336 - iou_score: 0.0628 - val_loss: 1.4649 - val_dice_coef: 0.5488 - val_accuracy: 0.5789 - val_true_positive_rate: 0.4573 - val_iou_score: 0.0526\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 1.44776\n",
      "Epoch 178/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.1080 - dice_coef: 0.6441 - accuracy: 0.6697 - true_positive_rate: 0.5330 - iou_score: 0.0629 - val_loss: 1.4632 - val_dice_coef: 0.5463 - val_accuracy: 0.5755 - val_true_positive_rate: 0.4538 - val_iou_score: 0.0526\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 1.44776\n",
      "Epoch 179/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.0860 - dice_coef: 0.6515 - accuracy: 0.6767 - true_positive_rate: 0.5407 - iou_score: 0.0643 - val_loss: 1.4553 - val_dice_coef: 0.5428 - val_accuracy: 0.5768 - val_true_positive_rate: 0.4480 - val_iou_score: 0.0529\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 1.44776\n",
      "Epoch 180/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.1003 - dice_coef: 0.6475 - accuracy: 0.6719 - true_positive_rate: 0.5379 - iou_score: 0.0639 - val_loss: 1.4487 - val_dice_coef: 0.5460 - val_accuracy: 0.5768 - val_true_positive_rate: 0.4554 - val_iou_score: 0.0529\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 1.44776\n",
      "Epoch 181/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.0924 - dice_coef: 0.6504 - accuracy: 0.6745 - true_positive_rate: 0.5409 - iou_score: 0.0643 - val_loss: 1.4530 - val_dice_coef: 0.5463 - val_accuracy: 0.5765 - val_true_positive_rate: 0.4557 - val_iou_score: 0.0532\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 1.44776\n",
      "Epoch 182/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.0833 - dice_coef: 0.6540 - accuracy: 0.6773 - true_positive_rate: 0.5446 - iou_score: 0.0643 - val_loss: 1.4604 - val_dice_coef: 0.5475 - val_accuracy: 0.5771 - val_true_positive_rate: 0.4556 - val_iou_score: 0.0526\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 1.44776\n",
      "Epoch 183/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.0864 - dice_coef: 0.6515 - accuracy: 0.6745 - true_positive_rate: 0.5430 - iou_score: 0.0649 - val_loss: 1.4665 - val_dice_coef: 0.5526 - val_accuracy: 0.5791 - val_true_positive_rate: 0.4638 - val_iou_score: 0.0532\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 1.44776\n",
      "Epoch 184/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.0767 - dice_coef: 0.6546 - accuracy: 0.6784 - true_positive_rate: 0.5459 - iou_score: 0.0649 - val_loss: 1.4532 - val_dice_coef: 0.5450 - val_accuracy: 0.5767 - val_true_positive_rate: 0.4530 - val_iou_score: 0.0521\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 1.44776\n",
      "Epoch 185/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.0757 - dice_coef: 0.6552 - accuracy: 0.6782 - true_positive_rate: 0.5473 - iou_score: 0.0652 - val_loss: 1.4521 - val_dice_coef: 0.5470 - val_accuracy: 0.5756 - val_true_positive_rate: 0.4575 - val_iou_score: 0.0533\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 1.44776\n",
      "Epoch 186/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "116/116 [==============================] - 28s 245ms/step - loss: 1.0749 - dice_coef: 0.6568 - accuracy: 0.6794 - true_positive_rate: 0.5492 - iou_score: 0.0653 - val_loss: 1.4646 - val_dice_coef: 0.5533 - val_accuracy: 0.5784 - val_true_positive_rate: 0.4649 - val_iou_score: 0.0537\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 1.44776\n"
     ]
    }
   ],
   "source": [
    "from segmentation_models.losses import bce_jaccard_loss\n",
    "from segmentation_models.metrics import precision, iou_score\n",
    "\n",
    "model.compile(optimizer=\"Adam\", loss='categorical_crossentropy', \n",
    "              metrics=[dice_coef, \n",
    "                       'accuracy', \n",
    "                       true_positive_rate, \n",
    "                       iou_score\n",
    "                      ])\n",
    "\n",
    "history = model.fit(train, epochs=1000, verbose=1, validation_data=validation, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a74b300c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA5UElEQVR4nO3deXxcVfn48c+Tyb40bbZuSdt036ALsSxlp6wVCorQol9BUdSvKODXBRAV+ak/RdxQfigqbggV8YtWLYvsO3Qv3Ze0zdImzdJm32bm+f1xbtrJ1qZtJpNmnvfrNa/M3HvnzjM3yX3uOeeec0RVMcYYE71iIh2AMcaYyLJEYIwxUc4SgTHGRDlLBMYYE+UsERhjTJSzRGCMMVHOEoGJCiIyTkRURGJ7se1NIvJGf8RlzEBgicAMOCKyW0RaRSSr0/I13sl8XIRCC40lVUTqReSZSMdizImyRGAGql3AkvYXInIKkBy5cLr4MNACXCwiI/rzg3tTqjHmWFgiMAPVn4CPh7y+Efhj6AYiki4ifxSRChHZIyL3iEiMt84nIg+ISKWIFAILu3nvb0Vkn4iUish3RMR3DPHdCPwSWA98rNO+zxaRt0TkoIgUi8hN3vIkEfmRF2uNiLzhLTtfREo67WO3iCzwnt8rIk+JyGMiUgvcJCLzRORt7zP2icgvRCQ+5P0zROQ/IlItIuUicreIjBCRRhHJDNlurnf84o7hu5tBxhKBGajeAYaIyDTvBL0YeKzTNj8H0oHxwHm4xPEJb92ngQ8Cc4AC4NpO7/094AcmettcAnyqN4GJyFjgfODP3uPjndY948WWDcwG1nqrHwBOA84CMoCvAsHefCawCHgKGOp9ZgC4A8gCzgQuAv7biyENeAF4FhjlfccXVbUMeAW4LmS//wUsVdW2XsZhBiNVtYc9BtQD2A0sAO4B/i9wGfAfIBZQYBzgA1qB6SHv+wzwivf8JeCzIesu8d4bCwzHVeskhaxfArzsPb8JeOMI8d0DrPWej8adlOd4r+8Cnu7mPTFAEzCrm3XnAyXdHQPv+b3Aa0c5Zre3f673Xdb0sN31wJvecx9QBsyL9O/cHpF9WF2jGcj+BLwG5NOpWgh3JRwH7AlZtgd3YgZ3JVzcaV27sd5794lI+7KYTtsfyceBXwOoaqmIvIqrKloD5AE7u3lPFpDYw7re6BCbiEwGfowr7STjEtwqb3VPMQD8A/iliOQDU4AaVX3vOGMyg4RVDZkBS1X34BqNrwD+t9PqSqANd1JvNwYo9Z7vw50QQ9e1K8aVCLJUdaj3GKKqM44Wk4icBUwC7hKRMhEpA04HbvAacYuBCd28tRJo7mFdAyEN4V5VWHanbToPE/wwsAWYpKpDgLuB9qxWjKsu60JVm4Ence0a/4VLtibKWSIwA93NwIWq2hC6UFUDuBPad0Ukzaub/xKH2xGeBL4oIrkiMgy4M+S9+4DngR+JyBARiRGRCSJyXi/iuRFXTTUdV/8/G5gJJAGX4+rvF4jIdSISKyKZIjJbVYPAo8CPRWSU15h9pogkANuARBFZ6DXa3gMkHCWONKAWqBeRqcDnQtb9CxgpIreLSIJ3fE4PWf9HXPXXVVgiMFgiMAOcqu5U1ZU9rP4C7mq6EHgDeBx3sgVXdfMcsA5YTdcSxceBeGATcADXEDvySLGISCKuofXnqloW8tiFO6HeqKpFuBLM/wDVuIbiWd4uvgy8D6zw1v0AiFHVGlxD729wJZoGoMNdRN34MnADUOd917+0r1DVOuBi4EpcG8B24IKQ9W/iGqlXe6UuE+VE1SamMSbaiMhLwOOq+ptIx2IizxKBMVFGRD6Aq97K80oPJspZ1ZAxUURE/oDrY3C7JQHTzkoExhgT5axEYIwxUS6sHcpE5DLgZ7gejL9R1e93Wv8TDt/NkAzkqOrQI+0zKytLx40b1/fBGmPMILZq1apKVe3cPwUIYyLwOsU8hLuNrQRYISLLVHVT+zaqekfI9l/AjflyROPGjWPlyp7uJjTGGNMdEenxVuFwVg3NA3aoaqGqtgJLcQNn9WQJ8EQY4zHGGNONcCaC0XQcH6WEw+PAdOD1Cs3HDRRmjDGmHw2UxuLFwFPesAFdiMgtIrJSRFZWVFT0c2jGGDO4hbOxuJSOg37lcnhAsM4WA5/vaUeq+gjwCEBBQUGX+13b2tooKSmhubn5+KM9SSQmJpKbm0tcnM0jYozpG+FMBCuASd5wt6W4k/0NnTfyBswaBrx9vB9UUlJCWloa48aNI2RY4UFHVamqqqKkpIT8/PxIh2OMGSTCVjWkqn7gVtzAX5uBJ1V1o4jcJyJXhWy6GDdD0nH3bGtubiYzM3NQJwEAESEzMzMqSj7GmP4T1n4EqrocWN5p2Tc7vb63Lz5rsCeBdtHyPY0x/cdmKDPGmAEoEFS2ldcRHxtDeU0zK3YfYMH0HGaMSu/zz7JE0Aeqqqq46KKLACgrK8Pn85Gd7Trwvffee8THx/f43pUrV/LHP/6RBx98sF9iNcYMDK9vr+D90ho+c+4EfDHCrsoGfv7idhpa/dx0Vj6/eHk7b+6oOrS9CGSkxlsiGKgyMzNZu3YtAPfeey+pqal8+ctfPrTe7/cTG9v9oS4oKKCgoKA/wjTGDBC7Kxv47J9W0dAaYOPeWoYkxvHkymLifTHEx8bw3MZy4mNj+PoV08gZksCQpDjmjhlGelJ47ha0RBAmN910E4mJiaxZs4b58+ezePFibrvtNpqbm0lKSuJ3v/sdU6ZM4ZVXXuGBBx7gX//6F/feey9FRUUUFhZSVFTE7bffzhe/+MVIfxVjzDFqbgvwrX9sJGdIAncsmMzKPQdY/v4+AIYkxvLC5v3E+mL43PnjePiVncT5hI+dPobPXziRBJ+Px98r4tzJWWG5+u/OoEsE3/7nRjbtre3TfU4fNYRvXXnUec27KCkp4a233sLn81FbW8vrr79ObGwsL7zwAnfffTd/+9vfurxny5YtvPzyy9TV1TFlyhQ+97nPWZ8BY04ixdWNfPmv63h3VzUAL2/dz8a9tSTExhDni6G+xU9cTAw/v2EOl84YwfmTsxk1NIm8jORD+/jc+RP6NeZBlwgGko985CP4fD4AampquPHGG9m+fTsiQltbW7fvWbhwIQkJCSQkJJCTk0N5eTm5ubn9GbYxpgf1LX7uf3YLBxrb+O/zJ1Db1Ma6koMEFQor6nm7sIri6iZiY4SfLZ5NVX0r312+metOy+ObV04nJSEWfyBIayBIcrw7/Z4+PjPC32oQJoLjuXIPl5SUlEPPv/GNb3DBBRfw9NNPs3v3bs4///xu35OQkHDouc/nw+/3hztMY6KeqnZ7a3Z9i59Vew6wp6qB3ZWN/GdzGSUHmkiK8/HPdXs7bJueFMfp+Rl8cn4+50/JIT/L/f/fcPoYEuN8h7aL9cUQ6xsoo/s4gy4RDFQ1NTWMHu3G3Pv9738f2WCMMYe8snU/t/9lLTedNY5bL5hIWW0ztU1+tpTV8r3lW6isbwEgKc7HlBFp/Pi62UzITuV/V5cwamgSZ47PJD42hqQ4HzExXZNJaBIYqCwR9JOvfvWr3HjjjXznO99h4cKFkQ7HmKjX0OKnsKKBWx9fgy9G+OkL2/nVq4U0tR0e+/LU3HR+dN0spo5IIyctoUOp4VPnjI9E2GFx0s1ZXFBQoJ0nptm8eTPTpk2LUET9L9q+rzFH09wW4Dv/3sQ5k7K5dMYIgkFl2bq9/PaNXYzPTuGM8ZkUVTeSn5XCwlNGctf/vs8yr2onKzWBZbfOZ+WeA7y9s4rpo4aQnRpPcnws8ydm4evmKv9kJCKrVLXbe9WtRGCMOel999+beeydIh57p4grThnBlrI6CisamJiTyitbK/jH2r3ECAQV7l22kaa2AJ+cn0/usCQunJrDqKFJXDU0iatmjYr0V4kISwTGmAFvZ0U9v3l9F58+J5/x2akEg8pTq0v439UlpCbE8cLmcj4xfxz+gPLXVcWcNnYYt14wkatnj8YfVEoPNpE7LInnN5bz+7d28alzxnPpjBGR/loDhiUCY8yAUd/iP9S7tt0b2yv5/OOrqWlq41/r93LDvDG8vHU/28rrGZ+dQnF1E5fNGMHdV0wjzhfDfYtmdKjLj4+RQ3fwLDx1JAtPHdnv32ugs0RgjIkIVSWoHKqDf7ewis/9eTU5aQn88eZ5bNlXx4MvbmflngNMzEnllx87jW//cyOPvF7I7Lyh/PT62Vw1a1SXO3VshN5jZ4nAGNPv9tc2c9PvVrCnqoGCcRkEVXmnsIrRQ5PYU9XIRT96lbpmP6OHJvGND07n+g/kkZoQy7+/eA71Lf6wjbkTrSwRGGP6XCCo/Pg/WxkxJJErThlJRX0LVfWtNLcFKK9t4devF1Je28yVp45iXclBEuN8fHhuLnddMY0d++u45+8buWrWKD559jgSYg/fh++LEUsCYWCJoA9ccMEF3HnnnVx66aWHlv30pz9l69atPPzww122P//883nggQds1FFz0mv1BwkElaR4H8GgUlTdyJiMZH7yn2089PJOAL7xj41d3peREs+fbj6d08YO67LutLEZPHPbOWGP3RxmiaAPLFmyhKVLl3ZIBEuXLuX++++PYFTGhEddcxsvbdnP85vKeXVrBYGg8ulzx/NOYRXv7aomLyOJ4uomri/I44bTx/DmzkpGD01ixJBEEuJ8ZKclMDwtYcANsxDNLBH0gWuvvZZ77rmH1tZW4uPj2b17N3v37uWJJ57gS1/6Ek1NTVx77bV8+9vfjnSoxvRKMKjUt/oZktixGqairoWrH3qT0oNNZKUmcOWskVQ3tPLgi9sZkhjLbRdN4s0dlYxKT+Lbi2aQGOdjVt7QyHwJ02uDLxE8cyeUvd+3+xxxClz+/R5XZ2RkMG/ePJ555hkWLVrE0qVLue6667j77rvJyMggEAhw0UUXsX79ek499dS+jc2YPuQPBFm6opjfvrGLXZUNzJ+YSVJcLOtLDrLw1JFs3ldLZX0Lf/zkPM6emHXojp21xQcZPTSJ7LQE7rh4coS/hTlWVjbrI+3VQ+CqhZYsWcKTTz7J3LlzmTNnDhs3bmTTpk0RjtKYrlSVHfvreHbDPhY99Cb3/H0DQ5Li+Mx54ymubmJreS2njE7nD2/t5p3Cav7vh07h3MnZHW7bnJ03lOy0hCN8ihnIBl+J4AhX7uG0aNEi7rjjDlavXk1jYyMZGRk88MADrFixgmHDhnHTTTfR3NwckdiMCdXqD/LWzkrqmv1MyE7l/ue28MrWCgCy0xJ4+KNzuWzmCESEuy4/PKbV5n217Klq4LKZ1iFrsBl8iSBCUlNTueCCC/jkJz/JkiVLqK2tJSUlhfT0dMrLy3nmmWd6nIPAmHDaVl7HG9srSY73sWL3Af6zqYza5sPzXCTGxXDn5VM5Y3wmU4ankRTf/bDJ00YOYdrIIf0VtulHlgj60JIlS7jmmmtYunQpU6dOZc6cOUydOpW8vDzmz58f6fDMIFbX3Mb7pTXMHTOMxDgfBxpaaWwLsLG0htuWrj00tPKQxFgunj6CK04ZQVZqAu+X1jB/YtahIRhMdAprIhCRy4CfAT7gN6rapd5GRK4D7gUUWKeqN4QzpnC6+uqrCR3Wu6cJaF555ZX+CcgMWlX1LaQkxLK/toUHnt/KsxvLaPUHGZWeyNyxw3h2Qxn+oPtbnDl6CL9YMhdfjDB8SGKHcXzsjh4DYUwEIuIDHgIuBkqAFSKyTFU3hWwzCbgLmK+qB0QkJ1zxGHMyK6tp5j+by7lwag5PrSzhpy9uI0YEAeJ8Mdwwbwxzxgzlt2/s4qUt+/nYGWOZMiKNtkCQD8/NJSXBCv+mZ+H865gH7FDVQgARWQosAkJvnfk08JCqHgBQ1f1hjMeYk8L+umae31jOB08dydDkeAor6vmv375H6cEmvuFtc9WsUYzLTKbFH+QT8/MZkZ4IwKLZo3ucf9eYnoQzEYwGikNelwCnd9pmMoCIvImrPrpXVZ/tvCMRuQW4BWDMmDHdfli0/PGfbDPKmWPzTmEVX3hiDRV1LfzgmS1MHzWE90trSIrz8dsbC9i8r5bRw5K4evboHv/eo+H/wPStSJcXY4FJwPlALvCaiJyiqgdDN1LVR4BHwE1V2XkniYmJVFVVkZmZOaj/CVSVqqoqEhMTIx2KOQ5tgSAvbCpHgYTYGGqb21i95yBby+o4c0ImZTXNPLmqmPzMFL579Uz+sW4vpQeauGbOaD59znjGZaVw0bThkf4aZhAKZyIoBfJCXud6y0KVAO+qahuwS0S24RLDimP5oNzcXEpKSqioqDiReE8KiYmJ5ObmRjoMc4wCQeVLT67jn948ue2S432Mz07hwZe24xPhU2fnc9uCyaQmxHKJzaBl+kk4E8EKYJKI5OMSwGKg8x1BfweWAL8TkSxcVVHhsX5QXFwc+fn5JxatMWGyaW8tP31hG89vKucrl07hwqk5tPiDpCXGkjcsmfjYGPbXNRMMcqiu35j+FLZEoKp+EbkVeA5X//+oqm4UkfuAlaq6zFt3iYhsAgLAV1S1KlwxGRNOqkpzW5CkeB81jW08+uYunt9UzuZ9tYc6bX32vAndvjcn7TgSQDAI/iaIT3HPy9ZB+hhIyex+++ZaiE2E2Pgj77exGorfg+YamHE1xPYwdERLHSSkHX5dXwHrHoe5N0LS0KPHX1cGB4tg6BhI60XpRxUGcdVvJMnJ1vhYUFCgK1eujHQYxhxS09jGgy9tZ/n7+yivbWb+xCw27a2lurGVD4zL4NIZI/jw3NEMjfVD0wHwN0PVTih8BYJtkJIDqTnQVA173nYn0cxJ0NYAgTZ3IvYlQGo2zLzWnXyL3oFnvgrlG2D61VBdCPvWuoBSctwJMzkLMvIhOdOdcHe96vYz4hSITwaJcY/YRLfPtBGwfzNs/w+o64DG0LFw+mdh2DhY+agb0HHc2XBgF5SugjFnwgc+BVmT4KmboWo75EyHa34FQT/seAFKVkLGeBg+wz0yxsPuN+Dpz0JrnfuckbNh4gKo3esS28hZLq74FMiaDCt+7T4/awqMmgXxqeBvcccna6I7rlufdd9j+HTImQE50yBzooupphRGzYEDu2HbMy5hZk0Ef6v7OWquO2bBoItn31oXtwahbD1s+ReMLoBLv+v2GwzAuqVu/3nzXCzbnoUt/4b0XMic4D5z9GkwaUHIH0up+/3GH6EDX3tSH5bfMaHWlEDqcPAd38Q8IrJKVbudBMUSgTHd8bdCS607iYZeharCzpcgcSikZrPrhUco3vQO8f56Ria2kRrTSlNLG74YISMljgRfDARa3VW2v6njZ8QmuhNzS83hZVmT3ZV23T6IiXP/9P6WwyfmhHR3cji4B9JGweRL4f2n3LKz73AxV3u1q/X73Ymv6YA7QU67Etqa3ck82OZOcsGA239LrfvMlGw49XqYdDG0NcEL34ZybzTfpAzIPwf2vOWSzcQLYeM/oKbIi20InPc1ePUHbn8AiEsSNSXQ1tjx+4+aC+f8j4t33VLYv9F9p5ZaaK3v9AsRmPlhqC+Hyu0utth4l8jqyyEmFsad45LP/k3QeISKhfi0wwmoXepwt89DcXfaftIC93tvqXfHuWoHbPq7W5841JWeUHeMmmsO/74ATl3sks2et9w+0kbCgm9DYyUc2OMSfWzi4e+y8yX3+41PgzkfO3zM3/s1XPY9l3iPgyUCYzoL+AE9fHXV2gCb/gGV29zV8/YX3AnalwDpowmkj2F53URya1Yxp23Nod0EVdjtG0NO9nBS0zMgrv1Kuz15iPuM5AyXVJKGQWwSpA2HvDMgLtGdnBsq3MkgNdu9ra3ZnSDa9xMMwL518PYv3Alr4gJ3wk5IdUkrxuceJyIYdJ/XufqlphQqt0LuPPd5nY/jvrVQuhryz4Wcqe7Evuctl3xyPwBDRrn4D+yG8o3u+IpAwc3u+4NLsIE2d3IPBtyJMBh0paTyDa7EMHpu93E3HXDHPDH98L7q97vEUrnDlUDSc2HvaneinniR+33XlLhjXPweFL7sfjfJmS6ZZE5yJZ+4JHf1HpvgkvlzX3fVXwAXfcslzpL3YMhoyC2A8Re4El9dmSvlvfET99Cg22b2Da7UsN/rTpUwxF0o+L0BKZMzXYltxodg9+uw8WkXj8TArCVw/l0wNK/rMegFSwQmulVud/9oOTNc8X3NY65apq3Bu7LPcVdizTXuyjIlByZcCCNmQu1eGiv3UL5zPfmBXTSSyPfbrqdK05maWMXwM29g0QVndphX1wxyO192J+dJF/du+9YG93fV3tbib4Fdr0P2lMMndVWXAH2dmm1bG10JLiXLVTedAEsEJrq01MO6J9wVXPkG2LzMLW+vEkgbBVMug9QR0FBB2b5i9jYIjTM/SjD3dMpqW9iwt4a6Zj85QxJ4/J0iAqo8fHUeZ00eyatFbWSnJTBzdDq+GDlyLMYMEEdKBJHuUGbM8WltdEXs0lWuaiBthLv7pKYY1j7urvDBnfzP/Ypbt/tNmHCBa3D1xdLqD/LD57bw6x27iI0R/PuU9i4sqQmxpCXGsq+mmdPzM/jhtbMYk5kMwILpEfrOxoSJJQIz8LU1uVsffXGuTvXdX8Ir33dX93Eprv69rsw1gIoPxp4F1z/m3QkSAzFutM2GGTewrbyOvRsraPEH+OWrO9lWXs/HzxzL3VdMY2tZHW2BIFmpCYzJSCYmRmhuC5AQGzOoe6wbY4nADDztDYe+OHj3V/D8Pe4kD66h1d8Eky6B+bfBmLPcid7f6koBaSO6vb3utW0VfPaxVTS2Hr6bY1R6Io/eVMCFU92wDd0NyZwYZ3X/ZvCzRGAGBlXXkPv2Q+7umNYGd7dH1XaYdKm7TbKtyd2Rkn+Ou3c+9Co9Nr7buynaAkGWv7+Przy1nonZqdy+YBJ5GcnEiDA2M9lO9MZgicBE2v7N7i6eHS9AxRbXcenU690te3vXwKnXwTlfPlS9cyTBoHKgsZWXt1bw9zWlVNa3sK+mmZqmNmaMGsJjN5/OsJSj9Ko1JgpZIjD9q63Z3cWzd43rlLP9efDFw5gz4Iz/dvdZ97LnpKqyvqSGZzaU8XZhFRtLaw7NypWflcKknFRm5Q7l4unDOXdydoeZuYwxh1kiMH3P3wJNB13PydLVrpNWfbnruVq2wXUSiktx9++f82U48/OuwbeXWvwB3t5ZxQPPb2VDaS2xMcLcMcO4+Zx8RgxJZNrIIZyen2ENvMb0kiUC07OA3/Xw1KA3Ps4O96je7Tpj+Vsh0OJO/P4W97yx2vXYJKR/ii/B9aRNG+k64cy+AfLP6/UAYoGg8teVxfz7/X3sqmxg78Emggq5w5L43jWnsPCUkaQnH9/4K8YYSwTRp6bU1cWDOxH7W6G2xF3BB9rcffgHdrshDw7scSf3zlJHuOEDYhNctU5sohvEzDcMsqe6Rt6ULNdrd+QsyJjQqzr+UNUNreyva+a9XdU8ubKYDaW1TMpJZe6YYXxobi6Th6dy8fTh1qPXmD5giWAwCbS5cVwqt7m7a1rq3UBfbU3u58Ei2PUaHa7WO0sb6UY9zJnmbtHMme5O9jE+18U9Y0LX8Wb6kD8Q5Gt/e5+/rS45tGx8dgo/Wzybq2aNsuoeY8LAEsHJoumgq5ZpPugGNgsGoGSFO+HXl7ufB3a7MVBC+RLcwFlxyW6EynO/4nrXineFHhPrBsNKznDPT3TgshNQ3dDKnX9bz/Obyvnk/HzmjBnK9FFDmJAdvsRjjLFEMDC1Nrp69qDf3VO//Tk3nEKgteu2qcPdI2c6TLvKXbVnTXbjpCemR/TE3lt7qhp4/N0iHntnD41tAb515XQ+Md9mnDOmv1giGChU3QBpax5zY+WEjouenAkFn3RD3CYNcw21waAblvcY7raJNH8gyLu7qtm8rxZfjDAmI5knVxbz3MZyfDHC5TNHcPuCSUzMSTv6zowxfcYSQaTV7oP1S2H9k26M8pg4Nz3gpEtc9U32VHe1f4yNrf2h1R/kG3/fwGnjhnFdQR4t/gAbSmvYX9uCCGSkJDBnzFDifDFU1bdw6+NreLuw44QhaYmxfPHCiXz0jLEMH2Lz9RoTCZYIIuFgsZt0YseLbpajoB/yToeFP3ITUgygq/zy2mbe3FFJVX0rV5w6kvd2VbH0vWIunzmC90tr+dvqEp5aXUJCbAwPv7KTLWUdZ37KSIlnfFYKW8vraPUH+d41p3DpjOG0BZRt5XXMyhtKepLd+mlMJNl8BP0lGHS9aVf8Gtb/xd2bn5gOsz/qpp47wUknektV8QeVOF8Mm/bW8uq2CnKHJTF8SCK+GOGU0enEx8bw7/X7+P1bu1ix+0CXfWSlJlBZ724r/cx543lhUzk7KxpIifdx36KZTB3pqnaKq5v41/q97K9rIT8zhf86cywzR6f3y/c0xnRk8xFEir8Vdr8GW5bD1uWuZ21skhtKYc7H3ETcfVTl09wWoKi6kfysFOJ8h/fZFgjy9JpSDja20twW5MmVxZTVNDN6WBJ7qhq77Cc/K4UZo4bwr/X7GJ+dwv9cPJkLpuYwJDGOZetKGZmexDVzRvP8pnKKqxv51Dn5XFeQx/3PbuELF07qcKKfMSqdy2aO6JPvZ4wJHysRhEN9hZundM2fXKNvXIqbJ3XqQlf3f4JVP6pKiz9IjAi1zW2s2nOA+/65idKDTSTF+ThrQiaXzBhOY2uApe8Vs7X8cHXN6fkZzB4zlMKKBmbnDeUjBblU1rVS3dBKVUMLP3txO4UVDXz+ggncsWAysb6B1zZhjDl2ViLoL00H4M0H3Rj6/iY3E9bMD8P489y9/MehocXPqj0HyB2WxIrd1Tz6xm52VzXQ4g922G5iTirfvWYm28rqeH5TOS9u2Q+4YRh+9V+nMX9iFi1tATJTE7p8Rk7a4UbaK04ZSVlNM3kZyccVrzHm5BPWRCAilwE/A3zAb1T1+53W3wT8ECj1Fv1CVX8TzpjCoqEKVv4W3voFtNS4k//5d0HWpOPepary6rYKvv70BkoPNh1afmpuOjeeNY6hyXEEg0pKQiy5w5I5d3LWoeEWvnXlDHZW1DMsJZ7MlPhDvXFTE47+647zxVgSMCbKhC0RiIgPeAi4GCgBVojIMlXd1GnTv6jqreGKI6xKVsLrP3YdvoJ+mLIQLrgbRsw85l2pKq9sreDZDWUkxsWwuugg75fWMD47hV9+bC61TW4i9fMmZx91mIWYGGHScLsX3xjTO+EsEcwDdqhqIYCILAUWAZ0TwcmnpR7+eRtseAqSMlzj76nXH1cC8AeC/Pv9fYduvRySGIuIMHxIAt+5eibXnpZrs2gZY8IqnIlgNFAc8roEOL2b7T4sIucC24A7VLW48wYicgtwC8CYMWPCEOoxOLAbnrgBKjbDeV+Ds77gRuI8Rs1tAZ5aVcIjrxVSVN3IxJxUHvjILBbNHtXhrh9jjAm3SDcW/xN4QlVbROQzwB+ACztvpKqPAI+Au2uof0MMUfgq/PVG1wfgo3+FiQuO6e0VdS1sKK1hddEBlq4opqKuhVl5Q/n6wmlcPG04MTE2sqYxpv+FMxGUAqGziedyuFEYAFUNHW/gN8D9YYznxBzYA3/+iBtrf/Gfe90BrKiqkSdWFLFs7d5Djb4icPbELH52/WzOnJBpQysbYyIqnIlgBTBJRPJxCWAxcEPoBiIyUlX3eS+vAjaHMZ4T89J33Bn8Y3+D9NFH3byyvoUHX9zO4+8WocB5k7P5xPxxnDI6nRmj03t1B48xxvSHsJ2NVNUvIrcCz+FuH31UVTeKyH3ASlVdBnxRRK4C/EA1cFO44jkh+9bB+0/C2XccNQkEg8rDr+7k4Vd20tQWYMm8PG69YBIj0m1ANWPMwBTWy1JVXQ4s77TsmyHP7wLuCmcMfeLt/+fGBZp/+xE3U1W+/c+N/OHtPSyYNpw7L5/KxBybVMUYM7BZ/URv7F0DY+e7Gb46Kayo50fPb+PVbRWMHprE1vI6Pn1OPndfMc3q/o0xJwVLBEfT1gRV22H6og6Ll63by29fL2RdSQ3J8T4unzmSouoGPnPeeO68bKolAWPMScMSwdHs3+xuFw3pLPbIazv53vItTB2RxlcuncJHCnI7jNdjjDEnE0sER1O+wf0cPpOSA41899+beWZDGQtPHclPrptNfKx1/jLGnNwsERxN2QaIS2F1/VA+/ujr+INBvnzJZD53/kR81gHMGDMIWCI4mvINNA6bwo2PriQzNZ7Hbj7dRuc0xgwqVq9xJKpo+Qaer85iSFIcT3z6DEsCxphBxxLBkdSUIM01rGwazU+un82oocc3uYwxxgxklgiOoHDTCgDGTf8A8/JPbHpJY4wZqCwR9EBVef7tNQAsXnBWhKMxxpjwsUTQg2c3lNFYvReA1MyjDzJnjDEnK0sE3Who8fO9ZzYzKaUeTcqA2PhIh2SMMWFjiaAb3/n3ZkoONDF/eABJGxHpcIwxJqwsEXTy0pZynniviFvOGU9GsBpSh0c6JGOMCStLBCGCQeX7z2xhQnYKX7pkMtSVg5UIjDGD3FETgYhcKSJRkTBe2FzOtvJ6vnDhJBJ8MVBfbiUCY8yg15sT/PXAdhG5X0SmhjugSFFVHnplJ3kZSXzw1JHQWA3BNisRGGMGvaMmAlX9GDAH2An8XkTeFpFbRCQt7NH1o7XFB1lXfJBbzp1ArC8G6svcCisRGGMGuV5V+ahqLfAUsBQYCVwDrBaRL4Qxtn71+vZKROCDp4x0C+q8RJA2MnJBGWNMP+hNG8FVIvI08AoQB8xT1cuBWcD/hDe8/vPWzkqmjxzCsBSvz0B9ufuZZiUCY8zg1pthqD8M/ERVXwtdqKqNInJzeMLqX02tAVbvOchN88cdXtheIki1NgJjzODWm0RwL7Cv/YWIJAHDVXW3qr4YrsD606o9B2gNBDlzQubhhfXlkDAE4m3YaWPM4NabNoK/AsGQ1wFv2aDx5s5KYmOEeeNCRhitK7OGYmNMVOhNIohV1db2F97zXg2+IyKXichWEdkhInceYbsPi4iKSEFv9tvX3tpZxey8oaQkhBSQ6q0zmTEmOvQmEVSIyFXtL0RkEVB5tDeJiA94CLgcmA4sEZHp3WyXBtwGvNvboPuSqrK1rJZZeUM7rrASgTEmSvQmEXwWuFtEikSkGPga8JlevG8esENVC71SxFJgUTfb/R/gB0BzL2PuUxV1LTS3BRmb2aktoH6/JQJjTFToTYeynap6Bu6qfpqqnqWqO3qx79FAccjrEm/ZISIyF8hT1X8faUdeB7aVIrKyoqKiFx/de3uqGwEYEzoXcWsDtDVAanaffpYxxgxEvblrCBFZCMwAEkUEAFW970Q+2Bu/6MfATUfbVlUfAR4BKCgo0BP53M6KqrpJBA1ezVdyVl9+lDHGDEi96VD2S9x4Q18ABPgIMLYX+y4F8kJe53rL2qUBM4FXRGQ3cAawrL8bjPdUNxIjkDssJBE0eokgxUoExpjBrzdtBGep6seBA6r6beBMYHIv3rcCmCQi+SISDywGlrWvVNUaVc1S1XGqOg54B7hKVVce87c4AUVVDYxMTyI+NuRQNFgiMMZEj94kgvZG3EYRGQW04cYbOiJV9QO3As8Bm4EnVXWjiNwXehdSpBVVN3ZtKG7w2iFSMru+wRhjBpnetBH8U0SGAj8EVgMK/Lo3O1fV5cDyTsu+2cO25/dmn32tqLqRBdM63R1kJQJjTBQ5YiLwGnRfVNWDwN9E5F9AoqrW9Edw4Vbf4qeyvpUx3ZUI4pIhPiUygRljTD86YtWQqgZxncLaX7cMliQAUOzdOjo2o9MJv6HS7hgyxkSN3rQRvOgNASFhj6af7fFuHe3SRtBYCSmWCIwx0aE3ieAzuEHmWkSkVkTqRKQ2zHH1i6LqBgDyMrqpGrL2AWNMlDhqY7GqDqopKUPtq2kmNSGW9KS4jisaKmH4zMgEZYwx/eyoiUBEzu1ueeeJak5G1Q2tZKZ2GkhV1SUCqxoyxkSJ3tw++pWQ54m4weRWAReGJaJ+VN3QSkZKp0TQUgeBFqsaMsZEjd5UDV0Z+lpE8oCfhiug/lRZ38rooUkdF7Z3JrO7howxUaI3jcWdlQDT+jqQSKhuaCGzc4mgscr9tBKBMSZK9KaN4Oe43sTgEsdsXA/jk5qquqqhzm0Eh4aXsBKBMSY69KaNIHQQOD/whKq+GaZ4+k1ts5+2gHYtERwaXsISgTEmOvQmETwFNKtqANwUlCKSrKqN4Q0tvKob3DTMXe4asjYCY0yU6VXPYiC0RTUJeCE84fSfqvoWADJTEjquaKiE+DSIS4xAVMYY0/96kwgSVbW+/YX3PPkI258UqrwSQZfbRxv2Q2pOBCIyxpjI6E0iaPDmFgZARE4DmsIXUv+oqu+haqiu3CatN8ZEld60EdwO/FVE9uKmqhyBm7rypFbd4KqGupQI6sth+IwIRGSMMZHRmw5lK0RkKjDFW7RVVdvCG1b4VTW0kpYQS0Ksr+OK+nKYeFFkgjLGmAjozeT1nwdSVHWDqm4AUkXkv8MfWnhV1XfTh6C1EVpqrY3AGBNVetNG8GlvhjIAVPUA8OmwRdRPqhtau+lDsN/9TB3R/wEZY0yE9CYR+EInpRERHxB/hO1PCpX1LWR0vnW0rtz9tMZiY0wU6U0ieBb4i4hcJCIXAU8Az4Q3rPDrtkRQ354IrGrIGBM9enPX0NeAW4DPeq/X4+4cOmm1jzPU5dbR9kSQdlJ/PWOMOSZHLRF4E9i/C+zGzUVwIbA5vGGFV22TH39Qu791VGIgOTMygRljTAT0mAhEZLKIfEtEtgA/B4oAVPUCVf1Fb3YuIpeJyFYR2SEid3az/rMi8r6IrBWRN0Rk+vF+kWNR5fUh6LZEkJINMb5u3mWMMYPTkUoEW3BX/x9U1bNV9edAoLc79hqVHwIuB6YDS7o50T+uqqeo6mzgfuDHxxL88apv8QOQltBprmLrVWyMiUJHSgQfAvYBL4vIr72GYjnC9p3NA3aoaqGqtgJLgUWhG6hqbcjLFA7PexBWja0unyXHd9OZzBKBMSbK9JgIVPXvqroYmAq8jBtqIkdEHhaRS3qx79FAccjrEm9ZByLyeRHZiSsRfLG7HYnILSKyUkRWVlRU9OKjj6yx1ZUIkhM6tZVbIjDGRKHeNBY3qOrj3tzFucAa3J1EfUJVH1LVCd4+7+lhm0dUtUBVC7KzT3wKyW5LBMEg1O+HNEsExpjockxzFqvqAe+k3JvBeEqBvJDXud6yniwFrj6WeI5Xt4mgqRo0YCUCY0zUOZ7J63trBTBJRPJFJB5YDCwL3UBEJoW8XAhsD2M8hzR6jcXJ8SFVQ3Vl7qd1JjPGRJnedCg7LqrqF5FbgecAH/Coqm4UkfuAlaq6DLhVRBYAbcAB4MZwxROqsa2bEsH+Te5nxvj+CMEYYwaMsCUCAFVdDizvtOybIc9vC+fn96SpNUCMQEJsSIFo12uQmA7DZ0YiJGOMiZhwVg0NWA0tAZLjYwkZSw92vw5jz7bOZMaYqBOViaCpzU9SaLXQwWI4sBvyz4lYTMYYEylRmQgaWgKkhCaC3a+7n+MsERhjok9UJoLG1gBJoXcM7XodkjIgp1+GOjLGmAElKhNBU5u/Y4mg6G0YNx9iovJwGGOiXFSe+RpaAofbCIIBOFgEWZMjG5QxxkRIVCaCptbA4T4EdWWuR3F6bmSDMsaYCInKRNDQ6ielvY2gxhsXL31M5AIyxpgIispE0NQaUjVUU+J+WonAGBOlojIRNIZWDR0scj8tERhjolTUJYJgUGlqCxwecK6mBJKGQUJqZAMzxpgIibpE0NR5wLmaEisNGGOiWvQlgoqdZHMwJBEUW0OxMSaqRV0iSH9qCf8n7ncdq4asRGCMiWLRlQhqSog7uJOJUupKBE0HoaUWhuYd9a3GGDNYRVci2OUGl8uTCpLjY+zWUWOMIdoSwe43AEiQNtL9lSGJwEoExpjoFWWJ4DVa44cCMKSpJKRXsSUCY0z0ip5EcGAPHCyiKPdKANIai6FqJ8QmQkp2hIMzxpjIiZ5E4E0+s23klfg1hqSGYih5D0bNteGnjTFRLXrOgEkZMGUhpfETKdUsEqq3wr51MOb0SEdmjDERFT2JYOoVsORxGtuCFGkOsYUvQdAPeWdEOjJjjImo6EkEnsY2PyUyAgm0uAV58yIbkDHGRFhYE4GIXCYiW0Vkh4jc2c36L4nIJhFZLyIvisjYcMYD0NgSoNw3wr3ImgLJGeH+SGOMGdDClghExAc8BFwOTAeWiEjn2eHXAAWqeirwFHB/uOJp19gaoCJ2lHth7QPGGBPWEsE8YIeqFqpqK7AUWBS6gaq+rKqN3st3gLB38W1s9bMv3htkbuzZ4f44Y4wZ8GLDuO/RQHHI6xLgSJfgNwPPdLdCRG4BbgEYM+bERgptbA1wMCkfFr8Ao087oX0ZY8xgMCAai0XkY0AB8MPu1qvqI6paoKoF2dkn1vnr0DSVeR+w/gPGGEN4E0EpEDp2Q663rAMRWQB8HbhKVVvCGA/gJq4/NAS1McaYsCaCFcAkEckXkXhgMbAsdAMRmQP8CpcE9ocxlkOa2kImrjfGGBO+RKCqfuBW4DlgM/Ckqm4UkftE5Cpvsx8CqcBfRWStiCzrYXd9prk1QHKcJQJjjGkX1joSVV0OLO+07JshzxeE8/O702glAmOM6SDqWkubWgMkWYnAGGMOiapEEAwqLf4giZYIjDHmkKhKBM3+AIBVDRljTIioSgRNrS4RJFsiMMaYQ6IqETR6icCqhowx5rCoSgTNbV7VkCUCY4w5JKoSQZMlAmOM6SK6EoG1ERhjTBdRlQgavRJBoiUCY4w5JKoSQXOrVQ0ZY0xnUZUIrI3AGGO6ispEYG0ExhhzWHQlglZrIzDGmM6iMhFY1ZAxxhwWXYmgLUBsjBDni6qvbYwxRxRVZ0SbncwYY7qKqkTQ3GZzERhjTGdRlQgaW61EYIwxnUVVIrDZyYwxpqvoSgTWRmCMMV1EVSKwNgJjjOkqqhJBkyUCY4zpIqoSQWNrwHoVG2NMJ2FNBCJymYhsFZEdInJnN+vPFZHVIuIXkWvDGQu40UeTrURgjDEdhC0RiIgPeAi4HJgOLBGR6Z02KwJuAh4PVxyhrLHYGGO6ig3jvucBO1S1EEBElgKLgE3tG6jqbm9dMIxxHGJtBMYY01U4q4ZGA8Uhr0u8ZcdMRG4RkZUisrKiouK4ggkGlea2IImWCIwxpoOTorFYVR9R1QJVLcjOzj6ufTT7bS4CY4zpTjgTQSmQF/I611sWEYeGoLZEYIwxHYQzEawAJolIvojEA4uBZWH8vCNqn53MqoaMMaajsCUCVfUDtwLPAZuBJ1V1o4jcJyJXAYjIB0SkBPgI8CsR2RiueJptvmJjjOlWOO8aQlWXA8s7LftmyPMVuCqjsGtstTYCY4zpzknRWNwXbJpKY4zpXvQkgjabuN4YY7oTNYnA2giMMaZ7UZMIrI3AGGO6FzWJoMlKBMYY063oSQSt1kZgjDHdiZpEMCYjmctnjrASgTHGdBLWfgQDySUzRnDJjBGRDsMYYwacqCkRGGOM6Z4lAmOMiXKWCIwxJspZIjDGmChnicAYY6KcJQJjjIlylgiMMSbKWSIwxpgoJ6oa6RiOiYhUAHuO8+1ZQGUfhhMOJ0OMcHLEaTH2DYuxb0Q6xrGqmt3dipMuEZwIEVmpqgWRjuNIToYY4eSI02LsGxZj3xjIMVrVkDHGRDlLBMYYE+WiLRE8EukAeuFkiBFOjjgtxr5hMfaNARtjVLURGGOM6SraSgTGGGM6sURgjDFRLmoSgYhcJiJbRWSHiNwZ6XgARCRPRF4WkU0islFEbvOW3ysipSKy1ntcEeE4d4vI+14sK71lGSLyHxHZ7v0cFsH4poQcq7UiUisitw+E4ygij4rIfhHZELKs22MnzoPe3+h6EZkbwRh/KCJbvDieFpGh3vJxItIUckx/GcEYe/z9ishd3nHcKiKXRjDGv4TEt1tE1nrLI3Ice6Sqg/4B+ICdwHggHlgHTB8AcY0E5nrP04BtwHTgXuDLkY4vJM7dQFanZfcDd3rP7wR+EOk4Q37XZcDYgXAcgXOBucCGox074ArgGUCAM4B3IxjjJUCs9/wHITGOC90uwsex29+v9z+0DkgA8r3/fV8kYuy0/kfANyN5HHt6REuJYB6wQ1ULVbUVWAosinBMqOo+VV3tPa8DNgOjIxtVry0C/uA9/wNwdeRC6eAiYKeqHm/v8z6lqq8B1Z0W93TsFgF/VOcdYKiIjIxEjKr6vKr6vZfvALnhjuNIejiOPVkELFXVFlXdBezAnQPC6kgxiogA1wFPhDuO4xEtiWA0UBzyuoQBdsIVkXHAHOBdb9GtXrH80UhWu3gUeF5EVonILd6y4aq6z3teBgyPTGhdLKbjP9tAOo7tejp2A/Xv9JO4kkq7fBFZIyKvisg5kQrK093vdyAex3OAclXdHrJswBzHaEkEA5qIpAJ/A25X1VrgYWACMBvYhytSRtLZqjoXuBz4vIicG7pSXVk34vchi0g8cBXwV2/RQDuOXQyUY9cTEfk64Af+7C3aB4xR1TnAl4DHRWRIhMIb8L/fEEvoeIEykI5j1CSCUiAv5HWutyziRCQOlwT+rKr/C6Cq5aoaUNUg8Gv6oVh7JKpa6v3cDzztxVPeXm3h/dwfuQgPuRxYrarlMPCOY4iejt2A+jsVkZuADwIf9RIWXnVLlfd8Fa7+fXIk4jvC73egHcdY4EPAX9qXDaTjCNGTCFYAk0Qk37tqXAwsi3BM7fWGvwU2q+qPQ5aH1gtfA2zo/N7+IiIpIpLW/hzXiLgBd/xu9Da7EfhHZCLsoMNV10A6jp30dOyWAR/37h46A6gJqULqVyJyGfBV4CpVbQxZni0iPu/5eGASUBihGHv6/S4DFotIgojk42J8r7/jC7EA2KKqJe0LBtJxBKLjriHvYuYK3F05O4GvRzoeL6azcdUC64G13uMK4E/A+97yZcDICMY4HncHxjpgY/uxAzKBF4HtwAtARoSPZQpQBaSHLIv4ccQlpn1AG66u+uaejh3ubqGHvL/R94GCCMa4A1fP3v53+Utv2w97fwdrgdXAlRGMscffL/B17zhuBS6PVIze8t8Dn+20bUSOY08PG2LCGGOiXLRUDRljjOmBJQJjjIlylgiMMSbKWSIwxpgoZ4nAGGOinCUCYzoRkUCn0Uz7bLRab9TJgdKfwRgAYiMdgDEDUJOqzo50EMb0FysRGNNL3njy94ubm+E9EZnoLR8nIi95g5+9KCJjvOXDvbH813mPs7xd+UTk1+LmoHheRJIi9qWMwRKBMd1J6lQ1dH3IuhpVPQX4BfBTb9nPgT+o6qm4wdke9JY/CLyqqrNw49Rv9JZPAh5S1RnAQVwvU2MixnoWG9OJiNSramo3y3cDF6pqoTdYYJmqZopIJW54gzZv+T5VzRKRCiBXVVtC9jEO+I+qTvJefw2IU9Xv9MNXM6ZbViIw5thoD8+PRUvI8wDWVmcizBKBMcfm+pCfb3vP38KNaAvwUeB17/mLwOcARMQnIun9FaQxx8KuRIzpKql9knHPs6rafgvpMBFZj7uqX+It+wLwOxH5ClABfMJbfhvwiIjcjLvy/xxudEpjBhRrIzCml7w2ggJVrYx0LMb0JasaMsaYKGclAmOMiXJWIjDGmChnicAYY6KcJQJjjIlylgiMMSbKWSIwxpgo9/8Bc1jez039uCcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA13UlEQVR4nO3dd3xV9fnA8c+T3OwBWSSBAGFvZKQ4EAduxVFrVawTq9X219aqtdUObX/tr3ZZqx1q1aq17i2KG9yIAdkEgTASEjIhk8z7/P44B0hCggFyc5Oc5/163Vduvufce597Ave53y2qijHGGO8KCXYAxhhjgssSgTHGeJwlAmOM8ThLBMYY43GWCIwxxuMsERhjjMdZIjDmK4hIpoioiPg6ce6VIvJRd8RlTFexRGD6FBHZIiINIpLcpvwL98M8M0ihHVRCMaY7WSIwfdFmYO6eX0RkEhAdvHCM6dksEZi+6D/A5S1+vwJ4rOUJItJPRB4TkRIR2SoiPxeREPdYqIj8SURKRSQXOKudxz4kIoUisl1EfiMioYcTsIgMFJFXRKRcRDaKyDUtjs0QkWwRqRSRIhG5yy2PFJHHRaRMRHaJyOcikno4cRhvskRg+qLFQLyIjHM/oC8GHm9zzr1AP2A4cDxO4rjKPXYNMAeYCmQBF7R57CNAEzDSPedU4NuHGfNTQD4w0H29/xOR2e6xvwJ/VdV4YATwjFt+hfseBgNJwHXA7sOMw3iQJQLTV+2pFZwCrAO27znQIjncqqpVqroF+DNwmXvKhcDdqpqnquXA71o8NhU4E7hBVWtUtRj4i/t8h0REBgMzgZ+oap2qLgceZF+tphEYKSLJqlqtqotblCcBI1W1WVWXqmrlocZhvMsSgemr/gNcAlxJm2YhIBkIA7a2KNsKDHLvDwTy2hzbY6j72EK3OWYXcD8w4DBiHQiUq2pVB/FcDYwGctzmnzlu+X+AN4GnRKRARP4gImGHEYfxKEsEpk9S1a04ncZnAi+0OVyK8216aIuyIeyrNRTiNLe0PLZHHlAPJKtqf/cWr6oTDiPcAiBRROLai0dVN6jqXJxk83vgORGJUdVGVf2Vqo4HjsFpzrocYw6SJQLTl10NzFbVmpaFqtqM087+WxGJE5GhwI3s60d4BviBiGSISALw0xaPLQTeAv4sIvEiEiIiI0Tk+IOIK8Lt6I0UkUicD/xPgN+5ZZPd2B8HEJFLRSRFVf3ALvc5/CJyoohMcpu6KnGSm/8g4jAGsERg+jBV3aSq2R0c/j5QA+QCHwFPAA+7x/6F0+SyAljG/jWKy4FwYC2wE3gOSD+I0KpxOnX33GbjDHfNxKkdvAjcrqrvuOefDqwRkWqcjuOLVXU3kOa+diVOP8j7OM1FxhwUsY1pjDHG26xGYIwxHmeJwBhjPM4SgTHGeJwlAmOM8bhetwpicnKyZmZmBjsMY4zpVZYuXVqqqintHet1iSAzM5Ps7I5GBBpjjGmPiGzt6Jg1DRljjMdZIjDGGI+zRGCMMR7X6/oIjDHmYDU2NpKfn09dXV2wQwm4yMhIMjIyCAvr/EK0lgiMMX1efn4+cXFxZGZmIiLBDidgVJWysjLy8/MZNmxYpx9nTUPGmD6vrq6OpKSkPp0EAESEpKSkg675WCIwxnhCX08CexzK+/RMIli/o4o/vbme8pqGYIdijDE9imcSQW5JNX9buJGiyr7fWWSM6VnKysqYMmUKU6ZMIS0tjUGDBu39vaHhwF9Os7Oz+cEPfhDQ+DzTWRwVHgpAbUNzkCMxxnhNUlISy5cvB+COO+4gNjaWm2++ee/xpqYmfL72P46zsrLIysoKaHyeqRFEhzsXebclAmNMD3DllVdy3XXXceSRR3LLLbewZMkSjj76aKZOncoxxxzD+vXrAVi0aBFz5swBnCQyb948TjjhBIYPH84999zTJbF4pkYQvbdG0BTkSIwxwfSrV9ewtqCyS59z/MB4bj97wkE/Lj8/n08++YTQ0FAqKyv58MMP8fl8vPPOO9x22208//zz+z0mJyeHhQsXUlVVxZgxY7j++usPas5AezyYCKxGYIzpGb75zW8SGup8NlVUVHDFFVewYcMGRITGxsZ2H3PWWWcRERFBREQEAwYMoKioiIyMjMOKw0OJwHmrlgiM8bZD+eYeKDExMXvv/+IXv+DEE0/kxRdfZMuWLZxwwgntPiYiImLv/dDQUJqaDr+VwzN9BFHWNGSM6cEqKioYNGgQAI888ki3vrZnEsGepiHrLDbG9ES33HILt956K1OnTu2Sb/kHQ1S1W1/wcGVlZemhbkwz+mcLuHrWMH5y+tgujsoY05OtW7eOcePGBTuMbtPe+xWRpara7jhUz9QIwGkeqq23piFjjGnJU4kgOjzUOouNMaYN7yWCRksExhjTkscSgc86i40xpg3PzCNgx2qurXuY6oY4+OJLSBkLA6dCiKdyoTHG7Mc7iaA8l1Nr5xOh9fDyI07Zaf8HR38vqGEZY0yweefr8Phz+NHIBZwR9xx8f5lTI8h5PdhRGWM84MQTT+TNN99sVXb33Xdz/fXXt3v+CSecwKEOkz8UAUsEIhIpIktEZIWIrBGRX7VzzpUiUiIiy93btwMVDzh9BJWNoZA0AsacAXmLoa5rF58yxpi25s6dy1NPPdWq7KmnnmLu3LlBiqi1QNYI6oHZqnoEMAU4XUSOaue8p1V1int7MIDxEB0eSs2eJSZGngL+JshdFMiXNMYYLrjgAl577bW9m9Bs2bKFgoICnnzySbKyspgwYQK333570OILWB+BOlOWq91fw9xbUKcxR7WcRzB4BkTEw8a3Yfw5wQzLGNOdFvwUdqzq2udMmwRn3Nnh4cTERGbMmMGCBQs499xzeeqpp7jwwgu57bbbSExMpLm5mZNOOomVK1cyefLkro2tEwLaRyAioSKyHCgG3lbVz9o57RsislJEnhORwR08z7Uiki0i2SUlJYccT3SYj4YmP81+hdAwGH4CbHgHetkyG8aY3qdl89CeZqFnnnmGadOmMXXqVNasWcPatWuDEltARw2pajMwRUT6Ay+KyERVXd3ilFeBJ1W1XkS+AzwKzG7neR4AHgBnraFDjScmYt8KpHGRbiJY9wrs2gYJQw/1aY0xvckBvrkH0rnnnsuPfvQjli1bRm1tLYmJifzpT3/i888/JyEhgSuvvJK6uuDsqd4to4ZUdRewEDi9TXmZqta7vz4ITA9kHPvtW5w0wvm5a1sgX9YYY4iNjeXEE09k3rx5zJ07l8rKSmJiYujXrx9FRUUsWLAgaLEFctRQilsTQESigFOAnDbnpLf49RxgXaDigXZ2Kes/xPlpicAY0w3mzp3LihUrmDt3LkcccQRTp05l7NixXHLJJcycOTNocQWyaSgdeFREQnESzjOqOl9Efg1kq+orwA9E5BygCSgHrgxgPESF7dmlzB05FJ8BiCUCY0y3OO+882i59H9HG9AsWrSoewJyBXLU0Epgajvlv2xx/1bg1kDF0NaePoK96w35wiF+oCUCY4yneWdmMfuahmpaLjzXf4glAmOMp3kqEexpGtrdct9iSwTGeEJv243xUB3K+/RUItivsxicRFC5HZpt5zJj+qrIyEjKysr6fDJQVcrKyoiMjDyox3ln9VEOkAi02UkGNpfAmD4pIyOD/Px8DmdCam8RGRlJRkbGQT3GW4kgos2oIWg9hNQSgTF9UlhYGMOGDQt2GD2Wp5qGosI6qBGA9RMYYzzLU4kgNESI8IW03q7S5hIYYzzOU4kA3A3sWyYCm0tgjPE4DyYCX+tEANB/KOzcHJyAjDEmyDyYCEJbdxYDJI+E0i+DE5AxxgSZRxNBmxpB8hioLYOasuAEZYwxQeS5RBAVHtq6sxggZYzzs3R99wdkjDFB5rlEEBPu27dv8R7Jo52fJZYIjDHe47lEkBATzs6ahtaF/QZDWLT1ExhjPMlziSAlLoKS6vrWa46EhEDyKKsRGGM8yXuJIDaCxmalYndj6wPJY6xGYIzxJO8lgrgIAEqq6tscGA0VeVBfHYSojDEmeCwR7JHsjhwq29DNERljTHB5NxFUt60RuImgxJqHjDHe4t1E0LZGsGcV0oq8bo7IGGOCy3OJIC7CR4QvZP9EEBYFUQlQVRicwIwxJkg8lwhExBlC2jYRAMQNhMqC7g/KGGOCyHOJAPbNJdhPvCUCY4z3eDMRxHZQI4hPt6YhY4zneDMRHKhpqLoYmhv3P2aMMX2UZxNBeW0Djc3+1gfiBwIKVTuCEpcxxgSDZxOBKpS3XXwufqDz0/oJjDEe4s1EENvBXIK4dOdnlSUCY4x3BCwRiEikiCwRkRUiskZEftXOOREi8rSIbBSRz0QkM1DxtLRnUllxVV3rA3trBNZhbIzxjkDWCOqB2ap6BDAFOF1EjmpzztXATlUdCfwF+H0A49lrQHwk0E6NICoBfJFQub07wjDGmB4hYIlAHXuW8gxzb9rmtHOBR937zwEniYgEKqY9kmPDAdhR0SYRiDjNQzaE1BjjIQHtIxCRUBFZDhQDb6vqZ21OGQTkAahqE1ABJLXzPNeKSLaIZJeUlBx2XBG+UFLjI8jfWbv/wfhB1llsjPGUgCYCVW1W1SlABjBDRCYe4vM8oKpZqpqVkpLSJbENTogmr91EkG6JwBjjKd0yakhVdwELgdPbHNoODAYQER/QDyjrjpgGJ0aTV757/wPxA52mIW3bimWMMX1TIEcNpYhIf/d+FHAKkNPmtFeAK9z7FwDvqXbPJ/DghCgKK3bvP6ksLh2aG6C2vDvCMMaYoAtkjSAdWCgiK4HPcfoI5ovIr0XkHPech4AkEdkI3Aj8NIDxtJKRGI1foXBXmyGksanOz2qbXWyM8QZfoJ5YVVcCU9sp/2WL+3XANwMVw4FkJEQBkLezliFJ0fsO7J1UtgNSJwQhMmOM6V6enFkMTmcxQF55mw7jOLdGYOsNGWM8wrOJIL1fJKEhQv7ONh3GsWnOT2saMsZ4hGcTgS80hIH9I/cfQhoeDRHxUFUUnMCMMaabeTYRgDuXoG3TEDgdxlYjMMZ4hCWCtk1DAHFpViMwxniGpxNBRkIUJVX11DU2tz4Ql2brDRljPMPTiSAzOQaA3JKa1gdiU6G6yGYXG2M8wdOJYFx6HAA5OypbH4hLg6Y6qKsIQlTGGNO9PJ0IMpNiCPeFkLOjqvWBvUNIrZ/AGNP3eToR+EJDGJ0ay7rCdmoEYJPKjDGe4OlEADA2LX7/GoElAmOMh1giSIujpKqe0uoWu5XZwnPGGA/xfCIYlx4PwPqWtYKIOAiLtrkExhhP8HwiGJvmjBxq1U8gYrOLjTGe4flEkBQbQXJsRDv9BOnWR2CM8QTPJwKAiYPiWbZ1Z+vCuFRLBMYYT7BEABw3KoXc0hq2lrWYYRybZvMIjDGeYIkAmD12AAALc4r3FcalQkM11FcHKSpjjOkelghw1hwanhzDe+tL9hXa7GJjjEdYInCdOHYAi3PLqG1ocgr2TiqzVUiNMX2bJQLX7LEDaGjy88GXpU6BzS42xniEJQLX1zITGdQ/in8s2oiqtphdbE1Dxpi+zRKBK9wXwg0nj2JlfgVvrN4BUQkQGmE1AmNMn2eJoIXzp2UwakAsf3xrPU1+3bdBjTHG9GGWCFoIDRFuPm0MuSU1PL8s37asNMZ4giWCNk4dn8qUwf25+50NNMcMsIXnjDF9niWCNkSEn5w+lsKKOnKqY2zhOWNMn2eJoB1Hj0hi1qhkFhWEOPsWN+4OdkjGGBMwAUsEIjJYRBaKyFoRWSMiP2znnBNEpEJElru3XwYqnoN1w8mj2NLgLFFtHcbGmL7M15mTRCQG2K2qfhEZDYwFFqhq4wEe1gTcpKrLRCQOWCoib6vq2jbnfaiqcw4p+gCaPjSRd9OHQinUlW8nMiEz2CEZY0xAdLZG8AEQKSKDgLeAy4BHDvQAVS1U1WXu/SpgHTDo0EPtfnNmTgXgo2UrghyJMcYETmcTgahqLXA+8A9V/SYwobMvIiKZwFTgs3YOHy0iK0RkgYi0+5wicq2IZItIdklJSXunBMT4idNpJoQta7P3rUFkjDF9TKcTgYgcDXwLeM0tC+3kA2OB54EbVLWyzeFlwFBVPQK4F3ipvedQ1QdUNUtVs1JSUjoZchcIi6Sh/wgym3J5fPHW7ntdY4zpRp1NBDcAtwIvquoaERkOLPyqB4lIGE4S+K+qvtD2uKpWqmq1e/91IExEkjsbfHeIyjiCKeH5/HPRJvJ31gY7HGOM6XKdSgSq+r6qnqOqvxeREKBUVX9woMeIiAAPAetU9a4Ozklzz0NEZrjxlB3UOwi0tIkkN5cQ7a9i3iOfU1l3oP5xY4zpfTqVCETkCRGJd0cPrQbWisiPv+JhM3E6lWe3GB56pohcJyLXuedcAKwWkRXAPcDFqqqH+F4CI3USAPefEsnm0hrO+9vHfLKxNMhBGWNM1+ls09B4t33/PGABMAznQ75DqvqRqoqqTlbVKe7tdVW9T1Xvc8/5m6pOUNUjVPUoVf3kcN5MQKRNBGBiaB6PXDWDJr9yyYOf8fLy7UEOzBhjukZnE0GY295/HvCKO3+gZ31zD5TYVIhOhqJVzByZzFs/Oo6soQnc9sIqcktsP2NjTO/X2URwP7AFiAE+EJGhQNsRQH2TiFMr2LEagMiwUO6ZO5UwXwhX/HsJzy3Np6HJH+QgjTHm0HW2s/geVR2kqmeqYytwYoBj6znSj4DitVDpLEk9sH8UD1yWRXSYj5ufXcGpf3mfN9fsoKd1bxhjTGd0trO4n4jctWdSl4j8Gad24A1Z85yfC3+7t2jGsETeuGEWD16ehS80hO/8ZykXPbCYNQUVQQrSGGMOTWebhh4GqoAL3Vsl8O9ABdXjJGTCjGvhi8ehaM3eYhHh5PGpvPHDWfzmvIlsKq7mwvs+ZUNRVfBiNcaYg9TZRDBCVW9X1Vz39itgeCAD63Fm3QSR/eC5eVBd3OqQLzSES48ayvwfHEtUuI9rHsumotbmGxhjeofOJoLdInLsnl9EZCbgrUX6oxPhosdh1zZ45Kx2N7VP7xfF/ZdNY/uu3Vxw3ydsLq0JQqDGGHNwOpsIrgP+LiJbRGQL8DfgOwGLqqcaNgsufR4qC5xkUFmw3ynThyby6LwZlFbXc8ZfP+Ci+z/l2ey8IARrjDGd09lRQyvcheEmA5NVdSowO6CR9VRDj4FLX3D2Mn7wZFi/YL9TjhmRzKvfP5aLsgazs7aBHz+30iagGWN6LDnUIY8isk1Vh3RxPF8pKytLs7Ozu/tl91ewHF68DkrWwYAJMOoUOPYGiEpodVp9UzOXPbiE5Xm7OHfKQMakxXHxjCHERnRqTyBjjOkSIrJUVbPaPXYYiSBPVQcfVmSHoMckAoCmBlj6COS8Cls+hvhB8M1/Q0bra72zpoGbnl3B6u0VFFfVMyAugl/MGc/ZRwwMTtzGGM8JVCLwdo2grfxseO4qZ0TRRY87NYR2LNu2kzteWcPK/ArOnzqI/z1vIjFWOzDGBNiBEsEB+whEpEpEKtu5VQH2dbaljCy4ZhEkj4Yn58LnD4J//6Unpg1J4IXrj+GHJ43ipeXbueyhz6jYbUNNjTHBc8BEoKpxqhrfzi1OVe1rbFsxSXDFq5A5E167yRlZVPLlfqf5QkP40Smj+ce3prFqewUX3f8pawu8sXSTMabn6ezwUdNZUf3hspfg3L876xPdNxMW/g4a9592cfrEdB664muUVtdz9t8+4s4FOdQ1Nnd7yMYYbzvkPoJg6bF9BO2pLoE3fgqrn4P+Q+DYH8GkCyEittVpu2ob+L/X1/FMdj4ZCVFMG5LApEH9uGpmJr5Qy9XGmMMXkM7iYOlViWCPzR/CWz+HwuXOMhVHXg9HXe/UHlr4ZFMp9767kfxdteSV72bGsETunTuV1PjIoIRtjOk7LBH0BKqQ/zl8/FfImQ8xKXDa72DSBc6eB228sCyf215chS8khO/PHsmRw5MYOSDW5h8YYw6JJYKepmA5vHYjbF8K486Gs+9x1jJqY3NpDXe8sob3vywBoF9UGH/65hGcMj61mwM2xvR2lgh6In8zfPo3ePd/ITwGMo+FsWfBxAvAF773NFVlY3E1m0truOe9DazeXkliTDhRYaHMHjuAk8enMjYtzpqPjDEHZImgJyv4Aj67H7Z+7KxsGpcOc/4CY87Y79T6pmYe+mgzBbt2U1rVwML1xdS722SeNiGV35w3iZS4iO5+B8aYXsASQW+gCpvehXfugB2rYPpVMPUyGDSt3T4EgKq6RlZtr2Bxbjn3LdpEaIgwKjWWSF8oO2sb6BcVRnr/KNL7RZLeL5LBCdEcNzqFcJ+NRDLGaywR9CaNdfD2LyH7IfA3OesXjZ0D0y6DtEkdPmxDURWPL95KbmkNDU1+EqLD2bW7gcKKOgor6mhwaw6TM/px+9kTUFVGpMSSEBO+33NV1zdZp7QxfYwlgt6othy+fBPWvQob34HmesiY4eyfPGAs+CIheQyEfPW3e1WlvKaBjzeV8YuXVu9d0iI2wsd3jhvO8WNSSImLoLiynnvf28B7OcXcef5kLvxat68paIwJEEsEvV1tOax4ErIfhrKN+8rjB8HIkyBtMqROhNQJEBl/wKcqqqxjcW4ZMeE+ns7O4+21Ra2Ox0b4yEyOZk1BJXecPYG5M4YQ7gtBVXlrbREhIjZqyZheyBJBX6EKeUtgdznUlkHO604nc92ufeckZDpJIW2S8zNxmLO8RUyKM7u5TX/DltIa1hVWUl7bQHxkGEePSCI2wtl3+cMNpSTHhjN9aAI7axpZsqUcgGuPG05RZR1Lt+7kgcuyGD/wwMnHGBN8lgj6MlWo3A47VkPRKqejecdqKM8F2vxt4wfBtCuc5qWY5A47oQGa/cqHG0p4dmk+63dUsbuhmeuOH86q7RU8k51PVFgoMRGh+BUuzBrMsm07OW5UMpcfk0l8ZFhg37Mx5qBZIvCi+mooXgcVec48hV3bYMNbzg1AQp1mpKgE6D8UUsY6S2knDHNWUY1Odh7XJlmoKu9/WcL4gfHU1jdz0QOfUlJVz8gBsXxZVE18pI8fnDSK/tHhvJdTRGhICLERPuKjfJw6Po3pQxPaCdYYE2hBSQQiMhh4DEjF+Wr6gKr+tc05AvwVOBOoBa5U1WUHel5LBIepaI3T+VxX4dxqy2HnZihZD421rc+NTXPmM/QfAhFxMHQmDBjXKjlU1DbSrEpiTDirt1fw+zdy+HBDKQAD+0USERZKVV0jFbsbafIr82YO46zJ6YxLiycqPLQ737kxnhasRJAOpKvqMhGJA5YC56nq2hbnnAl8HycRHAn8VVWPPNDzWiIIkOYmZ//liu1QWwo1pVCwDDa83TpBRCfBgPFO/0PyKGfhvIh4ZzG9uHQ0Lp3svEpCxNmER9ykUVPfxG9fX8cTn20DIDIshJPGpnLDyaMYlRoXhDdsjLf0iKYhEXkZ+Juqvt2i7H5gkao+6f6+HjhBVQs7eh5LBN3M3wzNDU5i2PSes3Be8Vqn2altDQIgPA5Gn+Z0VodFQcbXIH3K3mGu23ftZs32Cj7aWMrLywsI94XwwvXHMDgxunvflzEeE/REICKZwAfARFWtbFE+H7hTVT9yf38X+ImqZrd5/LXAtQBDhgyZvnXr1oDHbL6C3w/VO6C+CuoqnWamynxn7+ac15yRTXuERTtLZ8SlQ2ImnHAb9BvEhqIqLrjvUxJjwnn0qhkMSbJkYEygBDURiEgs8D7wW1V9oc2xTiWClqxG0Av4/dBU5wxr3fyhsw9DVSFU7YDClU5/wyVPw8ApZG8pZ94jn6MKv5gznnOnDiTCZ30HxnS1oCUCEQkD5gNvqupd7Ry3piGvKVoLT1zoJIVjb4CZN5BXE8L3n/yC5Xm7SIwJ5+6LpnDc6JRgR2pMn3KgRBCw1cfcEUEPAevaSwKuV4DLxXEUUHGgJGD6gNTxcM1CmHg+fPBH+OMIBr/9HV64dBiPzZtBYkw4Nz27goraxmBHaoxnBHIZypnAZcBsEVnu3s4UketE5Dr3nNeBXGAj8C/guwGMx/QUsSlw/gPw7Xdh+pWw8V1CHjyJ4+IKufuiKZTXNPDr+WvpbXNcjOmtbEKZCb4dq+CJi5xO50ue5g85Sfxj0SYmDIznplNHM3usrW1kzOEKStOQMZ2WNgm+/Q7ED4THz+fmgav4wwWT8dXv5IePfMB3/pNNeU1DsKM0ps+yGoHpOWpK4cm5kL8E0iahRWupiBzI7KpfMXxQOv+95kgbUWTMIbIagekdYpLhqgUw++egINOvoH9dAa8NeZLsreXc+MwKNhRVWd+BMV3MtqEyPUuoD477sXMDSBxO+ls/5/Okrdy35mvMWXkKGSkJzJ0xhEuPGkpkmNUQjDlcViMwPdvR/wNn3UVK/3h+EfZflibcxqzQ1fzmtXVc81g2uxuagx2hMb2eJQLTs4nA166Ga96FK+YTGxPHHVW/5t8nNvDRxlIufuBTnluaT3V9U7AjNabXss5i07vUlsPDp0FVEbkZ5/Da1lCkbif10el8/ZyvMzzOD3FpkDg82JEa06MEfdG5rmSJwLArD166HrYvhcZaVEIQ9e893Cxh1F/6CtEjjglikMb0LAdKBNZZbHqf/oPhyvnOEtn1lUhEP8ry1/Peu2+wpky5svI+4v9zEW/MeIAzTznVOpSN+QpWIzB9Ts6qbAa/cC4xWs2XMozNx9zJSbNPxRdqXWLGu2wegfGUsZOyiLnpC3K/9ksSpJrjP7qUT+48B/8fRsCiO4MdnjE9jjUNmb4pdgDDz7oJPf4yyh69nCOKl7G+KZ1xi34HEgq+cAiNgEnfhJikYEdrTFBZ05DxhFV5u/j2I4u5s/FOTgz5Yt+B0HAYdw5MuxyGznQmtBnTB9moIWOA4qo6fv7M5/g3LWSFfzjHDgrhttTPSNn0ItRXQFQCTL4Ijrul/VrC1k9g5xaYckm3x27M4bJEYIxLVVmRX8Gnm8p46KPNlFbXM29GKrcM30rkpgWw+gWIiIUpl8Kok6G50dmXOT8bPrsPULjuY0ibGOy3YsxBsURgTDuq6hq56+0veeSTLSTHRnDU8CS+PqiCEwsfRta/Dv42u6RNvRTWvASjT4cLHgpKzMYcKptHYEw74iLDuP3sCZw5KZ2HPtzM55vLeXVFHWNSv80ZU77LMbGFZI3MICQqHqISnZ3VohLg07/DoGlQvBbGzoFRp0FICFSXwOb3YcLXIcTmLpjew2oExrj8fmX+qkL+9UEu63dU0dDs54iMftx+zgSmDUlwTqraAXdPguYG8EVB025IyIShx0LOq1BXAbNugpN+GdT3Ykxb1jRkzEFqavbz6soCfvd6DsVV9Zw/bRA/O3McSbERsPVTkBCnVrDmRVj1LGz5GAbPgKj+Ttn5D8LE853zmhvAFxHst2Q8zhKBMYeour6Jvy/cyEMfbiY+ysfcGUPYUFTNrNHJXDJjCCLinKjqrJTauNtZFK9wBUTEO53N/iZnpFHG12DnZpj4DUid0PqFmhqgoRqiE7v/TRpPsERgzGHK2VHJjU+vYG1hJcmx4ZRWNzB3xhB+fNoYEmPCW59cXw0b3oQtH0FYtDPqaMWTTs0AnIlsJ/wERsx2FtBb9yp8+YazdtLlLzk1C2O6mCUCY7qA369U1TcRF+Hjj2+t55+LNuELEc6YlM5vvz6R+Miwjh9cXeL0H0TGwyvfdz7494hKgDFnwbZPnX2bs65yzh0x2xmh5HMTjSqsft7pp5hx7b5yYzrBEoExAZCzo5IXlm3n4Y82MyQpmn9+azpj0uK++oGqUJ4LO1Y5SWDPjOZdefDYObBzq1OTaKiCxBEw7w2nr+Gl7zo1DYDUSTDnLqs9mE6zRGBMAH2WW8Z3/7uMyrpGrpo5jEH9o0iNj2DWqBRiIg5yhLa/2UkUAF8ugOevgZTRsHsXVBfByXdAvwx47Sbn99Gnwzn3QuwAp58hxOcMZTWmDUsExgRYWXU9/zt/LS8tL9hbFuEL4ewjBnLd8cMZOaATNYX25LwGT30LYlJg7lOQMd0pr6+GJffD+3+EmGQYcSKseNo5ljwaZlwDR1xso5XMXpYIjOkmFbWNNPr9bCiqZv7KAp5flk9Dk59rZg3nR6eMPrRNcvKznVpAXNr+xwq+gCcvgdpSmHyhM/Ft8/vOqKWUsfDNR6EkBza+DQ21Tv9CTTGMOxuO+q5Tk2hJFT5/0GmaGn26rczah1giMCZIyqrr+dNb63lySR4TBsbz2LwZzlyErlRXAc1N+z60VZ3O6Je/B7VlTll0ktMfETMAwqJg03tOv8OQo5xhrSljYfw5kP1veOtn7hOLUz7pG3DsTU6Tk6qTTCLjITyma9+HCaigJAIReRiYAxSr6n4rdInICcDLwGa36AVV/fVXPa8lAtMbvbO2iO89sYzBidEcPTwJvyoXZg3miMH9A/eiFdvhgz/AsONh/Lmtl70o3Qgrn3ISRnGOs65SdDLsLneWzTj2R7DxHdj8AWz5ECZd6Hzwr37BWak1JgXO+jNE9nf6KoYc7WwhCk6yULW+ih4mWIngOKAaeOwAieBmVZ1zMM9ricD0Vp9uKuN7Tyyj2a80NvupbWgmMyma8QPjGZ8ez7ShCRw9PGnfJLXu0twE+Z/D+7+Hpjr41nPOCqzgfKB/8EdY+Ftn/sPE8yH9CFj+X2fUU0u+KCfZNNZCeKyz5tKYM50mrZXPQGMNnPFHG/YaJEFrGhKRTGC+JQJjHKqKiFBV18jzS/NZnFvOuh2VbC2rBWBsWhzXHT+CsyanE9aT9lje9hkkDtvXp9DU4CylEZ3kLMa35WOoKgC/32l6qsiHda84SQGc0Uz+JphwPnzjwX21k6K18OK1MP48OO5mp6bSWAvpk1u/fnUxLLjFGWo77XLrBD8EPTkRPA/kAwU4SWHNVz2nJQLTF1XVNfLmmiLuf38TG4qrSYuPZFJGP6YPTWDezGGE+3pQUuishlqn03rnZmdy3Mpn4O1fOH0TvijIyILty6C53pl1PeIkyF0E2uzcD4ty+j+O+q5TKyn4AlCIG+g0XQ05ypm1nZG1LzGUfOl0jI87G/oPOfTYmxud2eBj5/SZZT96aiKIB/yqWi0iZwJ/VdVRHTzPtcC1AEOGDJm+devWgMVsTDD5/cqiL4t5+vM8cktq2FBczYSB8fzqnAlMH5rQ/c1GXW3Vc1C8Dup2ObWI6ET4+n1Os9QXj8OUb0HSCFj8T4js59Q8KrY5yePiJ8AX6Zy77dN9zxmTAiNPgcp82PwhoE4z1pHfgVk3QkMNrH0Fitc4z5eQ6fRrVOQ5o6Pi0pxO8ckXOZ3gAJ/cC2/93KmBXP4yhLqzxmvKOj+SqqbMqflE9e+663cYemQiaOfcLUCWqpYe6DyrERgveXPNDm59YRXlNQ0MT45hdGocIwfEcuTwRI4cltQ7awrtUYXKAug3qHV5U70zkikuDSact+/cvCXOh7kILPsPFC53zhl5stMxvvg+5xt9RJyzmJ/6nYThi3SaraL6Owmhsc553foKGHwkXPaiU8u4N8tp8irPhckXw7E3wOJ/wLLH4NgbnWXGt37s1Ggq8pznTZ3oLCiY9xks+p1zPCwGTr4dsq52Yl39vNO3EpMMmcdC+hSnfI/6aqdWlLsQBoyHaVc4s84bapzklDkLMmce0iXukYlARNKAIlVVEZkBPAcM1a8IyBKB8Zrq+ibmryhgweod5O2sZWtZLc1+ZWC/SK6eNZyTxg5gaFJ0768tdLUdq5wPz7h0mH6l08cBTq0gNGzfB7AqrH0JnpvnfPj6m6F8E3x3MSx/Aj78k/uE4izpkfeZ0zxV5U4ejOjndLI310N8hlMz6TfYmdCXn73vQz1ppNNvIqFO8xc4zVfjznFGZOVnOwsVNtc7NZrmekgeA6njYdtiqCp09tOe/TMORbBGDT0JnAAkA0XA7UAYgKreJyL/A1wPNAG7gRtV9ZOvel5LBMbrauqb+HhjKf/6MJfPt+wEYNSAWK6ZNZyCit3kle/m27OGMS49PsiR9jIrn4GP/uJ8u8+aB9Muc8rLNztDadMmObWG9/7X+daedTWMOcNp3lKFnPlOk9agaXDCrc6Hu6rTqb7wt1C2ySk/7maoLXfWjVr7Mmxa6CSG5DHODPHRpzvDcde/7tRCasucZDb7FzDkyEN+ezahzJg+amNxFZ9uKuPxxdtYX1SFCESFhVLX2MyMYYkM7B/FpUcN3bfDmgmO5ianKatt0xc4zUESAuHRAQ3BEoExfZzfr3yRt5OMhGgifaH8fdFGlm7dyaaSaip2N3Lh9MGcP20QWZmJhIZYE5IXWSIwxqOq65v481vr+e/ibTQ0+0mMCefkcQM4Y2I6kzL6UbirjszkaOIOtJeC6RMsERjjcdX1Tby/voQ31+zgvZxiquub9h5Ljg3nZ2eNY87kgT1rEpvpUpYIjDF71Tc18/HGUjaX1pIcG87DH21mRX4F8ZE+Tp2QxmVHDQ3sGkgmKCwRGGM61OxX3llXxNtri1iwqpCahmaOG53CD08aRf7OWhqblWNHJtPQ5KfR72dESmywQzaHwBKBMaZTquoaeXLJNu59dyNVLZqPWvrhSaO44eRRNm+hlzlQIjjIffSMMX1ZXGQY1x43gvOnZfBeTjHj0+MJEeHT3DJiI0JZsnknf313A+t3VPGzs8YxODGwQx5N97AagTGm01SV+z/I5e53vsTvhzlHpDM6NY4nPttGYkw4t54xlmZVVOGYEUFYUtt0yJqGjDFdqrBiN39fuJGXviigur6J6UMTyN9ZS1Fl/d5z5kxO57hRKeTsqGL60ASOH5NCbIQ1QgSLJQJjTEDU1Dexo7KOESmxVNc38eqKAtL6RbK2oJK73v6SZr/iCxGa/M7nTGp8BDOGJXHWpHROHZ9KiE1u6zaWCIwx3W5bWS31Tc0MS45hyZZylm7ZSW5pDe9/WUJ5TQMzRyZx6xnjiAwLJSMhisiw0K9+UnPILBEYY3qMpmY/T2fn8Zv569jd6KzCGeEL4cjhSfzwpFHsqm3g1/PXMiMzkRtPHU16v6ggR9w3WCIwxvQ4+TtrWbp1J35VVm+v5NUVBRRXOX0MQ5OiKdxVB8B5Uwdy3fEjGG7zFw6LJQJjTI9XU9/Egx9uptnv53uzR1JSVc/97+fy7NI8AG4+dQxlNQ1sK6/lkhlDbFTSQbJEYIzptYor67jp2RV8uKGU0BAhLtLHrtpGkmPDGZwYjV9hcEIU/3f+JOIjw2ho8vedndu6kE0oM8b0WgPiI3n0qhl8trmcESkxxEeF8fLy7Szbuov8XbWEiPDG6h1sLatlYP9I3lxTxKxRyVx97DBmjUpptex2Q5OfxblljEuPJyUuIojvqmexGoExptd7L6eI6x5fRnhoCHMmp/NuTjElVfWkxEUQHhpCSVU9Y9PjKKqso6iynv7RYdx+9nhPrbhqTUPGmD5vW1ktcZE+EmLCqW9q5r11xby2qhBfiJAUG8Gaggoiw0I5b8ogHvlkC8vzdpEQHcZVM4fxPyeO7PNzGiwRGGNMC03Nft7LKebZpfm8vbaI0yakUlXXxLJtO5mc0Z+mZj8biqo5ZXwq3z1xJCMH9P4RS5YIjDGmHarKfe/n8vs3ckiNj2D22AGsLagkNETITIrh9dWF1DX6GZMax5mT0jl/2qBeu9CeJQJjjDmArWU1pPeL2m+0UWl1PS99sZ231haxZHM5ACNSYkiJiyBnRxVDEqOZNSqZlfkV+FW57KihnDh2ABG+njdL2hKBMcYcprzyWuavLGRxbhm7ahsYmxbP6oIK1hRUMmpALLsbm8nfuRtfiDBhUD/uOHs8U4ckUN/UTHhoSNDnPFgiMMaYAKltaCI63EezX1m0vphl23by0hcFFFXWMWFgPKu2V5AaH8m0oQkMiItgYL8oRqbGMmtkMr5uHLFkicAYY7pRxe5Gfv3qWnJLq5mRmUj+zt2s2l5BeU0D1e7Ob6eOT+XOb0zm4Y8241flG9MzAroNqCUCY4zpIXbVNvBsdj6/fX0d4aEhNPr9hIjQ7FemDenPUcOT2FFZx5jUOC762mD6R4d3yetaIjDGmB7mqSXbeHl5AbecPoZBCVG89MV2nsnOZ1NJNcmxEZRU1eNzl9SIDAslKiyUS44cwrdnDT+k17NEYIwxvYCqOpv5hIawrrCS+SsLqKprYndDM7sbmzl5XCrnTR10SM9taw0ZY0wvICL4Qp3RRePS4xmXHt8trxuwLmsReVhEikVkdQfHRUTuEZGNIrJSRKYFKhZjjDEdC+TYpUeA0w9w/AxglHu7FvhnAGMxxhjTgYAlAlX9ACg/wCnnAo+pYzHQX0TSAxWPMcaY9gVz/dVBQF6L3/Pdsv2IyLUiki0i2SUlJd0SnDHGeEWvWIhbVR9Q1SxVzUpJSQl2OMYY06cEMxFsBwa3+D3DLTPGGNONgpkIXgEud0cPHQVUqGphEOMxxhhPCtg8AhF5EjgBSBaRfOB2IAxAVe8DXgfOBDYCtcBVgYrFGGNMx3rdzGIRKQG2HuLDk4HSLgwnUHpDnBZj17AYu4bF+NWGqmq7nay9LhEcDhHJ7miKdU/SG+K0GLuGxdg1LMbD0ytGDRljjAkcSwTGGONxXksEDwQ7gE7qDXFajF3DYuwaFuNh8FQfgTHGmP15rUZgjDGmDUsExhjjcZ5JBCJyuoisd/c/+Gmw4wEQkcEislBE1orIGhH5oVt+h4hsF5Hl7u3MIMe5RURWubFku2WJIvK2iGxwfyYEMb4xLa7VchGpFJEbesJ1bG9fjo6uXbD26Oggxj+KSI4bx4si0t8tzxSR3S2u6X1BjLHDv6+I3Opex/UicloQY3y6RXxbRGS5Wx6U69ghVe3zNyAU2AQMB8KBFcD4HhBXOjDNvR8HfAmMB+4Abg52fC3i3AIktyn7A/BT9/5Pgd8HO84Wf+sdwNCecB2B44BpwOqvunY4M+0XAAIcBXwWxBhPBXzu/d+3iDGz5XlBvo7t/n3d/0MrgAhgmPt/PzQYMbY5/mfgl8G8jh3dvFIjmAFsVNVcVW0AnsLZDyGoVLVQVZe596uAdXSwFHcPdC7wqHv/UeC84IXSyknAJlU91NnnXUrb35ejo2sXlD062otRVd9S1Sb318U4i0IGTQfXsSPnAk+par2qbsZZxmZGwIJzHShGERHgQuDJQMdxKLySCDq990GwiEgmMBX4zC36H7da/nAwm11cCrwlIktF5Fq3LFX3LRK4A0gNTmj7uZjW/9l60nXco6Nr11P/nc7DqansMUxEvhCR90VkVrCCcrX39+2J13EWUKSqG1qU9Zjr6JVE0KOJSCzwPHCDqlbibNs5ApgCFOJUKYPpWFWdhrO96PdE5LiWB9Wp6wZ9HLKIhAPnAM+6RT3tOu6np1y7jojIz4Am4L9uUSEwRFWnAjcCT4hI9+ywvr8e//dtYS6tv6D0pOvomUTQY/c+EJEwnCTwX1V9AUBVi1S1WVX9wL/ohmrtgajqdvdnMfCiG0/RnmYL92dx8CLc6wxgmaoWQc+7ji10dO161L9TEbkSmAN8y01YuM0tZe79pTjt76ODEd8B/r497Tr6gPOBp/eU9aTrCN5JBJ8Do0RkmPut8WKc/RCCym03fAhYp6p3tShv2S78dWB128d2FxGJEZG4PfdxOhFX41y/K9zTrgBeDk6ErbT61tWTrmMbHV27HrNHh4icDtwCnKOqtS3KU0Qk1L0/HBgF5AYpxo7+vq8AF4tIhIgMw4lxSXfH18LJQI6q5u8p6EnXEfDGqCH3y8yZOKNyNgE/C3Y8bkzH4jQLrASWu7czgf8Aq9zyV4D0IMY4HGcExgpgzZ5rByQB7wIbgHeAxCBfyxigDOjXoizo1xEnMRUCjTht1Vd3dO1wRgv93f03ugrICmKMG3Ha2ff8u7zPPfcb7r+D5cAy4Owgxtjh3xf4mXsd1wNnBCtGt/wR4Lo25wblOnZ0syUmjDHG47zSNGSMMaYDlgiMMcbjLBEYY4zHWSIwxhiPs0RgjDEeZ4nAmDZEpLnNaqZdtlqtu+pkT5nPYAwAvmAHYEwPtFtVpwQ7CGO6i9UIjOkkdz35P4izN8MSERnplmeKyHvu4mfvisgQtzzVXct/hXs7xn2qUBH5lzh7ULwlIlFBe1PGYInAmPZEtWkauqjFsQpVnQT8DbjbLbsXeFRVJ+MsznaPW34P8L6qHoGzTv0at3wU8HdVnQDswpllakzQ2MxiY9oQkWpVjW2nfAswW1Vz3cUCd6hqkoiU4ixv0OiWF6pqsoiUABmqWt/iOTKBt1V1lPv7T4AwVf1NN7w1Y9plNQJjDo52cP9g1Le434z11Zkgs0RgzMG5qMXPT937n+CsaAvwLeBD9/67wPUAIhIqIv26K0hjDoZ9EzFmf1F7Nhl3vaGqe4aQJojISpxv9XPdsu8D/xaRHwMlwFVu+Q+BB0Tkapxv/tfjrE5pTI9ifQTGdJLbR5ClqqXBjsWYrmRNQ8YY43FWIzDGGI+zGoExxnicJQJjjPE4SwTGGONxlgiMMcbjLBEYY4zH/T96ElDWQJ6B9AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_acc(history)\n",
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36f42960",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x1_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10532/831864409.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx1_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx2_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Test loss:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Test accuracy:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x1_test' is not defined"
     ]
    }
   ],
   "source": [
    "score = model.evaluate([x1_test,x2_test], y_test, verbose = 0) \n",
    "\n",
    "print('Test loss:', score[0]) \n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128f606e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Para pasar la segmentacion a imagen\n",
    "y_pred = model.predict([x1_test,x2_test])\n",
    "y_classes = [np.argmax(y, axis=-1) for y in y_pred]\n",
    "label = [np.argmax(y, axis=-1) for y in y_test]\n",
    "del y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef540bfe",
   "metadata": {},
   "source": [
    "# Fine tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50de00f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# release all layers for training\n",
    "# set all layers trainable and recompile model\n",
    "for layer in model.layers:\n",
    "    layer.trainable=True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb512b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# continue training\n",
    "history = model.fit(train, epochs=100, verbose=1, validation_data=validation, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9574a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate([x1_test,x2_test], y_test, verbose = 0) \n",
    "\n",
    "print('Test loss:', score[0]) \n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1207818f02c8e106e76b126192fd4af7c5708815ebe301344494fac4b3fd23ae"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
