{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9297a132",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e308ad1e",
   "metadata": {},
   "source": [
    "# Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c1c484b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dataset_sunrgbd/train_rgb\\\\0.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12412/2239561325.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mx1_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marchivo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m587\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dataset_sunrgbd/train_rgb'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marchivo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimsize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mx1_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   2966\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2967\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2968\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2969\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2970\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset_sunrgbd/train_rgb\\\\0.jpg'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage import transform\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import tensorflow as tf\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "\n",
    "imsize = (128,96)\n",
    "\n",
    "x1_train = []\n",
    "for archivo in range(587):\n",
    "    img = Image.open(os.path.join('dataset_sunrgbd/train_rgb',str(archivo)+'.jpg'))\n",
    "    img = cv2.resize(img_to_array(img), dsize=imsize)\n",
    "    x1_train.append(np.asarray(img))\n",
    "# x1_train = np.array(x1_train)\n",
    "# x1_train = x1_train/255.0\n",
    "# print(x1_train.shape)\n",
    "\n",
    "# x1_test = []\n",
    "for archivo in range(572):\n",
    "    img = Image.open(os.path.join('dataset_sunrgbd/test_rgb',str(archivo)+'.jpg'))\n",
    "    img = cv2.resize(img_to_array(img), dsize=imsize)\n",
    "    x1_train.append(np.asarray(img))\n",
    "x1_train = np.array(x1_train)\n",
    "x1_train = x1_train/255.0\n",
    "print(x1_train.shape)\n",
    "\n",
    "x2_train = []\n",
    "for archivo in range(587):\n",
    "    img = Image.open(os.path.join('dataset_sunrgbd/train_depth',str(archivo)+'.png'))\n",
    "    img = cv2.resize(cv2.cvtColor(img_to_array(img),cv2.COLOR_GRAY2RGB), dsize=imsize)\n",
    "#     img = cv2.cvtColor(img_to_array(img),cv2.COLOR_GRAY2RGB)\n",
    "    x2_train.append(np.asarray(img))\n",
    "# x2_train = np.array(x2_train)\n",
    "# x2_train = x2_train/26000.0\n",
    "# print(x2_train.shape)\n",
    "\n",
    "# x2_test = []\n",
    "for archivo in range(572):\n",
    "    img = Image.open(os.path.join('dataset_sunrgbd/test_depth',str(archivo)+'.png'))\n",
    "    img = cv2.resize(cv2.cvtColor(img_to_array(img),cv2.COLOR_GRAY2RGB), dsize=imsize)\n",
    "#     img = cv2.cvtColor(img_to_array(img),cv2.COLOR_GRAY2RGB)\n",
    "    x2_train.append(np.asarray(img))\n",
    "x2_train = np.array(x2_train)\n",
    "x2_train = x2_train/26000.0\n",
    "print(x2_train.shape)\n",
    "\n",
    "y_train = []\n",
    "for archivo in range(587):\n",
    "    img = np.load(os.path.join('dataset_sunrgbd/train_label',str(archivo)+'.npy'))\n",
    "    img = cv2.resize(img_to_array(img), dsize=imsize)\n",
    "    for i in range(0,img.shape[0]-1):\n",
    "        for j in range(0,img.shape[1]-1):\n",
    "            if img[i,j]%1 != 0:\n",
    "                img[i,j]=38\n",
    "    y_train.append(img)\n",
    "# y_train = np.array(y_train).astype('uint8')\n",
    "# y_train = tf.keras.utils.to_categorical(y_train, dtype='float32')\n",
    "# print(y_train.shape)\n",
    "\n",
    "# y_test = []\n",
    "for archivo in range(572):\n",
    "    img = np.load(os.path.join('dataset_sunrgbd/test_label',str(archivo)+'.npy'))\n",
    "    img = cv2.resize(img_to_array(img), dsize=imsize)\n",
    "    for i in range(0,img.shape[0]-1):\n",
    "        for j in range(0,img.shape[1]-1):\n",
    "            if img[i,j]%1 != 0:\n",
    "                img[i,j]=38\n",
    "    y_train.append(img)\n",
    "y_train = np.array(y_train).astype('uint8')\n",
    "y_train = tf.keras.utils.to_categorical(y_train, dtype='float32')\n",
    "y_train = y_train[:,:,:,:38]\n",
    "print(y_train.shape)\n",
    "\n",
    "del img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711bb80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = np.array(list(zip(x1_train[1:], x2_train[1:])))\n",
    "del x1_train, x2_train\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x,y_train[1:],test_size=0.3)\n",
    "del x\n",
    "\n",
    "x1_train, x2_train = x_train[:, 0], x_train[:, 1]\n",
    "del x_train\n",
    "\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_val,y_val,test_size=0.5)\n",
    "\n",
    "x1_test, x2_test = x_test[:, 0], x_test[:, 1]\n",
    "x1_val, x2_val = x_val[:, 0], x_val[:, 1]\n",
    "\n",
    "del x_test, x_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65a9c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_color(ax, color, title=\"Color\"):\n",
    "    \"\"\"Displays a color image from the NYU dataset.\"\"\"\n",
    "\n",
    "    ax.axis('off')\n",
    "    ax.set_title(title)\n",
    "    ax.imshow(color)\n",
    "\n",
    "def plot_depth(ax, depth, title=\"Depth\"):\n",
    "    \"\"\"Displays a depth map from the NYU dataset.\"\"\"\n",
    "\n",
    "    ax.axis('off')\n",
    "    ax.set_title(title)\n",
    "    ax.imshow(depth, cmap='Spectral')\n",
    "\n",
    "def plot_label(ax, labels, title=\"Label\"):\n",
    "    \"\"\"Displays a label map from the NYU dataset.\"\"\"\n",
    "\n",
    "    ax.axis('off')\n",
    "    ax.set_title(title)\n",
    "    ax.imshow(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d929fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(\"Labeled Dataset Sample\", figsize=(24, 10))\n",
    "\n",
    "for number in range(1):\n",
    "    fig = plt.figure(\"Labeled Dataset Sample\", figsize=(24, 10))\n",
    "    ax = fig.add_subplot(1, 3, 1)\n",
    "    plot_color(ax, x1_train[number])\n",
    "\n",
    "    ax = fig.add_subplot(1, 3, 2)\n",
    "    plot_depth(ax, x2_train[number])\n",
    "\n",
    "    ax = fig.add_subplot(1, 3, 3)\n",
    "    plot_label(ax, np.argmax(y_train[number],axis=-1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25458cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation_models import get_preprocessing\n",
    "\n",
    "BACKBONE = 'resnet34'\n",
    "preprocess_input = get_preprocessing(BACKBONE)\n",
    "\n",
    "\n",
    "x1_train = preprocess_input(x1_train)\n",
    "x2_train = preprocess_input(x2_train)\n",
    "x1_val = preprocess_input(x1_val)\n",
    "x2_val = preprocess_input(x2_val)\n",
    "x1_test = preprocess_input(x1_test)\n",
    "x2_test = preprocess_input(x2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c060103",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'seed'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12412/3530193858.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m train_datagen = ImageDataGenerator(\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mrotation_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mshear_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.02\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'seed'"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rotation_range=15,\n",
    "        shear_range=0.02,\n",
    "        zoom_range=[0.9, 1.25],\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        fill_mode=\"nearest\",\n",
    "        seed=42)\n",
    "val_datagen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d1c1636",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_datagen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12412/360489941.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_datagen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mval_datagen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_datagen' is not defined"
     ]
    }
   ],
   "source": [
    "train_datagen.fit(x1_train)\n",
    "val_datagen.fit(x1_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "977047ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_datagen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12412/331544524.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_datagen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx1_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx2_train\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mvalidation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval_datagen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx1_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx2_val\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_datagen' is not defined"
     ]
    }
   ],
   "source": [
    "train = train_datagen.flow([x1_train, x2_train], y_train, batch_size=8)\n",
    "validation = val_datagen.flow([x1_val, x2_val], y_val, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a23ec49",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a6affdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "data (InputLayer)               [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bn_data (BatchNormalization)    (None, None, None, 3 9           data[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, None, None, 3 0           bn_data[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv0 (Conv2D)                  (None, None, None, 6 9408        zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn0 (BatchNormalization)        (None, None, None, 6 256         conv0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu0 (Activation)              (None, None, None, 6 0           bn0[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, None, None, 6 0           relu0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pooling0 (MaxPooling2D)         (None, None, None, 6 0           zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn1 (BatchNormaliz (None, None, None, 6 256         pooling0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu1 (Activation) (None, None, None, 6 0           stage1_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, None, None, 6 0           stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv1 (Conv2D)     (None, None, None, 6 36864       zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn2 (BatchNormaliz (None, None, None, 6 256         stage1_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu2 (Activation) (None, None, None, 6 0           stage1_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, None, None, 6 0           stage1_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv2 (Conv2D)     (None, None, None, 6 36864       zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_sc (Conv2D)        (None, None, None, 6 4096        stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, None, None, 6 0           stage1_unit1_conv2[0][0]         \n",
      "                                                                 stage1_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn1 (BatchNormaliz (None, None, None, 6 256         add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu1 (Activation) (None, None, None, 6 0           stage1_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, None, None, 6 0           stage1_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv1 (Conv2D)     (None, None, None, 6 36864       zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn2 (BatchNormaliz (None, None, None, 6 256         stage1_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu2 (Activation) (None, None, None, 6 0           stage1_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPadding2D (None, None, None, 6 0           stage1_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv2 (Conv2D)     (None, None, None, 6 36864       zero_padding2d_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, None, None, 6 0           stage1_unit2_conv2[0][0]         \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_bn1 (BatchNormaliz (None, None, None, 6 256         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_relu1 (Activation) (None, None, None, 6 0           stage1_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPadding2D (None, None, None, 6 0           stage1_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_conv1 (Conv2D)     (None, None, None, 6 36864       zero_padding2d_6[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_bn2 (BatchNormaliz (None, None, None, 6 256         stage1_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_relu2 (Activation) (None, None, None, 6 0           stage1_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPadding2D (None, None, None, 6 0           stage1_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_conv2 (Conv2D)     (None, None, None, 6 36864       zero_padding2d_7[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, None, None, 6 0           stage1_unit3_conv2[0][0]         \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn1 (BatchNormaliz (None, None, None, 6 256         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu1 (Activation) (None, None, None, 6 0           stage2_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPadding2D (None, None, None, 6 0           stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv1 (Conv2D)     (None, None, None, 1 73728       zero_padding2d_8[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn2 (BatchNormaliz (None, None, None, 1 512         stage2_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu2 (Activation) (None, None, None, 1 0           stage2_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPadding2D (None, None, None, 1 0           stage2_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv2 (Conv2D)     (None, None, None, 1 147456      zero_padding2d_9[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_sc (Conv2D)        (None, None, None, 1 8192        stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, None, None, 1 0           stage2_unit1_conv2[0][0]         \n",
      "                                                                 stage2_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn1 (BatchNormaliz (None, None, None, 1 512         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu1 (Activation) (None, None, None, 1 0           stage2_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPadding2 (None, None, None, 1 0           stage2_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv1 (Conv2D)     (None, None, None, 1 147456      zero_padding2d_10[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn2 (BatchNormaliz (None, None, None, 1 512         stage2_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu2 (Activation) (None, None, None, 1 0           stage2_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPadding2 (None, None, None, 1 0           stage2_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv2 (Conv2D)     (None, None, None, 1 147456      zero_padding2d_11[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, None, None, 1 0           stage2_unit2_conv2[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_bn1 (BatchNormaliz (None, None, None, 1 512         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_relu1 (Activation) (None, None, None, 1 0           stage2_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPadding2 (None, None, None, 1 0           stage2_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_conv1 (Conv2D)     (None, None, None, 1 147456      zero_padding2d_12[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_bn2 (BatchNormaliz (None, None, None, 1 512         stage2_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_relu2 (Activation) (None, None, None, 1 0           stage2_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_13 (ZeroPadding2 (None, None, None, 1 0           stage2_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_conv2 (Conv2D)     (None, None, None, 1 147456      zero_padding2d_13[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, None, None, 1 0           stage2_unit3_conv2[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_bn1 (BatchNormaliz (None, None, None, 1 512         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_relu1 (Activation) (None, None, None, 1 0           stage2_unit4_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_14 (ZeroPadding2 (None, None, None, 1 0           stage2_unit4_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_conv1 (Conv2D)     (None, None, None, 1 147456      zero_padding2d_14[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_bn2 (BatchNormaliz (None, None, None, 1 512         stage2_unit4_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_relu2 (Activation) (None, None, None, 1 0           stage2_unit4_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_15 (ZeroPadding2 (None, None, None, 1 0           stage2_unit4_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_conv2 (Conv2D)     (None, None, None, 1 147456      zero_padding2d_15[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, None, None, 1 0           stage2_unit4_conv2[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn1 (BatchNormaliz (None, None, None, 1 512         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu1 (Activation) (None, None, None, 1 0           stage3_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_16 (ZeroPadding2 (None, None, None, 1 0           stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv1 (Conv2D)     (None, None, None, 2 294912      zero_padding2d_16[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn2 (BatchNormaliz (None, None, None, 2 1024        stage3_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu2 (Activation) (None, None, None, 2 0           stage3_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_17 (ZeroPadding2 (None, None, None, 2 0           stage3_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv2 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_17[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_sc (Conv2D)        (None, None, None, 2 32768       stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, None, None, 2 0           stage3_unit1_conv2[0][0]         \n",
      "                                                                 stage3_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn1 (BatchNormaliz (None, None, None, 2 1024        add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu1 (Activation) (None, None, None, 2 0           stage3_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_18 (ZeroPadding2 (None, None, None, 2 0           stage3_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv1 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_18[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn2 (BatchNormaliz (None, None, None, 2 1024        stage3_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu2 (Activation) (None, None, None, 2 0           stage3_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_19 (ZeroPadding2 (None, None, None, 2 0           stage3_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv2 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_19[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, None, None, 2 0           stage3_unit2_conv2[0][0]         \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_bn1 (BatchNormaliz (None, None, None, 2 1024        add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_relu1 (Activation) (None, None, None, 2 0           stage3_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_20 (ZeroPadding2 (None, None, None, 2 0           stage3_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_conv1 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_20[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_bn2 (BatchNormaliz (None, None, None, 2 1024        stage3_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_relu2 (Activation) (None, None, None, 2 0           stage3_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_21 (ZeroPadding2 (None, None, None, 2 0           stage3_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_conv2 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_21[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, None, None, 2 0           stage3_unit3_conv2[0][0]         \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_bn1 (BatchNormaliz (None, None, None, 2 1024        add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_relu1 (Activation) (None, None, None, 2 0           stage3_unit4_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_22 (ZeroPadding2 (None, None, None, 2 0           stage3_unit4_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_conv1 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_22[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_bn2 (BatchNormaliz (None, None, None, 2 1024        stage3_unit4_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_relu2 (Activation) (None, None, None, 2 0           stage3_unit4_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_23 (ZeroPadding2 (None, None, None, 2 0           stage3_unit4_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_conv2 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_23[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, None, None, 2 0           stage3_unit4_conv2[0][0]         \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_bn1 (BatchNormaliz (None, None, None, 2 1024        add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_relu1 (Activation) (None, None, None, 2 0           stage3_unit5_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_24 (ZeroPadding2 (None, None, None, 2 0           stage3_unit5_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_conv1 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_24[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_bn2 (BatchNormaliz (None, None, None, 2 1024        stage3_unit5_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_relu2 (Activation) (None, None, None, 2 0           stage3_unit5_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_25 (ZeroPadding2 (None, None, None, 2 0           stage3_unit5_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_conv2 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_25[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, None, None, 2 0           stage3_unit5_conv2[0][0]         \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_bn1 (BatchNormaliz (None, None, None, 2 1024        add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_relu1 (Activation) (None, None, None, 2 0           stage3_unit6_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_26 (ZeroPadding2 (None, None, None, 2 0           stage3_unit6_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_conv1 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_26[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_bn2 (BatchNormaliz (None, None, None, 2 1024        stage3_unit6_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_relu2 (Activation) (None, None, None, 2 0           stage3_unit6_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_27 (ZeroPadding2 (None, None, None, 2 0           stage3_unit6_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_conv2 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_27[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, None, None, 2 0           stage3_unit6_conv2[0][0]         \n",
      "                                                                 add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn1 (BatchNormaliz (None, None, None, 2 1024        add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu1 (Activation) (None, None, None, 2 0           stage4_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_28 (ZeroPadding2 (None, None, None, 2 0           stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv1 (Conv2D)     (None, None, None, 5 1179648     zero_padding2d_28[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn2 (BatchNormaliz (None, None, None, 5 2048        stage4_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu2 (Activation) (None, None, None, 5 0           stage4_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_29 (ZeroPadding2 (None, None, None, 5 0           stage4_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv2 (Conv2D)     (None, None, None, 5 2359296     zero_padding2d_29[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_sc (Conv2D)        (None, None, None, 5 131072      stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, None, None, 5 0           stage4_unit1_conv2[0][0]         \n",
      "                                                                 stage4_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn1 (BatchNormaliz (None, None, None, 5 2048        add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu1 (Activation) (None, None, None, 5 0           stage4_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_30 (ZeroPadding2 (None, None, None, 5 0           stage4_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv1 (Conv2D)     (None, None, None, 5 2359296     zero_padding2d_30[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn2 (BatchNormaliz (None, None, None, 5 2048        stage4_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu2 (Activation) (None, None, None, 5 0           stage4_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_31 (ZeroPadding2 (None, None, None, 5 0           stage4_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv2 (Conv2D)     (None, None, None, 5 2359296     zero_padding2d_31[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, None, None, 5 0           stage4_unit2_conv2[0][0]         \n",
      "                                                                 add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_bn1 (BatchNormaliz (None, None, None, 5 2048        add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_relu1 (Activation) (None, None, None, 5 0           stage4_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_32 (ZeroPadding2 (None, None, None, 5 0           stage4_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_conv1 (Conv2D)     (None, None, None, 5 2359296     zero_padding2d_32[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_bn2 (BatchNormaliz (None, None, None, 5 2048        stage4_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_relu2 (Activation) (None, None, None, 5 0           stage4_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_33 (ZeroPadding2 (None, None, None, 5 0           stage4_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_conv2 (Conv2D)     (None, None, None, 5 2359296     zero_padding2d_33[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, None, None, 5 0           stage4_unit3_conv2[0][0]         \n",
      "                                                                 add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bn1 (BatchNormalization)        (None, None, None, 5 2048        add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, None, None, 5 0           bn1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0_upsampling (UpSa (None, None, None, 5 0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0_concat (Concaten (None, None, None, 7 0           decoder_stage0_upsampling[0][0]  \n",
      "                                                                 stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0a_conv (Conv2D)   (None, None, None, 2 1769472     decoder_stage0_concat[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0a_bn (BatchNormal (None, None, None, 2 1024        decoder_stage0a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0a_relu (Activatio (None, None, None, 2 0           decoder_stage0a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0b_conv (Conv2D)   (None, None, None, 2 589824      decoder_stage0a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0b_bn (BatchNormal (None, None, None, 2 1024        decoder_stage0b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0b_relu (Activatio (None, None, None, 2 0           decoder_stage0b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1_upsampling (UpSa (None, None, None, 2 0           decoder_stage0b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1_concat (Concaten (None, None, None, 3 0           decoder_stage1_upsampling[0][0]  \n",
      "                                                                 stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1a_conv (Conv2D)   (None, None, None, 1 442368      decoder_stage1_concat[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1a_bn (BatchNormal (None, None, None, 1 512         decoder_stage1a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1a_relu (Activatio (None, None, None, 1 0           decoder_stage1a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1b_conv (Conv2D)   (None, None, None, 1 147456      decoder_stage1a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1b_bn (BatchNormal (None, None, None, 1 512         decoder_stage1b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1b_relu (Activatio (None, None, None, 1 0           decoder_stage1b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2_upsampling (UpSa (None, None, None, 1 0           decoder_stage1b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2_concat (Concaten (None, None, None, 1 0           decoder_stage2_upsampling[0][0]  \n",
      "                                                                 stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2a_conv (Conv2D)   (None, None, None, 6 110592      decoder_stage2_concat[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2a_bn (BatchNormal (None, None, None, 6 256         decoder_stage2a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2a_relu (Activatio (None, None, None, 6 0           decoder_stage2a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2b_conv (Conv2D)   (None, None, None, 6 36864       decoder_stage2a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2b_bn (BatchNormal (None, None, None, 6 256         decoder_stage2b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2b_relu (Activatio (None, None, None, 6 0           decoder_stage2b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3_upsampling (UpSa (None, None, None, 6 0           decoder_stage2b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3_concat (Concaten (None, None, None, 1 0           decoder_stage3_upsampling[0][0]  \n",
      "                                                                 relu0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3a_conv (Conv2D)   (None, None, None, 3 36864       decoder_stage3_concat[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3a_bn (BatchNormal (None, None, None, 3 128         decoder_stage3a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3a_relu (Activatio (None, None, None, 3 0           decoder_stage3a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3b_conv (Conv2D)   (None, None, None, 3 9216        decoder_stage3a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3b_bn (BatchNormal (None, None, None, 3 128         decoder_stage3b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3b_relu (Activatio (None, None, None, 3 0           decoder_stage3b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4_upsampling (UpSa (None, None, None, 3 0           decoder_stage3b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4a_conv (Conv2D)   (None, None, None, 1 4608        decoder_stage4_upsampling[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4a_bn (BatchNormal (None, None, None, 1 64          decoder_stage4a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4a_relu (Activatio (None, None, None, 1 0           decoder_stage4a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4b_conv (Conv2D)   (None, None, None, 1 2304        decoder_stage4a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4b_bn (BatchNormal (None, None, None, 1 64          decoder_stage4b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4b_relu (Activatio (None, None, None, 1 0           decoder_stage4b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "final_conv (Conv2D)             (None, None, None, 3 4350        decoder_stage4b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Activation)            (None, None, None, 3 0           final_conv[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 24,460,359\n",
      "Trainable params: 3,171,265\n",
      "Non-trainable params: 21,289,094\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from segmentation_models import Unet\n",
    "from segmentation_models.utils import set_trainable\n",
    "import segmentation_models as sm\n",
    "\n",
    "\n",
    "sm.set_framework('tf.keras')\n",
    "sm.framework()\n",
    "\n",
    "pretrained_model_1 = Unet(backbone_name='resnet34', encoder_weights='imagenet', encoder_freeze=True, classes=30, activation='softmax', input_shape=(None, None, 3))\n",
    "pretrained_model_1.summary()\n",
    "for layer in pretrained_model_1.layers:\n",
    "    layer._name += '_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "229a1c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "data (InputLayer)               [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bn_data (BatchNormalization)    (None, None, None, 3 9           data[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_34 (ZeroPadding2 (None, None, None, 3 0           bn_data[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv0 (Conv2D)                  (None, None, None, 6 9408        zero_padding2d_34[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "bn0 (BatchNormalization)        (None, None, None, 6 256         conv0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu0 (Activation)              (None, None, None, 6 0           bn0[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_35 (ZeroPadding2 (None, None, None, 6 0           relu0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pooling0 (MaxPooling2D)         (None, None, None, 6 0           zero_padding2d_35[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn1 (BatchNormaliz (None, None, None, 6 256         pooling0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu1 (Activation) (None, None, None, 6 0           stage1_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_36 (ZeroPadding2 (None, None, None, 6 0           stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv1 (Conv2D)     (None, None, None, 6 36864       zero_padding2d_36[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn2 (BatchNormaliz (None, None, None, 6 256         stage1_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu2 (Activation) (None, None, None, 6 0           stage1_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_37 (ZeroPadding2 (None, None, None, 6 0           stage1_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv2 (Conv2D)     (None, None, None, 6 36864       zero_padding2d_37[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_sc (Conv2D)        (None, None, None, 6 4096        stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, None, None, 6 0           stage1_unit1_conv2[0][0]         \n",
      "                                                                 stage1_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn1 (BatchNormaliz (None, None, None, 6 256         add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu1 (Activation) (None, None, None, 6 0           stage1_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_38 (ZeroPadding2 (None, None, None, 6 0           stage1_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv1 (Conv2D)     (None, None, None, 6 36864       zero_padding2d_38[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn2 (BatchNormaliz (None, None, None, 6 256         stage1_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu2 (Activation) (None, None, None, 6 0           stage1_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_39 (ZeroPadding2 (None, None, None, 6 0           stage1_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv2 (Conv2D)     (None, None, None, 6 36864       zero_padding2d_39[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, None, None, 6 0           stage1_unit2_conv2[0][0]         \n",
      "                                                                 add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_bn1 (BatchNormaliz (None, None, None, 6 256         add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_relu1 (Activation) (None, None, None, 6 0           stage1_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_40 (ZeroPadding2 (None, None, None, 6 0           stage1_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_conv1 (Conv2D)     (None, None, None, 6 36864       zero_padding2d_40[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_bn2 (BatchNormaliz (None, None, None, 6 256         stage1_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_relu2 (Activation) (None, None, None, 6 0           stage1_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_41 (ZeroPadding2 (None, None, None, 6 0           stage1_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_conv2 (Conv2D)     (None, None, None, 6 36864       zero_padding2d_41[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, None, None, 6 0           stage1_unit3_conv2[0][0]         \n",
      "                                                                 add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn1 (BatchNormaliz (None, None, None, 6 256         add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu1 (Activation) (None, None, None, 6 0           stage2_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_42 (ZeroPadding2 (None, None, None, 6 0           stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv1 (Conv2D)     (None, None, None, 1 73728       zero_padding2d_42[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn2 (BatchNormaliz (None, None, None, 1 512         stage2_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu2 (Activation) (None, None, None, 1 0           stage2_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_43 (ZeroPadding2 (None, None, None, 1 0           stage2_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv2 (Conv2D)     (None, None, None, 1 147456      zero_padding2d_43[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_sc (Conv2D)        (None, None, None, 1 8192        stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, None, None, 1 0           stage2_unit1_conv2[0][0]         \n",
      "                                                                 stage2_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn1 (BatchNormaliz (None, None, None, 1 512         add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu1 (Activation) (None, None, None, 1 0           stage2_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_44 (ZeroPadding2 (None, None, None, 1 0           stage2_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv1 (Conv2D)     (None, None, None, 1 147456      zero_padding2d_44[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn2 (BatchNormaliz (None, None, None, 1 512         stage2_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu2 (Activation) (None, None, None, 1 0           stage2_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_45 (ZeroPadding2 (None, None, None, 1 0           stage2_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv2 (Conv2D)     (None, None, None, 1 147456      zero_padding2d_45[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, None, None, 1 0           stage2_unit2_conv2[0][0]         \n",
      "                                                                 add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_bn1 (BatchNormaliz (None, None, None, 1 512         add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_relu1 (Activation) (None, None, None, 1 0           stage2_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_46 (ZeroPadding2 (None, None, None, 1 0           stage2_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_conv1 (Conv2D)     (None, None, None, 1 147456      zero_padding2d_46[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_bn2 (BatchNormaliz (None, None, None, 1 512         stage2_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_relu2 (Activation) (None, None, None, 1 0           stage2_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_47 (ZeroPadding2 (None, None, None, 1 0           stage2_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_conv2 (Conv2D)     (None, None, None, 1 147456      zero_padding2d_47[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, None, None, 1 0           stage2_unit3_conv2[0][0]         \n",
      "                                                                 add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_bn1 (BatchNormaliz (None, None, None, 1 512         add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_relu1 (Activation) (None, None, None, 1 0           stage2_unit4_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_48 (ZeroPadding2 (None, None, None, 1 0           stage2_unit4_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_conv1 (Conv2D)     (None, None, None, 1 147456      zero_padding2d_48[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_bn2 (BatchNormaliz (None, None, None, 1 512         stage2_unit4_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_relu2 (Activation) (None, None, None, 1 0           stage2_unit4_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_49 (ZeroPadding2 (None, None, None, 1 0           stage2_unit4_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_conv2 (Conv2D)     (None, None, None, 1 147456      zero_padding2d_49[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, None, None, 1 0           stage2_unit4_conv2[0][0]         \n",
      "                                                                 add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn1 (BatchNormaliz (None, None, None, 1 512         add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu1 (Activation) (None, None, None, 1 0           stage3_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_50 (ZeroPadding2 (None, None, None, 1 0           stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv1 (Conv2D)     (None, None, None, 2 294912      zero_padding2d_50[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn2 (BatchNormaliz (None, None, None, 2 1024        stage3_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu2 (Activation) (None, None, None, 2 0           stage3_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_51 (ZeroPadding2 (None, None, None, 2 0           stage3_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv2 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_51[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_sc (Conv2D)        (None, None, None, 2 32768       stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, None, None, 2 0           stage3_unit1_conv2[0][0]         \n",
      "                                                                 stage3_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn1 (BatchNormaliz (None, None, None, 2 1024        add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu1 (Activation) (None, None, None, 2 0           stage3_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_52 (ZeroPadding2 (None, None, None, 2 0           stage3_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv1 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_52[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn2 (BatchNormaliz (None, None, None, 2 1024        stage3_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu2 (Activation) (None, None, None, 2 0           stage3_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_53 (ZeroPadding2 (None, None, None, 2 0           stage3_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv2 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_53[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, None, None, 2 0           stage3_unit2_conv2[0][0]         \n",
      "                                                                 add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_bn1 (BatchNormaliz (None, None, None, 2 1024        add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_relu1 (Activation) (None, None, None, 2 0           stage3_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_54 (ZeroPadding2 (None, None, None, 2 0           stage3_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_conv1 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_54[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_bn2 (BatchNormaliz (None, None, None, 2 1024        stage3_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_relu2 (Activation) (None, None, None, 2 0           stage3_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_55 (ZeroPadding2 (None, None, None, 2 0           stage3_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_conv2 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_55[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, None, None, 2 0           stage3_unit3_conv2[0][0]         \n",
      "                                                                 add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_bn1 (BatchNormaliz (None, None, None, 2 1024        add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_relu1 (Activation) (None, None, None, 2 0           stage3_unit4_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_56 (ZeroPadding2 (None, None, None, 2 0           stage3_unit4_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_conv1 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_56[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_bn2 (BatchNormaliz (None, None, None, 2 1024        stage3_unit4_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_relu2 (Activation) (None, None, None, 2 0           stage3_unit4_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_57 (ZeroPadding2 (None, None, None, 2 0           stage3_unit4_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_conv2 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_57[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, None, None, 2 0           stage3_unit4_conv2[0][0]         \n",
      "                                                                 add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_bn1 (BatchNormaliz (None, None, None, 2 1024        add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_relu1 (Activation) (None, None, None, 2 0           stage3_unit5_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_58 (ZeroPadding2 (None, None, None, 2 0           stage3_unit5_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_conv1 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_58[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_bn2 (BatchNormaliz (None, None, None, 2 1024        stage3_unit5_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_relu2 (Activation) (None, None, None, 2 0           stage3_unit5_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_59 (ZeroPadding2 (None, None, None, 2 0           stage3_unit5_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_conv2 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_59[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, None, None, 2 0           stage3_unit5_conv2[0][0]         \n",
      "                                                                 add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_bn1 (BatchNormaliz (None, None, None, 2 1024        add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_relu1 (Activation) (None, None, None, 2 0           stage3_unit6_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_60 (ZeroPadding2 (None, None, None, 2 0           stage3_unit6_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_conv1 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_60[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_bn2 (BatchNormaliz (None, None, None, 2 1024        stage3_unit6_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_relu2 (Activation) (None, None, None, 2 0           stage3_unit6_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_61 (ZeroPadding2 (None, None, None, 2 0           stage3_unit6_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_conv2 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_61[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, None, None, 2 0           stage3_unit6_conv2[0][0]         \n",
      "                                                                 add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn1 (BatchNormaliz (None, None, None, 2 1024        add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu1 (Activation) (None, None, None, 2 0           stage4_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_62 (ZeroPadding2 (None, None, None, 2 0           stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv1 (Conv2D)     (None, None, None, 5 1179648     zero_padding2d_62[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn2 (BatchNormaliz (None, None, None, 5 2048        stage4_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu2 (Activation) (None, None, None, 5 0           stage4_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_63 (ZeroPadding2 (None, None, None, 5 0           stage4_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv2 (Conv2D)     (None, None, None, 5 2359296     zero_padding2d_63[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_sc (Conv2D)        (None, None, None, 5 131072      stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, None, None, 5 0           stage4_unit1_conv2[0][0]         \n",
      "                                                                 stage4_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn1 (BatchNormaliz (None, None, None, 5 2048        add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu1 (Activation) (None, None, None, 5 0           stage4_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_64 (ZeroPadding2 (None, None, None, 5 0           stage4_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv1 (Conv2D)     (None, None, None, 5 2359296     zero_padding2d_64[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn2 (BatchNormaliz (None, None, None, 5 2048        stage4_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu2 (Activation) (None, None, None, 5 0           stage4_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_65 (ZeroPadding2 (None, None, None, 5 0           stage4_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv2 (Conv2D)     (None, None, None, 5 2359296     zero_padding2d_65[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, None, None, 5 0           stage4_unit2_conv2[0][0]         \n",
      "                                                                 add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_bn1 (BatchNormaliz (None, None, None, 5 2048        add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_relu1 (Activation) (None, None, None, 5 0           stage4_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_66 (ZeroPadding2 (None, None, None, 5 0           stage4_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_conv1 (Conv2D)     (None, None, None, 5 2359296     zero_padding2d_66[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_bn2 (BatchNormaliz (None, None, None, 5 2048        stage4_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_relu2 (Activation) (None, None, None, 5 0           stage4_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_67 (ZeroPadding2 (None, None, None, 5 0           stage4_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_conv2 (Conv2D)     (None, None, None, 5 2359296     zero_padding2d_67[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, None, None, 5 0           stage4_unit3_conv2[0][0]         \n",
      "                                                                 add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bn1 (BatchNormalization)        (None, None, None, 5 2048        add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, None, None, 5 0           bn1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0_upsampling (UpSa (None, None, None, 5 0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0_concat (Concaten (None, None, None, 7 0           decoder_stage0_upsampling[0][0]  \n",
      "                                                                 stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0a_conv (Conv2D)   (None, None, None, 2 1769472     decoder_stage0_concat[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0a_bn (BatchNormal (None, None, None, 2 1024        decoder_stage0a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0a_relu (Activatio (None, None, None, 2 0           decoder_stage0a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0b_conv (Conv2D)   (None, None, None, 2 589824      decoder_stage0a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0b_bn (BatchNormal (None, None, None, 2 1024        decoder_stage0b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0b_relu (Activatio (None, None, None, 2 0           decoder_stage0b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1_upsampling (UpSa (None, None, None, 2 0           decoder_stage0b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1_concat (Concaten (None, None, None, 3 0           decoder_stage1_upsampling[0][0]  \n",
      "                                                                 stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1a_conv (Conv2D)   (None, None, None, 1 442368      decoder_stage1_concat[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1a_bn (BatchNormal (None, None, None, 1 512         decoder_stage1a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1a_relu (Activatio (None, None, None, 1 0           decoder_stage1a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1b_conv (Conv2D)   (None, None, None, 1 147456      decoder_stage1a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1b_bn (BatchNormal (None, None, None, 1 512         decoder_stage1b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1b_relu (Activatio (None, None, None, 1 0           decoder_stage1b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2_upsampling (UpSa (None, None, None, 1 0           decoder_stage1b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2_concat (Concaten (None, None, None, 1 0           decoder_stage2_upsampling[0][0]  \n",
      "                                                                 stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2a_conv (Conv2D)   (None, None, None, 6 110592      decoder_stage2_concat[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2a_bn (BatchNormal (None, None, None, 6 256         decoder_stage2a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2a_relu (Activatio (None, None, None, 6 0           decoder_stage2a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2b_conv (Conv2D)   (None, None, None, 6 36864       decoder_stage2a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2b_bn (BatchNormal (None, None, None, 6 256         decoder_stage2b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2b_relu (Activatio (None, None, None, 6 0           decoder_stage2b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3_upsampling (UpSa (None, None, None, 6 0           decoder_stage2b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3_concat (Concaten (None, None, None, 1 0           decoder_stage3_upsampling[0][0]  \n",
      "                                                                 relu0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3a_conv (Conv2D)   (None, None, None, 3 36864       decoder_stage3_concat[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3a_bn (BatchNormal (None, None, None, 3 128         decoder_stage3a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3a_relu (Activatio (None, None, None, 3 0           decoder_stage3a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3b_conv (Conv2D)   (None, None, None, 3 9216        decoder_stage3a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3b_bn (BatchNormal (None, None, None, 3 128         decoder_stage3b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3b_relu (Activatio (None, None, None, 3 0           decoder_stage3b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4_upsampling (UpSa (None, None, None, 3 0           decoder_stage3b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4a_conv (Conv2D)   (None, None, None, 1 4608        decoder_stage4_upsampling[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4a_bn (BatchNormal (None, None, None, 1 64          decoder_stage4a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4a_relu (Activatio (None, None, None, 1 0           decoder_stage4a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4b_conv (Conv2D)   (None, None, None, 1 2304        decoder_stage4a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4b_bn (BatchNormal (None, None, None, 1 64          decoder_stage4b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4b_relu (Activatio (None, None, None, 1 0           decoder_stage4b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "final_conv (Conv2D)             (None, None, None, 3 4350        decoder_stage4b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Activation)            (None, None, None, 3 0           final_conv[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 24,460,359\n",
      "Trainable params: 3,171,265\n",
      "Non-trainable params: 21,289,094\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pretrained_model_2 = Unet(backbone_name='resnet34', encoder_weights='imagenet', encoder_freeze=True, classes=30, activation='softmax', input_shape=(None, None, 3))\n",
    "pretrained_model_2.summary()\n",
    "for layer in pretrained_model_2.layers:\n",
    "    layer._name += '_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f4cd473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_1 layer output shape:  (None, None, None, 512)\n",
      "model_2 layer output shape:  (None, None, None, 512)\n"
     ]
    }
   ],
   "source": [
    "#last layers add_ and add_31 for 34,50 add_32 and add_65 for 101\n",
    "rgb_last = pretrained_model_1.get_layer('add_15_1')\n",
    "depth_last = pretrained_model_2.get_layer('add_31_2')\n",
    "print('model_1 layer output shape: ', rgb_last.output_shape)\n",
    "print('model_2 layer output shape: ', depth_last.output_shape)\n",
    "output_1 = rgb_last.output\n",
    "output_2 = depth_last.output\n",
    "\n",
    "# Middle layers unit6 for 34, 50 and unit23 for 101 relu2 for 34 and relu3 for 50, 101\n",
    "rgb_stage_1 = pretrained_model_1.get_layer('stage1_unit3_relu2_1') \n",
    "depth_stage_1 = pretrained_model_2.get_layer('stage1_unit3_relu2_2')\n",
    "rgb_stage_2 = pretrained_model_1.get_layer('stage2_unit4_relu2_1')\n",
    "depth_stage_2 = pretrained_model_2.get_layer('stage2_unit4_relu2_2')\n",
    "rgb_stage_3 = pretrained_model_1.get_layer('stage3_unit6_relu2_1')\n",
    "depth_stage_3 = pretrained_model_2.get_layer('stage3_unit6_relu2_2')\n",
    "rgb_stage_4 = pretrained_model_1.get_layer('stage4_unit3_relu2_1')\n",
    "depth_stage_4 = pretrained_model_2.get_layer('stage4_unit3_relu2_2')\n",
    "\n",
    "rgb_fusion_1 = rgb_stage_1.output\n",
    "depth_fusion_1 = depth_stage_1.output\n",
    "rgb_fusion_2 = rgb_stage_2.output\n",
    "depth_fusion_2 = depth_stage_2.output\n",
    "rgb_fusion_3 = rgb_stage_3.output\n",
    "depth_fusion_3 = depth_stage_3.output\n",
    "rgb_fusion_4 = rgb_stage_4.output\n",
    "depth_fusion_4 = depth_stage_4.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47e8e8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgbd_fusion(input_r,input_d,reshape_size,label):\n",
    "    r = tf.keras.layers.GlobalAveragePooling2D()(input_r)\n",
    "    r = tf.keras.layers.Reshape((1,1,reshape_size))(r)\n",
    "    r = tf.keras.layers.Conv2D(32,kernel_size=(1,1),strides=(1,1),activation='relu')(r)\n",
    "    r = tf.keras.layers.Conv2D(reshape_size,kernel_size=(1,1),strides=(1,1),activation='sigmoid')(r)\n",
    "    m_1 = tf.keras.layers.Multiply()([input_r,r])\n",
    "    \n",
    "    d = tf.keras.layers.GlobalAveragePooling2D()(input_d)\n",
    "    d = tf.keras.layers.Reshape((1,1,reshape_size))(d)\n",
    "    d = tf.keras.layers.Conv2D(32,kernel_size=(1,1),strides=(1,1),activation='relu')(d)\n",
    "    d = tf.keras.layers.Conv2D(reshape_size,kernel_size=(1,1),strides=(1,1),activation='sigmoid')(d)\n",
    "    m_2 = tf.keras.layers.Multiply()([input_d,d])\n",
    "    name = 'fusion' + label\n",
    "    last = tf.keras.layers.Add(name=name)([m_1,m_2])\n",
    "    \n",
    "    return last\n",
    "\n",
    "def decode_layer(input_de,input_ad,filters):\n",
    "    x = tf.keras.layers.UpSampling2D(size=(2,2), interpolation=\"nearest\")(input_de)\n",
    "    x = tf.keras.layers.Concatenate()([x,input_ad])\n",
    "    x = tf.keras.layers.Conv2D(filters,kernel_size=(3,3),activation='relu', padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.activations.relu(x)\n",
    "    x = tf.keras.layers.Conv2D(filters,kernel_size=(3,3),activation='relu', padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.activations.relu(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def last_decode_layer(input_de,filters):\n",
    "    x = tf.keras.layers.UpSampling2D(size=(2,2), interpolation=\"nearest\")(input_de)\n",
    "    x = tf.keras.layers.Conv2D(filters,kernel_size=(3,3),activation='relu', padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.activations.relu(x)\n",
    "    x = tf.keras.layers.Conv2D(filters,kernel_size=(3,3),activation='relu', padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.activations.relu(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fbcb7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None, None, 64)\n",
      "(None, None, None, 128)\n",
      "(None, None, None, 256)\n",
      "(None, None, None, 512)\n"
     ]
    }
   ],
   "source": [
    "print(rgb_fusion_1.shape)\n",
    "print(rgb_fusion_2.shape)\n",
    "print(rgb_fusion_3.shape)\n",
    "# print(rgb_fusion_4.shape)\n",
    "print(output_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c95ee02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None, None, 64)\n",
      "(None, None, None, 128)\n",
      "(None, None, None, 256)\n",
      "(None, None, None, 512)\n",
      "(None, None, None, 512)\n"
     ]
    }
   ],
   "source": [
    "fusion_1 = rgbd_fusion(rgb_fusion_1,depth_fusion_1,64,'_1')\n",
    "print(fusion_1.shape)\n",
    "fusion_2 = rgbd_fusion(rgb_fusion_2,depth_fusion_2,128,'_2')\n",
    "print(fusion_2.shape)\n",
    "fusion_3 = rgbd_fusion(rgb_fusion_3,depth_fusion_3,256,'_3')\n",
    "print(fusion_3.shape)\n",
    "fusion_4 = rgbd_fusion(rgb_fusion_4,depth_fusion_4,512,'_4')\n",
    "print(fusion_4.shape)\n",
    "fusion_last = rgbd_fusion(output_1, output_2,512,'_last') #512 for 34 and 2048 for 101\n",
    "print(fusion_last.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d1d1468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"myModel\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "data_1 (InputLayer)             [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "data_2 (InputLayer)             [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bn_data_1 (BatchNormalization)  (None, None, None, 3 9           data_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bn_data_2 (BatchNormalization)  (None, None, None, 3 9           data_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, None, None, 3 0           bn_data_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_34_2 (ZeroPaddin (None, None, None, 3 0           bn_data_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv0_1 (Conv2D)                (None, None, None, 6 9408        zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv0_2 (Conv2D)                (None, None, None, 6 9408        zero_padding2d_34_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bn0_1 (BatchNormalization)      (None, None, None, 6 256         conv0_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn0_2 (BatchNormalization)      (None, None, None, 6 256         conv0_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "relu0_1 (Activation)            (None, None, None, 6 0           bn0_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu0_2 (Activation)            (None, None, None, 6 0           bn0_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1_1 (ZeroPadding (None, None, None, 6 0           relu0_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_35_2 (ZeroPaddin (None, None, None, 6 0           relu0_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "pooling0_1 (MaxPooling2D)       (None, None, None, 6 0           zero_padding2d_1_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "pooling0_2 (MaxPooling2D)       (None, None, None, 6 0           zero_padding2d_35_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn1_1 (BatchNormal (None, None, None, 6 256         pooling0_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn1_2 (BatchNormal (None, None, None, 6 256         pooling0_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu1_1 (Activatio (None, None, None, 6 0           stage1_unit1_bn1_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu1_2 (Activatio (None, None, None, 6 0           stage1_unit1_bn1_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2_1 (ZeroPadding (None, None, None, 6 0           stage1_unit1_relu1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_36_2 (ZeroPaddin (None, None, None, 6 0           stage1_unit1_relu1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv1_1 (Conv2D)   (None, None, None, 6 36864       zero_padding2d_2_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv1_2 (Conv2D)   (None, None, None, 6 36864       zero_padding2d_36_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn2_1 (BatchNormal (None, None, None, 6 256         stage1_unit1_conv1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn2_2 (BatchNormal (None, None, None, 6 256         stage1_unit1_conv1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu2_1 (Activatio (None, None, None, 6 0           stage1_unit1_bn2_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu2_2 (Activatio (None, None, None, 6 0           stage1_unit1_bn2_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3_1 (ZeroPadding (None, None, None, 6 0           stage1_unit1_relu2_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_37_2 (ZeroPaddin (None, None, None, 6 0           stage1_unit1_relu2_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv2_1 (Conv2D)   (None, None, None, 6 36864       zero_padding2d_3_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_sc_1 (Conv2D)      (None, None, None, 6 4096        stage1_unit1_relu1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv2_2 (Conv2D)   (None, None, None, 6 36864       zero_padding2d_37_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_sc_2 (Conv2D)      (None, None, None, 6 4096        stage1_unit1_relu1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, None, None, 6 0           stage1_unit1_conv2_1[0][0]       \n",
      "                                                                 stage1_unit1_sc_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_16_2 (Add)                  (None, None, None, 6 0           stage1_unit1_conv2_2[0][0]       \n",
      "                                                                 stage1_unit1_sc_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn1_1 (BatchNormal (None, None, None, 6 256         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn1_2 (BatchNormal (None, None, None, 6 256         add_16_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu1_1 (Activatio (None, None, None, 6 0           stage1_unit2_bn1_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu1_2 (Activatio (None, None, None, 6 0           stage1_unit2_bn1_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4_1 (ZeroPadding (None, None, None, 6 0           stage1_unit2_relu1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_38_2 (ZeroPaddin (None, None, None, 6 0           stage1_unit2_relu1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv1_1 (Conv2D)   (None, None, None, 6 36864       zero_padding2d_4_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv1_2 (Conv2D)   (None, None, None, 6 36864       zero_padding2d_38_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn2_1 (BatchNormal (None, None, None, 6 256         stage1_unit2_conv1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn2_2 (BatchNormal (None, None, None, 6 256         stage1_unit2_conv1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu2_1 (Activatio (None, None, None, 6 0           stage1_unit2_bn2_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu2_2 (Activatio (None, None, None, 6 0           stage1_unit2_bn2_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_5_1 (ZeroPadding (None, None, None, 6 0           stage1_unit2_relu2_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_39_2 (ZeroPaddin (None, None, None, 6 0           stage1_unit2_relu2_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv2_1 (Conv2D)   (None, None, None, 6 36864       zero_padding2d_5_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv2_2 (Conv2D)   (None, None, None, 6 36864       zero_padding2d_39_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_1_1 (Add)                   (None, None, None, 6 0           stage1_unit2_conv2_1[0][0]       \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_17_2 (Add)                  (None, None, None, 6 0           stage1_unit2_conv2_2[0][0]       \n",
      "                                                                 add_16_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_bn1_1 (BatchNormal (None, None, None, 6 256         add_1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_bn1_2 (BatchNormal (None, None, None, 6 256         add_17_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_relu1_1 (Activatio (None, None, None, 6 0           stage1_unit3_bn1_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_relu1_2 (Activatio (None, None, None, 6 0           stage1_unit3_bn1_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_6_1 (ZeroPadding (None, None, None, 6 0           stage1_unit3_relu1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_40_2 (ZeroPaddin (None, None, None, 6 0           stage1_unit3_relu1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_conv1_1 (Conv2D)   (None, None, None, 6 36864       zero_padding2d_6_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_conv1_2 (Conv2D)   (None, None, None, 6 36864       zero_padding2d_40_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_bn2_1 (BatchNormal (None, None, None, 6 256         stage1_unit3_conv1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_bn2_2 (BatchNormal (None, None, None, 6 256         stage1_unit3_conv1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_relu2_1 (Activatio (None, None, None, 6 0           stage1_unit3_bn2_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_relu2_2 (Activatio (None, None, None, 6 0           stage1_unit3_bn2_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_7_1 (ZeroPadding (None, None, None, 6 0           stage1_unit3_relu2_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_41_2 (ZeroPaddin (None, None, None, 6 0           stage1_unit3_relu2_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_conv2_1 (Conv2D)   (None, None, None, 6 36864       zero_padding2d_7_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_conv2_2 (Conv2D)   (None, None, None, 6 36864       zero_padding2d_41_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_2_1 (Add)                   (None, None, None, 6 0           stage1_unit3_conv2_1[0][0]       \n",
      "                                                                 add_1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_18_2 (Add)                  (None, None, None, 6 0           stage1_unit3_conv2_2[0][0]       \n",
      "                                                                 add_17_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn1_1 (BatchNormal (None, None, None, 6 256         add_2_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn1_2 (BatchNormal (None, None, None, 6 256         add_18_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu1_1 (Activatio (None, None, None, 6 0           stage2_unit1_bn1_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu1_2 (Activatio (None, None, None, 6 0           stage2_unit1_bn1_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_8_1 (ZeroPadding (None, None, None, 6 0           stage2_unit1_relu1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_42_2 (ZeroPaddin (None, None, None, 6 0           stage2_unit1_relu1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv1_1 (Conv2D)   (None, None, None, 1 73728       zero_padding2d_8_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv1_2 (Conv2D)   (None, None, None, 1 73728       zero_padding2d_42_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn2_1 (BatchNormal (None, None, None, 1 512         stage2_unit1_conv1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn2_2 (BatchNormal (None, None, None, 1 512         stage2_unit1_conv1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu2_1 (Activatio (None, None, None, 1 0           stage2_unit1_bn2_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu2_2 (Activatio (None, None, None, 1 0           stage2_unit1_bn2_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_9_1 (ZeroPadding (None, None, None, 1 0           stage2_unit1_relu2_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_43_2 (ZeroPaddin (None, None, None, 1 0           stage2_unit1_relu2_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv2_1 (Conv2D)   (None, None, None, 1 147456      zero_padding2d_9_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_sc_1 (Conv2D)      (None, None, None, 1 8192        stage2_unit1_relu1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv2_2 (Conv2D)   (None, None, None, 1 147456      zero_padding2d_43_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_sc_2 (Conv2D)      (None, None, None, 1 8192        stage2_unit1_relu1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_3_1 (Add)                   (None, None, None, 1 0           stage2_unit1_conv2_1[0][0]       \n",
      "                                                                 stage2_unit1_sc_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_19_2 (Add)                  (None, None, None, 1 0           stage2_unit1_conv2_2[0][0]       \n",
      "                                                                 stage2_unit1_sc_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn1_1 (BatchNormal (None, None, None, 1 512         add_3_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn1_2 (BatchNormal (None, None, None, 1 512         add_19_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu1_1 (Activatio (None, None, None, 1 0           stage2_unit2_bn1_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu1_2 (Activatio (None, None, None, 1 0           stage2_unit2_bn1_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_10_1 (ZeroPaddin (None, None, None, 1 0           stage2_unit2_relu1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_44_2 (ZeroPaddin (None, None, None, 1 0           stage2_unit2_relu1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv1_1 (Conv2D)   (None, None, None, 1 147456      zero_padding2d_10_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv1_2 (Conv2D)   (None, None, None, 1 147456      zero_padding2d_44_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn2_1 (BatchNormal (None, None, None, 1 512         stage2_unit2_conv1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn2_2 (BatchNormal (None, None, None, 1 512         stage2_unit2_conv1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu2_1 (Activatio (None, None, None, 1 0           stage2_unit2_bn2_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu2_2 (Activatio (None, None, None, 1 0           stage2_unit2_bn2_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_11_1 (ZeroPaddin (None, None, None, 1 0           stage2_unit2_relu2_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_45_2 (ZeroPaddin (None, None, None, 1 0           stage2_unit2_relu2_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv2_1 (Conv2D)   (None, None, None, 1 147456      zero_padding2d_11_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv2_2 (Conv2D)   (None, None, None, 1 147456      zero_padding2d_45_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_4_1 (Add)                   (None, None, None, 1 0           stage2_unit2_conv2_1[0][0]       \n",
      "                                                                 add_3_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_20_2 (Add)                  (None, None, None, 1 0           stage2_unit2_conv2_2[0][0]       \n",
      "                                                                 add_19_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_bn1_1 (BatchNormal (None, None, None, 1 512         add_4_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_bn1_2 (BatchNormal (None, None, None, 1 512         add_20_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_relu1_1 (Activatio (None, None, None, 1 0           stage2_unit3_bn1_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_relu1_2 (Activatio (None, None, None, 1 0           stage2_unit3_bn1_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_12_1 (ZeroPaddin (None, None, None, 1 0           stage2_unit3_relu1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_46_2 (ZeroPaddin (None, None, None, 1 0           stage2_unit3_relu1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_conv1_1 (Conv2D)   (None, None, None, 1 147456      zero_padding2d_12_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_conv1_2 (Conv2D)   (None, None, None, 1 147456      zero_padding2d_46_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_bn2_1 (BatchNormal (None, None, None, 1 512         stage2_unit3_conv1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_bn2_2 (BatchNormal (None, None, None, 1 512         stage2_unit3_conv1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_relu2_1 (Activatio (None, None, None, 1 0           stage2_unit3_bn2_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_relu2_2 (Activatio (None, None, None, 1 0           stage2_unit3_bn2_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_13_1 (ZeroPaddin (None, None, None, 1 0           stage2_unit3_relu2_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_47_2 (ZeroPaddin (None, None, None, 1 0           stage2_unit3_relu2_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_conv2_1 (Conv2D)   (None, None, None, 1 147456      zero_padding2d_13_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_conv2_2 (Conv2D)   (None, None, None, 1 147456      zero_padding2d_47_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_5_1 (Add)                   (None, None, None, 1 0           stage2_unit3_conv2_1[0][0]       \n",
      "                                                                 add_4_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_21_2 (Add)                  (None, None, None, 1 0           stage2_unit3_conv2_2[0][0]       \n",
      "                                                                 add_20_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_bn1_1 (BatchNormal (None, None, None, 1 512         add_5_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_bn1_2 (BatchNormal (None, None, None, 1 512         add_21_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_relu1_1 (Activatio (None, None, None, 1 0           stage2_unit4_bn1_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_relu1_2 (Activatio (None, None, None, 1 0           stage2_unit4_bn1_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_14_1 (ZeroPaddin (None, None, None, 1 0           stage2_unit4_relu1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_48_2 (ZeroPaddin (None, None, None, 1 0           stage2_unit4_relu1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_conv1_1 (Conv2D)   (None, None, None, 1 147456      zero_padding2d_14_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_conv1_2 (Conv2D)   (None, None, None, 1 147456      zero_padding2d_48_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_bn2_1 (BatchNormal (None, None, None, 1 512         stage2_unit4_conv1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_bn2_2 (BatchNormal (None, None, None, 1 512         stage2_unit4_conv1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_relu2_1 (Activatio (None, None, None, 1 0           stage2_unit4_bn2_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_relu2_2 (Activatio (None, None, None, 1 0           stage2_unit4_bn2_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_15_1 (ZeroPaddin (None, None, None, 1 0           stage2_unit4_relu2_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_49_2 (ZeroPaddin (None, None, None, 1 0           stage2_unit4_relu2_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_conv2_1 (Conv2D)   (None, None, None, 1 147456      zero_padding2d_15_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_conv2_2 (Conv2D)   (None, None, None, 1 147456      zero_padding2d_49_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_6_1 (Add)                   (None, None, None, 1 0           stage2_unit4_conv2_1[0][0]       \n",
      "                                                                 add_5_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_22_2 (Add)                  (None, None, None, 1 0           stage2_unit4_conv2_2[0][0]       \n",
      "                                                                 add_21_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn1_1 (BatchNormal (None, None, None, 1 512         add_6_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn1_2 (BatchNormal (None, None, None, 1 512         add_22_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu1_1 (Activatio (None, None, None, 1 0           stage3_unit1_bn1_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu1_2 (Activatio (None, None, None, 1 0           stage3_unit1_bn1_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_16_1 (ZeroPaddin (None, None, None, 1 0           stage3_unit1_relu1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_50_2 (ZeroPaddin (None, None, None, 1 0           stage3_unit1_relu1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv1_1 (Conv2D)   (None, None, None, 2 294912      zero_padding2d_16_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv1_2 (Conv2D)   (None, None, None, 2 294912      zero_padding2d_50_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn2_1 (BatchNormal (None, None, None, 2 1024        stage3_unit1_conv1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn2_2 (BatchNormal (None, None, None, 2 1024        stage3_unit1_conv1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu2_1 (Activatio (None, None, None, 2 0           stage3_unit1_bn2_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu2_2 (Activatio (None, None, None, 2 0           stage3_unit1_bn2_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_17_1 (ZeroPaddin (None, None, None, 2 0           stage3_unit1_relu2_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_51_2 (ZeroPaddin (None, None, None, 2 0           stage3_unit1_relu2_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv2_1 (Conv2D)   (None, None, None, 2 589824      zero_padding2d_17_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_sc_1 (Conv2D)      (None, None, None, 2 32768       stage3_unit1_relu1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv2_2 (Conv2D)   (None, None, None, 2 589824      zero_padding2d_51_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_sc_2 (Conv2D)      (None, None, None, 2 32768       stage3_unit1_relu1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_7_1 (Add)                   (None, None, None, 2 0           stage3_unit1_conv2_1[0][0]       \n",
      "                                                                 stage3_unit1_sc_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_23_2 (Add)                  (None, None, None, 2 0           stage3_unit1_conv2_2[0][0]       \n",
      "                                                                 stage3_unit1_sc_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn1_1 (BatchNormal (None, None, None, 2 1024        add_7_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn1_2 (BatchNormal (None, None, None, 2 1024        add_23_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu1_1 (Activatio (None, None, None, 2 0           stage3_unit2_bn1_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu1_2 (Activatio (None, None, None, 2 0           stage3_unit2_bn1_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_18_1 (ZeroPaddin (None, None, None, 2 0           stage3_unit2_relu1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_52_2 (ZeroPaddin (None, None, None, 2 0           stage3_unit2_relu1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv1_1 (Conv2D)   (None, None, None, 2 589824      zero_padding2d_18_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv1_2 (Conv2D)   (None, None, None, 2 589824      zero_padding2d_52_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn2_1 (BatchNormal (None, None, None, 2 1024        stage3_unit2_conv1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn2_2 (BatchNormal (None, None, None, 2 1024        stage3_unit2_conv1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu2_1 (Activatio (None, None, None, 2 0           stage3_unit2_bn2_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu2_2 (Activatio (None, None, None, 2 0           stage3_unit2_bn2_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_19_1 (ZeroPaddin (None, None, None, 2 0           stage3_unit2_relu2_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_53_2 (ZeroPaddin (None, None, None, 2 0           stage3_unit2_relu2_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv2_1 (Conv2D)   (None, None, None, 2 589824      zero_padding2d_19_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv2_2 (Conv2D)   (None, None, None, 2 589824      zero_padding2d_53_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_8_1 (Add)                   (None, None, None, 2 0           stage3_unit2_conv2_1[0][0]       \n",
      "                                                                 add_7_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_24_2 (Add)                  (None, None, None, 2 0           stage3_unit2_conv2_2[0][0]       \n",
      "                                                                 add_23_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_bn1_1 (BatchNormal (None, None, None, 2 1024        add_8_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_bn1_2 (BatchNormal (None, None, None, 2 1024        add_24_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_relu1_1 (Activatio (None, None, None, 2 0           stage3_unit3_bn1_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_relu1_2 (Activatio (None, None, None, 2 0           stage3_unit3_bn1_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_20_1 (ZeroPaddin (None, None, None, 2 0           stage3_unit3_relu1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_54_2 (ZeroPaddin (None, None, None, 2 0           stage3_unit3_relu1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_conv1_1 (Conv2D)   (None, None, None, 2 589824      zero_padding2d_20_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_conv1_2 (Conv2D)   (None, None, None, 2 589824      zero_padding2d_54_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_bn2_1 (BatchNormal (None, None, None, 2 1024        stage3_unit3_conv1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_bn2_2 (BatchNormal (None, None, None, 2 1024        stage3_unit3_conv1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_relu2_1 (Activatio (None, None, None, 2 0           stage3_unit3_bn2_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_relu2_2 (Activatio (None, None, None, 2 0           stage3_unit3_bn2_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_21_1 (ZeroPaddin (None, None, None, 2 0           stage3_unit3_relu2_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_55_2 (ZeroPaddin (None, None, None, 2 0           stage3_unit3_relu2_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_conv2_1 (Conv2D)   (None, None, None, 2 589824      zero_padding2d_21_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_conv2_2 (Conv2D)   (None, None, None, 2 589824      zero_padding2d_55_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_9_1 (Add)                   (None, None, None, 2 0           stage3_unit3_conv2_1[0][0]       \n",
      "                                                                 add_8_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_25_2 (Add)                  (None, None, None, 2 0           stage3_unit3_conv2_2[0][0]       \n",
      "                                                                 add_24_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_bn1_1 (BatchNormal (None, None, None, 2 1024        add_9_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_bn1_2 (BatchNormal (None, None, None, 2 1024        add_25_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_relu1_1 (Activatio (None, None, None, 2 0           stage3_unit4_bn1_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_relu1_2 (Activatio (None, None, None, 2 0           stage3_unit4_bn1_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_22_1 (ZeroPaddin (None, None, None, 2 0           stage3_unit4_relu1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_56_2 (ZeroPaddin (None, None, None, 2 0           stage3_unit4_relu1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_conv1_1 (Conv2D)   (None, None, None, 2 589824      zero_padding2d_22_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_conv1_2 (Conv2D)   (None, None, None, 2 589824      zero_padding2d_56_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_bn2_1 (BatchNormal (None, None, None, 2 1024        stage3_unit4_conv1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_bn2_2 (BatchNormal (None, None, None, 2 1024        stage3_unit4_conv1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_relu2_1 (Activatio (None, None, None, 2 0           stage3_unit4_bn2_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_relu2_2 (Activatio (None, None, None, 2 0           stage3_unit4_bn2_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_23_1 (ZeroPaddin (None, None, None, 2 0           stage3_unit4_relu2_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_57_2 (ZeroPaddin (None, None, None, 2 0           stage3_unit4_relu2_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_conv2_1 (Conv2D)   (None, None, None, 2 589824      zero_padding2d_23_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_conv2_2 (Conv2D)   (None, None, None, 2 589824      zero_padding2d_57_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_10_1 (Add)                  (None, None, None, 2 0           stage3_unit4_conv2_1[0][0]       \n",
      "                                                                 add_9_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_26_2 (Add)                  (None, None, None, 2 0           stage3_unit4_conv2_2[0][0]       \n",
      "                                                                 add_25_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_bn1_1 (BatchNormal (None, None, None, 2 1024        add_10_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_bn1_2 (BatchNormal (None, None, None, 2 1024        add_26_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_relu1_1 (Activatio (None, None, None, 2 0           stage3_unit5_bn1_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_relu1_2 (Activatio (None, None, None, 2 0           stage3_unit5_bn1_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_24_1 (ZeroPaddin (None, None, None, 2 0           stage3_unit5_relu1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_58_2 (ZeroPaddin (None, None, None, 2 0           stage3_unit5_relu1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_conv1_1 (Conv2D)   (None, None, None, 2 589824      zero_padding2d_24_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_conv1_2 (Conv2D)   (None, None, None, 2 589824      zero_padding2d_58_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_bn2_1 (BatchNormal (None, None, None, 2 1024        stage3_unit5_conv1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_bn2_2 (BatchNormal (None, None, None, 2 1024        stage3_unit5_conv1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_relu2_1 (Activatio (None, None, None, 2 0           stage3_unit5_bn2_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_relu2_2 (Activatio (None, None, None, 2 0           stage3_unit5_bn2_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_25_1 (ZeroPaddin (None, None, None, 2 0           stage3_unit5_relu2_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_59_2 (ZeroPaddin (None, None, None, 2 0           stage3_unit5_relu2_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_conv2_1 (Conv2D)   (None, None, None, 2 589824      zero_padding2d_25_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_conv2_2 (Conv2D)   (None, None, None, 2 589824      zero_padding2d_59_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_11_1 (Add)                  (None, None, None, 2 0           stage3_unit5_conv2_1[0][0]       \n",
      "                                                                 add_10_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_27_2 (Add)                  (None, None, None, 2 0           stage3_unit5_conv2_2[0][0]       \n",
      "                                                                 add_26_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_bn1_1 (BatchNormal (None, None, None, 2 1024        add_11_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_bn1_2 (BatchNormal (None, None, None, 2 1024        add_27_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_relu1_1 (Activatio (None, None, None, 2 0           stage3_unit6_bn1_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_relu1_2 (Activatio (None, None, None, 2 0           stage3_unit6_bn1_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_26_1 (ZeroPaddin (None, None, None, 2 0           stage3_unit6_relu1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_60_2 (ZeroPaddin (None, None, None, 2 0           stage3_unit6_relu1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_conv1_1 (Conv2D)   (None, None, None, 2 589824      zero_padding2d_26_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_conv1_2 (Conv2D)   (None, None, None, 2 589824      zero_padding2d_60_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_bn2_1 (BatchNormal (None, None, None, 2 1024        stage3_unit6_conv1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_bn2_2 (BatchNormal (None, None, None, 2 1024        stage3_unit6_conv1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_relu2_1 (Activatio (None, None, None, 2 0           stage3_unit6_bn2_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_relu2_2 (Activatio (None, None, None, 2 0           stage3_unit6_bn2_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_27_1 (ZeroPaddin (None, None, None, 2 0           stage3_unit6_relu2_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_61_2 (ZeroPaddin (None, None, None, 2 0           stage3_unit6_relu2_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_conv2_1 (Conv2D)   (None, None, None, 2 589824      zero_padding2d_27_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_conv2_2 (Conv2D)   (None, None, None, 2 589824      zero_padding2d_61_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_12_1 (Add)                  (None, None, None, 2 0           stage3_unit6_conv2_1[0][0]       \n",
      "                                                                 add_11_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_28_2 (Add)                  (None, None, None, 2 0           stage3_unit6_conv2_2[0][0]       \n",
      "                                                                 add_27_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn1_1 (BatchNormal (None, None, None, 2 1024        add_12_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn1_2 (BatchNormal (None, None, None, 2 1024        add_28_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu1_1 (Activatio (None, None, None, 2 0           stage4_unit1_bn1_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu1_2 (Activatio (None, None, None, 2 0           stage4_unit1_bn1_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_28_1 (ZeroPaddin (None, None, None, 2 0           stage4_unit1_relu1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_62_2 (ZeroPaddin (None, None, None, 2 0           stage4_unit1_relu1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv1_1 (Conv2D)   (None, None, None, 5 1179648     zero_padding2d_28_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv1_2 (Conv2D)   (None, None, None, 5 1179648     zero_padding2d_62_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn2_1 (BatchNormal (None, None, None, 5 2048        stage4_unit1_conv1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn2_2 (BatchNormal (None, None, None, 5 2048        stage4_unit1_conv1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu2_1 (Activatio (None, None, None, 5 0           stage4_unit1_bn2_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu2_2 (Activatio (None, None, None, 5 0           stage4_unit1_bn2_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_29_1 (ZeroPaddin (None, None, None, 5 0           stage4_unit1_relu2_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_63_2 (ZeroPaddin (None, None, None, 5 0           stage4_unit1_relu2_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv2_1 (Conv2D)   (None, None, None, 5 2359296     zero_padding2d_29_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_sc_1 (Conv2D)      (None, None, None, 5 131072      stage4_unit1_relu1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv2_2 (Conv2D)   (None, None, None, 5 2359296     zero_padding2d_63_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_sc_2 (Conv2D)      (None, None, None, 5 131072      stage4_unit1_relu1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_13_1 (Add)                  (None, None, None, 5 0           stage4_unit1_conv2_1[0][0]       \n",
      "                                                                 stage4_unit1_sc_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_29_2 (Add)                  (None, None, None, 5 0           stage4_unit1_conv2_2[0][0]       \n",
      "                                                                 stage4_unit1_sc_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn1_1 (BatchNormal (None, None, None, 5 2048        add_13_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn1_2 (BatchNormal (None, None, None, 5 2048        add_29_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu1_1 (Activatio (None, None, None, 5 0           stage4_unit2_bn1_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu1_2 (Activatio (None, None, None, 5 0           stage4_unit2_bn1_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_30_1 (ZeroPaddin (None, None, None, 5 0           stage4_unit2_relu1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_64_2 (ZeroPaddin (None, None, None, 5 0           stage4_unit2_relu1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv1_1 (Conv2D)   (None, None, None, 5 2359296     zero_padding2d_30_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv1_2 (Conv2D)   (None, None, None, 5 2359296     zero_padding2d_64_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn2_1 (BatchNormal (None, None, None, 5 2048        stage4_unit2_conv1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn2_2 (BatchNormal (None, None, None, 5 2048        stage4_unit2_conv1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu2_1 (Activatio (None, None, None, 5 0           stage4_unit2_bn2_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu2_2 (Activatio (None, None, None, 5 0           stage4_unit2_bn2_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_31_1 (ZeroPaddin (None, None, None, 5 0           stage4_unit2_relu2_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_65_2 (ZeroPaddin (None, None, None, 5 0           stage4_unit2_relu2_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv2_1 (Conv2D)   (None, None, None, 5 2359296     zero_padding2d_31_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv2_2 (Conv2D)   (None, None, None, 5 2359296     zero_padding2d_65_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_14_1 (Add)                  (None, None, None, 5 0           stage4_unit2_conv2_1[0][0]       \n",
      "                                                                 add_13_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_30_2 (Add)                  (None, None, None, 5 0           stage4_unit2_conv2_2[0][0]       \n",
      "                                                                 add_29_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_bn1_1 (BatchNormal (None, None, None, 5 2048        add_14_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_bn1_2 (BatchNormal (None, None, None, 5 2048        add_30_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_relu1_1 (Activatio (None, None, None, 5 0           stage4_unit3_bn1_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_relu1_2 (Activatio (None, None, None, 5 0           stage4_unit3_bn1_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_32_1 (ZeroPaddin (None, None, None, 5 0           stage4_unit3_relu1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_66_2 (ZeroPaddin (None, None, None, 5 0           stage4_unit3_relu1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_conv1_1 (Conv2D)   (None, None, None, 5 2359296     zero_padding2d_32_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_conv1_2 (Conv2D)   (None, None, None, 5 2359296     zero_padding2d_66_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_bn2_1 (BatchNormal (None, None, None, 5 2048        stage4_unit3_conv1_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_bn2_2 (BatchNormal (None, None, None, 5 2048        stage4_unit3_conv1_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_relu2_1 (Activatio (None, None, None, 5 0           stage4_unit3_bn2_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_relu2_2 (Activatio (None, None, None, 5 0           stage4_unit3_bn2_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_33_1 (ZeroPaddin (None, None, None, 5 0           stage4_unit3_relu2_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_67_2 (ZeroPaddin (None, None, None, 5 0           stage4_unit3_relu2_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_conv2_1 (Conv2D)   (None, None, None, 5 2359296     zero_padding2d_33_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_conv2_2 (Conv2D)   (None, None, None, 5 2359296     zero_padding2d_67_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_15_1 (Add)                  (None, None, None, 5 0           stage4_unit3_conv2_1[0][0]       \n",
      "                                                                 add_14_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_31_2 (Add)                  (None, None, None, 5 0           stage4_unit3_conv2_2[0][0]       \n",
      "                                                                 add_30_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_8 (Glo (None, 512)          0           add_15_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_9 (Glo (None, 512)          0           add_31_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_6 (Glo (None, 512)          0           stage4_unit3_relu2_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_7 (Glo (None, 512)          0           stage4_unit3_relu2_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 1, 1, 512)    0           global_average_pooling2d_8[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "reshape_9 (Reshape)             (None, 1, 1, 512)    0           global_average_pooling2d_9[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 1, 1, 512)    0           global_average_pooling2d_6[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 1, 1, 512)    0           global_average_pooling2d_7[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 1, 1, 32)     16416       reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 1, 1, 32)     16416       reshape_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 1, 1, 32)     16416       reshape_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 1, 1, 32)     16416       reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 1, 1, 512)    16896       conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 1, 1, 512)    16896       conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 1, 1, 512)    16896       conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 1, 1, 512)    16896       conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_8 (Multiply)           (None, None, None, 5 0           add_15_1[0][0]                   \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_9 (Multiply)           (None, None, None, 5 0           add_31_2[0][0]                   \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, None, None, 5 0           stage4_unit3_relu2_1[0][0]       \n",
      "                                                                 conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_7 (Multiply)           (None, None, None, 5 0           stage4_unit3_relu2_2[0][0]       \n",
      "                                                                 conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fusion_last (Add)               (None, None, None, 5 0           multiply_8[0][0]                 \n",
      "                                                                 multiply_9[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "fusion_4 (Add)                  (None, None, None, 5 0           multiply_6[0][0]                 \n",
      "                                                                 multiply_7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, None, None, 5 0           fusion_last[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, None, None, 5 0           fusion_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, None, None, 1 0           up_sampling2d_1[0][0]            \n",
      "                                                                 up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, None, None, 5 4719104     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_4 (Glo (None, 256)          0           stage3_unit6_relu2_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_5 (Glo (None, 256)          0           stage3_unit6_relu2_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, None, None, 5 2048        conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 1, 1, 256)    0           global_average_pooling2d_4[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 1, 1, 256)    0           global_average_pooling2d_5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu (TFOpLambda)         (None, None, None, 5 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 1, 1, 32)     8224        reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 1, 1, 32)     8224        reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, None, None, 5 2359808     tf.nn.relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 1, 1, 256)    8448        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 1, 1, 256)    8448        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, None, 5 2048        conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, None, None, 2 0           stage3_unit6_relu2_1[0][0]       \n",
      "                                                                 conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, None, None, 2 0           stage3_unit6_relu2_2[0][0]       \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1 (TFOpLambda)       (None, None, None, 5 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fusion_3 (Add)                  (None, None, None, 2 0           multiply_4[0][0]                 \n",
      "                                                                 multiply_5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, None, None, 5 0           tf.nn.relu_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, None, None, 2 0           fusion_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, None, 7 0           up_sampling2d_3[0][0]            \n",
      "                                                                 up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, None, None, 2 1769728     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 128)          0           stage2_unit4_relu2_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 128)          0           stage2_unit4_relu2_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, None, 2 1024        conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 1, 1, 128)    0           global_average_pooling2d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 1, 1, 128)    0           global_average_pooling2d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_2 (TFOpLambda)       (None, None, None, 2 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_4 (Conv2D)               (None, 1, 1, 32)     4128        reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 1, 1, 32)     4128        reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, None, None, 2 590080      tf.nn.relu_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 1, 1, 128)    4224        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 1, 1, 128)    4224        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, None, 2 1024        conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, None, None, 1 0           stage2_unit4_relu2_1[0][0]       \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, None, None, 1 0           stage2_unit4_relu2_2[0][0]       \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_3 (TFOpLambda)       (None, None, None, 2 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fusion_2 (Add)                  (None, None, None, 1 0           multiply_2[0][0]                 \n",
      "                                                                 multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, None, None, 2 0           tf.nn.relu_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, None, None, 1 0           fusion_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, None, None, 3 0           up_sampling2d_5[0][0]            \n",
      "                                                                 up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, None, None, 2 884992      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 64)           0           stage1_unit3_relu2_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 64)           0           stage1_unit3_relu2_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, None, None, 2 1024        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 1, 1, 64)     0           global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 1, 64)     0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_4 (TFOpLambda)       (None, None, None, 2 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 1, 1, 32)     2080        reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 1, 1, 32)     2080        reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, None, None, 2 590080      tf.nn.relu_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 1, 1, 64)     2112        conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 1, 1, 64)     2112        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, None, None, 2 1024        conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, None, None, 6 0           stage1_unit3_relu2_1[0][0]       \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, None, None, 6 0           stage1_unit3_relu2_2[0][0]       \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_5 (TFOpLambda)       (None, None, None, 2 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fusion_1 (Add)                  (None, None, None, 6 0           multiply[0][0]                   \n",
      "                                                                 multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2D)  (None, None, None, 2 0           tf.nn.relu_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2D)  (None, None, None, 6 0           fusion_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, None, None, 3 0           up_sampling2d_7[0][0]            \n",
      "                                                                 up_sampling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, None, None, 1 368768      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, None, None, 1 512         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_6 (TFOpLambda)       (None, None, None, 1 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, None, None, 1 147584      tf.nn.relu_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, None, None, 1 512         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_7 (TFOpLambda)       (None, None, None, 1 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_8 (UpSampling2D)  (None, None, None, 1 0           tf.nn.relu_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, None, None, 6 73792       up_sampling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, None, None, 6 256         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_8 (TFOpLambda)       (None, None, None, 6 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, None, None, 6 36928       tf.nn.relu_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, None, None, 6 256         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_9 (TFOpLambda)       (None, None, None, 6 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "last_layer (Conv2D)             (None, None, None, 3 2470        tf.nn.relu_9[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 54,345,592\n",
      "Trainable params: 11,768,556\n",
      "Non-trainable params: 42,577,036\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "xr = decode_layer(fusion_last,tf.keras.layers.UpSampling2D(size=(2,2), interpolation=\"nearest\")(fusion_4),512)\n",
    "xr = decode_layer(xr,tf.keras.layers.UpSampling2D(size=(2,2), interpolation=\"nearest\")(fusion_3),256)\n",
    "xr = decode_layer(xr,tf.keras.layers.UpSampling2D(size=(2,2), interpolation=\"nearest\")(fusion_2),256)\n",
    "xr = decode_layer(xr,tf.keras.layers.UpSampling2D(size=(2,2), interpolation=\"nearest\")(fusion_1),128)\n",
    "xr = last_decode_layer(xr,64)\n",
    "\n",
    "xr = tf.keras.layers.Conv2D(38, kernel_size=(1, 1), activation='softmax', padding='same', name='last_layer')(xr)\n",
    "\n",
    "model = tf.keras.Model(inputs=[pretrained_model_1.input, pretrained_model_2.input], outputs=xr, name='myModel')\n",
    "# encoder_fusion = tf.keras.Model(inputs=[pretrained_model_1.input, pretrained_model_2.input], outputs=fusion)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff17209f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " layer output shape:  (None, None, None, 38)\n"
     ]
    }
   ],
   "source": [
    "stage_fusion = model.get_layer('last_layer')\n",
    "print(' layer output shape: ', stage_fusion.output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7528ab91",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d16196da",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5638d4db",
   "metadata": {},
   "source": [
    "## Plot Training accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "419d06c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_acc(history, title=\"Model Accuracy\"):\n",
    "    \"\"\"Imprime una gráfica mostrando la accuracy por epoch obtenida en un entrenamiento\"\"\"\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_loss(history, title=\"Model Loss\"):\n",
    "    \"\"\"Imprime una gráfica mostrando la pérdida por epoch obtenida en un entrenamiento\"\"\"\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'], loc='upper right')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_compare_losses(history1, history2, name1=\"Red 1\",\n",
    "                        name2=\"Red 2\", title=\"Graph title\"):\n",
    "    \"\"\"Compara losses de dos entrenamientos con nombres name1 y name2\"\"\"\n",
    "    plt.plot(history1.history['loss'], color=\"green\")\n",
    "    plt.plot(history1.history['val_loss'], 'r--', color=\"green\")\n",
    "    plt.plot(history2.history['loss'], color=\"blue\")\n",
    "    plt.plot(history2.history['val_loss'], 'r--', color=\"blue\")\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train ' + name1, 'Val ' + name1, \n",
    "                'Train ' + name2, 'Val ' + name2],\n",
    "               loc='upper right')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_compare_accs(history1, history2, name1=\"Red 1\",\n",
    "                      name2=\"Red 2\", title=\"Graph title\"):\n",
    "    \"\"\"Compara accuracies de dos entrenamientos con nombres name1 y name2\"\"\"\n",
    "    plt.plot(history1.history['accuracy'], color=\"green\")\n",
    "    plt.plot(history1.history['val_accuracy'], 'r--', color=\"green\")\n",
    "    plt.plot(history2.history['accuracy'], color=\"blue\")\n",
    "    plt.plot(history2.history['val_accuracy'], 'r--', color=\"blue\")\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train ' + name1, 'Val ' + name1, \n",
    "                'Train ' + name2, 'Val ' + name2], \n",
    "               loc='lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cb0290",
   "metadata": {},
   "source": [
    "## metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e69cf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
    "    return score\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "def bce_logdice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n",
    "\n",
    "def weighted_bce_loss(y_true, y_pred, weight):\n",
    "    epsilon = 1e-7\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    logit_y_pred = K.log(y_pred / (1. - y_pred))\n",
    "    loss = weight * (logit_y_pred * (1. - y_true) + \n",
    "                     K.log(1. + K.exp(-K.abs(logit_y_pred))) + K.maximum(-logit_y_pred, 0.))\n",
    "    return K.sum(loss) / K.sum(weight)\n",
    "\n",
    "def weighted_dice_loss(y_true, y_pred, weight):\n",
    "    smooth = 1.\n",
    "    w, m1, m2 = weight, y_true, y_pred\n",
    "    intersection = (m1 * m2)\n",
    "    score = (2. * K.sum(w * intersection) + smooth) / (K.sum(w * m1) + K.sum(w * m2) + smooth)\n",
    "    loss = 1. - K.sum(score)\n",
    "    return loss\n",
    "\n",
    "def weighted_bce_dice_loss(y_true, y_pred):\n",
    "    y_true = K.cast(y_true, 'float32')\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    # if we want to get same size of output, kernel size must be odd\n",
    "    averaged_mask = K.pool2d(\n",
    "            y_true, pool_size=(50, 50), strides=(1, 1), padding='same', pool_mode='avg')\n",
    "    weight = K.ones_like(averaged_mask)\n",
    "    w0 = K.sum(weight)\n",
    "    weight = 5. * K.exp(-5. * K.abs(averaged_mask - 0.5))\n",
    "    w1 = K.sum(weight)\n",
    "    weight *= (w0 / w1)\n",
    "    loss = weighted_bce_loss(y_true, y_pred, weight) + dice_loss(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "def true_positive_rate(y_true, y_pred):\n",
    "    return K.sum(K.flatten(y_true)*K.flatten(K.round(y_pred)))/K.sum(y_true)\n",
    "#seg_model.compile(optimizer=Adam(1e-4, decay=1e-6), loss=dice_p_bce, metrics=[dice_coef, 'binary_accuracy', true_positive_rate])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7f89d6",
   "metadata": {},
   "source": [
    "## callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d3cab9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "import math\n",
    "weight_path=\"{}_best_weights.hdf5\".format('seg_model_2')\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min', save_weights_only = True)\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.5, \n",
    "                                   patience=10, \n",
    "                                   verbose=1, min_delta=0.0001, cooldown=2, min_lr=1e-7)\n",
    "\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 1e-5\n",
    "#     if epoch >= 5:\n",
    "#         initial_lrate = 5e-5\n",
    "#     if epoch >= 10:\n",
    "#         initial_lrate = 2.5e-5\n",
    "#     if epoch >= 30:\n",
    "#         initial_lrate = 1e-6\n",
    "#     if epoch >= 60:\n",
    "#         initial_lrate = 5e-6\n",
    "#     print('lr is: ', initial_lrate)\n",
    "    return initial_lrate\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "\n",
    "early = EarlyStopping(monitor=\"val_loss\",\n",
    "                      patience=10) # probably needs to be more patient, but kaggle time is limited\n",
    "\n",
    "callbacks_list = [checkpoint, early, lrate]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fd22e1",
   "metadata": {},
   "source": [
    "## Model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51ea1ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "102/102 [==============================] - 109s 877ms/step - loss: 3.7960 - dice_coef: 0.0123 - accuracy: 0.1000 - true_positive_rate: 0.0064 - iou_score: 0.0056 - val_loss: 3.5669 - val_dice_coef: 0.0000e+00 - val_accuracy: 0.2205 - val_true_positive_rate: 0.0000e+00 - val_iou_score: 0.0045\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.56688, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 2/1000\n",
      "102/102 [==============================] - 84s 828ms/step - loss: 3.3477 - dice_coef: 0.0468 - accuracy: 0.2039 - true_positive_rate: 0.0246 - iou_score: 0.0094 - val_loss: 3.5655 - val_dice_coef: 0.0000e+00 - val_accuracy: 0.2205 - val_true_positive_rate: 0.0000e+00 - val_iou_score: 0.0046\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.56688 to 3.56555, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 3/1000\n",
      "102/102 [==============================] - 80s 788ms/step - loss: 2.9819 - dice_coef: 0.1096 - accuracy: 0.3112 - true_positive_rate: 0.0595 - iou_score: 0.0146 - val_loss: 3.5641 - val_dice_coef: 0.0000e+00 - val_accuracy: 0.2182 - val_true_positive_rate: 0.0000e+00 - val_iou_score: 0.0046\n",
      "\n",
      "Epoch 00003: val_loss improved from 3.56555 to 3.56409, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 4/1000\n",
      "102/102 [==============================] - 80s 786ms/step - loss: 2.7220 - dice_coef: 0.1676 - accuracy: 0.3986 - true_positive_rate: 0.0943 - iou_score: 0.0189 - val_loss: 3.5061 - val_dice_coef: 4.8074e-05 - val_accuracy: 0.2084 - val_true_positive_rate: 2.4043e-05 - val_iou_score: 0.0053\n",
      "\n",
      "Epoch 00004: val_loss improved from 3.56409 to 3.50613, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 5/1000\n",
      "102/102 [==============================] - 80s 787ms/step - loss: 2.5719 - dice_coef: 0.2062 - accuracy: 0.4442 - true_positive_rate: 0.1190 - iou_score: 0.0218 - val_loss: 3.4073 - val_dice_coef: 0.0100 - val_accuracy: 0.2544 - val_true_positive_rate: 0.0051 - val_iou_score: 0.0072\n",
      "\n",
      "Epoch 00005: val_loss improved from 3.50613 to 3.40734, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 6/1000\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 786ms/step - loss: 2.4682 - dice_coef: 0.2338 - accuracy: 0.4654 - true_positive_rate: 0.1375 - iou_score: 0.0237 - val_loss: 3.2765 - val_dice_coef: 0.0457 - val_accuracy: 0.2869 - val_true_positive_rate: 0.0240 - val_iou_score: 0.0095\n",
      "\n",
      "Epoch 00006: val_loss improved from 3.40734 to 3.27652, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 7/1000\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 2.4307 - dice_coef: 0.2449 - accuracy: 0.4753 - true_positive_rate: 0.1454 - iou_score: 0.0248 - val_loss: 3.1165 - val_dice_coef: 0.0793 - val_accuracy: 0.3231 - val_true_positive_rate: 0.0427 - val_iou_score: 0.0120\n",
      "\n",
      "Epoch 00007: val_loss improved from 3.27652 to 3.11649, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 8/1000\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 2.3775 - dice_coef: 0.2549 - accuracy: 0.4866 - true_positive_rate: 0.1525 - iou_score: 0.0256 - val_loss: 2.8610 - val_dice_coef: 0.1238 - val_accuracy: 0.3890 - val_true_positive_rate: 0.0680 - val_iou_score: 0.0161\n",
      "\n",
      "Epoch 00008: val_loss improved from 3.11649 to 2.86100, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 9/1000\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 786ms/step - loss: 2.3406 - dice_coef: 0.2666 - accuracy: 0.4914 - true_positive_rate: 0.1609 - iou_score: 0.0263 - val_loss: 2.6213 - val_dice_coef: 0.1990 - val_accuracy: 0.4425 - val_true_positive_rate: 0.1153 - val_iou_score: 0.0210\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.86100 to 2.62132, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 10/1000\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 786ms/step - loss: 2.3080 - dice_coef: 0.2768 - accuracy: 0.4968 - true_positive_rate: 0.1683 - iou_score: 0.0271 - val_loss: 2.4278 - val_dice_coef: 0.2501 - val_accuracy: 0.4848 - val_true_positive_rate: 0.1493 - val_iou_score: 0.0248\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.62132 to 2.42782, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 11/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 2.2685 - dice_coef: 0.2859 - accuracy: 0.5024 - true_positive_rate: 0.1748 - iou_score: 0.0279 - val_loss: 2.2783 - val_dice_coef: 0.3165 - val_accuracy: 0.5057 - val_true_positive_rate: 0.1989 - val_iou_score: 0.0291\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.42782 to 2.27828, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 12/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 2.2525 - dice_coef: 0.2911 - accuracy: 0.5051 - true_positive_rate: 0.1788 - iou_score: 0.0281 - val_loss: 2.2176 - val_dice_coef: 0.3379 - val_accuracy: 0.5160 - val_true_positive_rate: 0.2157 - val_iou_score: 0.0305\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.27828 to 2.21756, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 13/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "102/102 [==============================] - 80s 786ms/step - loss: 2.2342 - dice_coef: 0.2985 - accuracy: 0.5080 - true_positive_rate: 0.1842 - iou_score: 0.0286 - val_loss: 2.1848 - val_dice_coef: 0.3539 - val_accuracy: 0.5199 - val_true_positive_rate: 0.2296 - val_iou_score: 0.0316\n",
      "\n",
      "Epoch 00013: val_loss improved from 2.21756 to 2.18479, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 14/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "102/102 [==============================] - 80s 786ms/step - loss: 2.2200 - dice_coef: 0.3015 - accuracy: 0.5090 - true_positive_rate: 0.1866 - iou_score: 0.0287 - val_loss: 2.1654 - val_dice_coef: 0.3601 - val_accuracy: 0.5219 - val_true_positive_rate: 0.2338 - val_iou_score: 0.0323\n",
      "\n",
      "Epoch 00014: val_loss improved from 2.18479 to 2.16544, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 15/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "102/102 [==============================] - 80s 787ms/step - loss: 2.2094 - dice_coef: 0.3012 - accuracy: 0.5111 - true_positive_rate: 0.1868 - iou_score: 0.0288 - val_loss: 2.1647 - val_dice_coef: 0.3578 - val_accuracy: 0.5231 - val_true_positive_rate: 0.2315 - val_iou_score: 0.0323\n",
      "\n",
      "Epoch 00015: val_loss improved from 2.16544 to 2.16469, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 16/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "102/102 [==============================] - 80s 787ms/step - loss: 2.1882 - dice_coef: 0.3080 - accuracy: 0.5131 - true_positive_rate: 0.1916 - iou_score: 0.0293 - val_loss: 2.1521 - val_dice_coef: 0.3604 - val_accuracy: 0.5247 - val_true_positive_rate: 0.2339 - val_iou_score: 0.0321\n",
      "\n",
      "Epoch 00016: val_loss improved from 2.16469 to 2.15212, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 17/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 2.1800 - dice_coef: 0.3135 - accuracy: 0.5151 - true_positive_rate: 0.1960 - iou_score: 0.0298 - val_loss: 2.1318 - val_dice_coef: 0.3730 - val_accuracy: 0.5259 - val_true_positive_rate: 0.2453 - val_iou_score: 0.0336\n",
      "\n",
      "Epoch 00017: val_loss improved from 2.15212 to 2.13177, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 18/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 2.1535 - dice_coef: 0.3212 - accuracy: 0.5185 - true_positive_rate: 0.2017 - iou_score: 0.0303 - val_loss: 2.1229 - val_dice_coef: 0.3730 - val_accuracy: 0.5290 - val_true_positive_rate: 0.2447 - val_iou_score: 0.0329\n",
      "\n",
      "Epoch 00018: val_loss improved from 2.13177 to 2.12290, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 19/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 2.1590 - dice_coef: 0.3189 - accuracy: 0.5173 - true_positive_rate: 0.2006 - iou_score: 0.0300 - val_loss: 2.1164 - val_dice_coef: 0.3719 - val_accuracy: 0.5295 - val_true_positive_rate: 0.2436 - val_iou_score: 0.0326\n",
      "\n",
      "Epoch 00019: val_loss improved from 2.12290 to 2.11643, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 20/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 2.1382 - dice_coef: 0.3238 - accuracy: 0.5199 - true_positive_rate: 0.2041 - iou_score: 0.0304 - val_loss: 2.0968 - val_dice_coef: 0.3849 - val_accuracy: 0.5316 - val_true_positive_rate: 0.2549 - val_iou_score: 0.0343\n",
      "\n",
      "Epoch 00020: val_loss improved from 2.11643 to 2.09678, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 21/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 2.1250 - dice_coef: 0.3267 - accuracy: 0.5203 - true_positive_rate: 0.2065 - iou_score: 0.0306 - val_loss: 2.0809 - val_dice_coef: 0.3921 - val_accuracy: 0.5331 - val_true_positive_rate: 0.2618 - val_iou_score: 0.0352\n",
      "\n",
      "Epoch 00021: val_loss improved from 2.09678 to 2.08090, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 22/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 2.1150 - dice_coef: 0.3321 - accuracy: 0.5209 - true_positive_rate: 0.2108 - iou_score: 0.0311 - val_loss: 2.0734 - val_dice_coef: 0.3907 - val_accuracy: 0.5345 - val_true_positive_rate: 0.2604 - val_iou_score: 0.0352\n",
      "\n",
      "Epoch 00022: val_loss improved from 2.08090 to 2.07342, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 23/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 2.0959 - dice_coef: 0.3386 - accuracy: 0.5256 - true_positive_rate: 0.2154 - iou_score: 0.0314 - val_loss: 2.0633 - val_dice_coef: 0.3890 - val_accuracy: 0.5349 - val_true_positive_rate: 0.2585 - val_iou_score: 0.0348\n",
      "\n",
      "Epoch 00023: val_loss improved from 2.07342 to 2.06327, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 24/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 2.0859 - dice_coef: 0.3386 - accuracy: 0.5262 - true_positive_rate: 0.2158 - iou_score: 0.0314 - val_loss: 2.0583 - val_dice_coef: 0.3887 - val_accuracy: 0.5366 - val_true_positive_rate: 0.2583 - val_iou_score: 0.0349\n",
      "\n",
      "Epoch 00024: val_loss improved from 2.06327 to 2.05827, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 25/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "102/102 [==============================] - 80s 786ms/step - loss: 2.0760 - dice_coef: 0.3412 - accuracy: 0.5271 - true_positive_rate: 0.2180 - iou_score: 0.0316 - val_loss: 2.0496 - val_dice_coef: 0.3913 - val_accuracy: 0.5374 - val_true_positive_rate: 0.2606 - val_iou_score: 0.0348\n",
      "\n",
      "Epoch 00025: val_loss improved from 2.05827 to 2.04957, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 26/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "102/102 [==============================] - 80s 787ms/step - loss: 2.0590 - dice_coef: 0.3457 - accuracy: 0.5308 - true_positive_rate: 0.2216 - iou_score: 0.0320 - val_loss: 2.0351 - val_dice_coef: 0.3998 - val_accuracy: 0.5381 - val_true_positive_rate: 0.2687 - val_iou_score: 0.0353\n",
      "\n",
      "Epoch 00026: val_loss improved from 2.04957 to 2.03510, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 27/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "102/102 [==============================] - 80s 786ms/step - loss: 2.0551 - dice_coef: 0.3448 - accuracy: 0.5291 - true_positive_rate: 0.2213 - iou_score: 0.0319 - val_loss: 2.0221 - val_dice_coef: 0.4038 - val_accuracy: 0.5392 - val_true_positive_rate: 0.2720 - val_iou_score: 0.0358\n",
      "\n",
      "Epoch 00027: val_loss improved from 2.03510 to 2.02214, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 28/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "102/102 [==============================] - 80s 786ms/step - loss: 2.0436 - dice_coef: 0.3500 - accuracy: 0.5316 - true_positive_rate: 0.2253 - iou_score: 0.0323 - val_loss: 2.0087 - val_dice_coef: 0.4122 - val_accuracy: 0.5408 - val_true_positive_rate: 0.2801 - val_iou_score: 0.0363\n",
      "\n",
      "Epoch 00028: val_loss improved from 2.02214 to 2.00867, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 29/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 2.0351 - dice_coef: 0.3538 - accuracy: 0.5314 - true_positive_rate: 0.2285 - iou_score: 0.0325 - val_loss: 2.0054 - val_dice_coef: 0.4078 - val_accuracy: 0.5420 - val_true_positive_rate: 0.2770 - val_iou_score: 0.0359\n",
      "\n",
      "Epoch 00029: val_loss improved from 2.00867 to 2.00539, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 30/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 2.0228 - dice_coef: 0.3578 - accuracy: 0.5330 - true_positive_rate: 0.2317 - iou_score: 0.0327 - val_loss: 2.0011 - val_dice_coef: 0.4071 - val_accuracy: 0.5423 - val_true_positive_rate: 0.2758 - val_iou_score: 0.0359\n",
      "\n",
      "Epoch 00030: val_loss improved from 2.00539 to 2.00110, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 31/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 2.0085 - dice_coef: 0.3584 - accuracy: 0.5354 - true_positive_rate: 0.2321 - iou_score: 0.0330 - val_loss: 1.9953 - val_dice_coef: 0.4122 - val_accuracy: 0.5426 - val_true_positive_rate: 0.2804 - val_iou_score: 0.0362\n",
      "\n",
      "Epoch 00031: val_loss improved from 2.00110 to 1.99534, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 32/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 2.0159 - dice_coef: 0.3578 - accuracy: 0.5346 - true_positive_rate: 0.2321 - iou_score: 0.0328 - val_loss: 1.9910 - val_dice_coef: 0.4124 - val_accuracy: 0.5429 - val_true_positive_rate: 0.2802 - val_iou_score: 0.0364\n",
      "\n",
      "Epoch 00032: val_loss improved from 1.99534 to 1.99104, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 33/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 2.0120 - dice_coef: 0.3581 - accuracy: 0.5340 - true_positive_rate: 0.2323 - iou_score: 0.0329 - val_loss: 1.9860 - val_dice_coef: 0.4140 - val_accuracy: 0.5436 - val_true_positive_rate: 0.2815 - val_iou_score: 0.0359\n",
      "\n",
      "Epoch 00033: val_loss improved from 1.99104 to 1.98601, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 34/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 1.9951 - dice_coef: 0.3627 - accuracy: 0.5379 - true_positive_rate: 0.2359 - iou_score: 0.0332 - val_loss: 1.9880 - val_dice_coef: 0.4090 - val_accuracy: 0.5437 - val_true_positive_rate: 0.2773 - val_iou_score: 0.0360\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.98601\n",
      "Epoch 35/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 1.9932 - dice_coef: 0.3634 - accuracy: 0.5372 - true_positive_rate: 0.2363 - iou_score: 0.0335 - val_loss: 1.9833 - val_dice_coef: 0.4144 - val_accuracy: 0.5441 - val_true_positive_rate: 0.2825 - val_iou_score: 0.0361\n",
      "\n",
      "Epoch 00035: val_loss improved from 1.98601 to 1.98326, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 36/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "102/102 [==============================] - 80s 786ms/step - loss: 1.9911 - dice_coef: 0.3655 - accuracy: 0.5368 - true_positive_rate: 0.2382 - iou_score: 0.0332 - val_loss: 1.9772 - val_dice_coef: 0.4161 - val_accuracy: 0.5446 - val_true_positive_rate: 0.2836 - val_iou_score: 0.0366\n",
      "\n",
      "Epoch 00036: val_loss improved from 1.98326 to 1.97725, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 37/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "102/102 [==============================] - 80s 783ms/step - loss: 1.9865 - dice_coef: 0.3687 - accuracy: 0.5388 - true_positive_rate: 0.2405 - iou_score: 0.0335 - val_loss: 1.9764 - val_dice_coef: 0.4158 - val_accuracy: 0.5447 - val_true_positive_rate: 0.2829 - val_iou_score: 0.0363\n",
      "\n",
      "Epoch 00037: val_loss improved from 1.97725 to 1.97638, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 38/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 1.9917 - dice_coef: 0.3673 - accuracy: 0.5366 - true_positive_rate: 0.2395 - iou_score: 0.0334 - val_loss: 1.9708 - val_dice_coef: 0.4200 - val_accuracy: 0.5450 - val_true_positive_rate: 0.2871 - val_iou_score: 0.0366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00038: val_loss improved from 1.97638 to 1.97085, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 39/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "102/102 [==============================] - 80s 783ms/step - loss: 1.9847 - dice_coef: 0.3669 - accuracy: 0.5356 - true_positive_rate: 0.2392 - iou_score: 0.0335 - val_loss: 1.9699 - val_dice_coef: 0.4195 - val_accuracy: 0.5454 - val_true_positive_rate: 0.2868 - val_iou_score: 0.0369\n",
      "\n",
      "Epoch 00039: val_loss improved from 1.97085 to 1.96987, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 40/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.9833 - dice_coef: 0.3694 - accuracy: 0.5374 - true_positive_rate: 0.2417 - iou_score: 0.0336 - val_loss: 1.9626 - val_dice_coef: 0.4231 - val_accuracy: 0.5455 - val_true_positive_rate: 0.2907 - val_iou_score: 0.0371\n",
      "\n",
      "Epoch 00040: val_loss improved from 1.96987 to 1.96260, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 41/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.9745 - dice_coef: 0.3682 - accuracy: 0.5393 - true_positive_rate: 0.2407 - iou_score: 0.0335 - val_loss: 1.9638 - val_dice_coef: 0.4219 - val_accuracy: 0.5461 - val_true_positive_rate: 0.2886 - val_iou_score: 0.0372\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.96260\n",
      "Epoch 42/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 1.9626 - dice_coef: 0.3694 - accuracy: 0.5411 - true_positive_rate: 0.2415 - iou_score: 0.0337 - val_loss: 1.9623 - val_dice_coef: 0.4198 - val_accuracy: 0.5463 - val_true_positive_rate: 0.2873 - val_iou_score: 0.0368\n",
      "\n",
      "Epoch 00042: val_loss improved from 1.96260 to 1.96229, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 43/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 1.9692 - dice_coef: 0.3685 - accuracy: 0.5392 - true_positive_rate: 0.2411 - iou_score: 0.0337 - val_loss: 1.9567 - val_dice_coef: 0.4209 - val_accuracy: 0.5464 - val_true_positive_rate: 0.2883 - val_iou_score: 0.0373\n",
      "\n",
      "Epoch 00043: val_loss improved from 1.96229 to 1.95675, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 44/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "102/102 [==============================] - 80s 786ms/step - loss: 1.9613 - dice_coef: 0.3715 - accuracy: 0.5413 - true_positive_rate: 0.2434 - iou_score: 0.0340 - val_loss: 1.9547 - val_dice_coef: 0.4226 - val_accuracy: 0.5466 - val_true_positive_rate: 0.2894 - val_iou_score: 0.0370\n",
      "\n",
      "Epoch 00044: val_loss improved from 1.95675 to 1.95467, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 45/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 1.9594 - dice_coef: 0.3748 - accuracy: 0.5406 - true_positive_rate: 0.2459 - iou_score: 0.0340 - val_loss: 1.9525 - val_dice_coef: 0.4214 - val_accuracy: 0.5473 - val_true_positive_rate: 0.2886 - val_iou_score: 0.0369\n",
      "\n",
      "Epoch 00045: val_loss improved from 1.95467 to 1.95245, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 46/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 1.9531 - dice_coef: 0.3738 - accuracy: 0.5421 - true_positive_rate: 0.2455 - iou_score: 0.0341 - val_loss: 1.9464 - val_dice_coef: 0.4258 - val_accuracy: 0.5480 - val_true_positive_rate: 0.2935 - val_iou_score: 0.0371\n",
      "\n",
      "Epoch 00046: val_loss improved from 1.95245 to 1.94637, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 47/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "102/102 [==============================] - 80s 786ms/step - loss: 1.9547 - dice_coef: 0.3783 - accuracy: 0.5422 - true_positive_rate: 0.2490 - iou_score: 0.0342 - val_loss: 1.9443 - val_dice_coef: 0.4250 - val_accuracy: 0.5482 - val_true_positive_rate: 0.2922 - val_iou_score: 0.0373\n",
      "\n",
      "Epoch 00047: val_loss improved from 1.94637 to 1.94428, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 48/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "102/102 [==============================] - 81s 789ms/step - loss: 1.9461 - dice_coef: 0.3778 - accuracy: 0.5420 - true_positive_rate: 0.2489 - iou_score: 0.0341 - val_loss: 1.9405 - val_dice_coef: 0.4283 - val_accuracy: 0.5482 - val_true_positive_rate: 0.2954 - val_iou_score: 0.0372\n",
      "\n",
      "Epoch 00048: val_loss improved from 1.94428 to 1.94045, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 49/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.9384 - dice_coef: 0.3799 - accuracy: 0.5444 - true_positive_rate: 0.2503 - iou_score: 0.0345 - val_loss: 1.9379 - val_dice_coef: 0.4282 - val_accuracy: 0.5484 - val_true_positive_rate: 0.2959 - val_iou_score: 0.0375\n",
      "\n",
      "Epoch 00049: val_loss improved from 1.94045 to 1.93790, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 50/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "102/102 [==============================] - 80s 787ms/step - loss: 1.9426 - dice_coef: 0.3798 - accuracy: 0.5416 - true_positive_rate: 0.2506 - iou_score: 0.0343 - val_loss: 1.9370 - val_dice_coef: 0.4250 - val_accuracy: 0.5490 - val_true_positive_rate: 0.2935 - val_iou_score: 0.0374\n",
      "\n",
      "Epoch 00050: val_loss improved from 1.93790 to 1.93696, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 51/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 1.9368 - dice_coef: 0.3795 - accuracy: 0.5422 - true_positive_rate: 0.2505 - iou_score: 0.0345 - val_loss: 1.9359 - val_dice_coef: 0.4276 - val_accuracy: 0.5495 - val_true_positive_rate: 0.2940 - val_iou_score: 0.0375\n",
      "\n",
      "Epoch 00051: val_loss improved from 1.93696 to 1.93587, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 52/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 1.9315 - dice_coef: 0.3824 - accuracy: 0.5420 - true_positive_rate: 0.2527 - iou_score: 0.0345 - val_loss: 1.9278 - val_dice_coef: 0.4311 - val_accuracy: 0.5491 - val_true_positive_rate: 0.2979 - val_iou_score: 0.0379\n",
      "\n",
      "Epoch 00052: val_loss improved from 1.93587 to 1.92781, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 53/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "102/102 [==============================] - 80s 788ms/step - loss: 1.9344 - dice_coef: 0.3815 - accuracy: 0.5439 - true_positive_rate: 0.2520 - iou_score: 0.0347 - val_loss: 1.9251 - val_dice_coef: 0.4318 - val_accuracy: 0.5495 - val_true_positive_rate: 0.2982 - val_iou_score: 0.0376\n",
      "\n",
      "Epoch 00053: val_loss improved from 1.92781 to 1.92515, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 54/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "102/102 [==============================] - 80s 786ms/step - loss: 1.9311 - dice_coef: 0.3812 - accuracy: 0.5437 - true_positive_rate: 0.2520 - iou_score: 0.0346 - val_loss: 1.9225 - val_dice_coef: 0.4345 - val_accuracy: 0.5504 - val_true_positive_rate: 0.3016 - val_iou_score: 0.0379\n",
      "\n",
      "Epoch 00054: val_loss improved from 1.92515 to 1.92252, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 55/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "102/102 [==============================] - 80s 788ms/step - loss: 1.9326 - dice_coef: 0.3817 - accuracy: 0.5414 - true_positive_rate: 0.2523 - iou_score: 0.0346 - val_loss: 1.9192 - val_dice_coef: 0.4344 - val_accuracy: 0.5508 - val_true_positive_rate: 0.3015 - val_iou_score: 0.0381\n",
      "\n",
      "Epoch 00055: val_loss improved from 1.92252 to 1.91925, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 56/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 1.9159 - dice_coef: 0.3841 - accuracy: 0.5451 - true_positive_rate: 0.2542 - iou_score: 0.0348 - val_loss: 1.9183 - val_dice_coef: 0.4352 - val_accuracy: 0.5510 - val_true_positive_rate: 0.3019 - val_iou_score: 0.0381\n",
      "\n",
      "Epoch 00056: val_loss improved from 1.91925 to 1.91830, saving model to seg_model_2_best_weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "102/102 [==============================] - 80s 782ms/step - loss: 1.9234 - dice_coef: 0.3844 - accuracy: 0.5441 - true_positive_rate: 0.2548 - iou_score: 0.0348 - val_loss: 1.9147 - val_dice_coef: 0.4328 - val_accuracy: 0.5514 - val_true_positive_rate: 0.2999 - val_iou_score: 0.0378\n",
      "\n",
      "Epoch 00057: val_loss improved from 1.91830 to 1.91467, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 58/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "102/102 [==============================] - 80s 780ms/step - loss: 1.9160 - dice_coef: 0.3838 - accuracy: 0.5447 - true_positive_rate: 0.2543 - iou_score: 0.0349 - val_loss: 1.9099 - val_dice_coef: 0.4383 - val_accuracy: 0.5514 - val_true_positive_rate: 0.3052 - val_iou_score: 0.0382\n",
      "\n",
      "Epoch 00058: val_loss improved from 1.91467 to 1.90992, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 59/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "102/102 [==============================] - 80s 781ms/step - loss: 1.9166 - dice_coef: 0.3862 - accuracy: 0.5452 - true_positive_rate: 0.2563 - iou_score: 0.0348 - val_loss: 1.9112 - val_dice_coef: 0.4359 - val_accuracy: 0.5518 - val_true_positive_rate: 0.3024 - val_iou_score: 0.0377\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1.90992\n",
      "Epoch 60/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "102/102 [==============================] - 80s 781ms/step - loss: 1.9059 - dice_coef: 0.3886 - accuracy: 0.5472 - true_positive_rate: 0.2581 - iou_score: 0.0351 - val_loss: 1.9078 - val_dice_coef: 0.4337 - val_accuracy: 0.5520 - val_true_positive_rate: 0.3005 - val_iou_score: 0.0381\n",
      "\n",
      "Epoch 00060: val_loss improved from 1.90992 to 1.90783, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 61/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 783ms/step - loss: 1.8968 - dice_coef: 0.3932 - accuracy: 0.5475 - true_positive_rate: 0.2619 - iou_score: 0.0354 - val_loss: 1.8948 - val_dice_coef: 0.4406 - val_accuracy: 0.5539 - val_true_positive_rate: 0.3073 - val_iou_score: 0.0382\n",
      "\n",
      "Epoch 00061: val_loss improved from 1.90783 to 1.89480, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 62/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.8914 - dice_coef: 0.3927 - accuracy: 0.5458 - true_positive_rate: 0.2623 - iou_score: 0.0355 - val_loss: 1.8718 - val_dice_coef: 0.4528 - val_accuracy: 0.5542 - val_true_positive_rate: 0.3208 - val_iou_score: 0.0395\n",
      "\n",
      "Epoch 00062: val_loss improved from 1.89480 to 1.87180, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 63/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.8646 - dice_coef: 0.4039 - accuracy: 0.5497 - true_positive_rate: 0.2716 - iou_score: 0.0362 - val_loss: 1.8616 - val_dice_coef: 0.4547 - val_accuracy: 0.5558 - val_true_positive_rate: 0.3221 - val_iou_score: 0.0395\n",
      "\n",
      "Epoch 00063: val_loss improved from 1.87180 to 1.86159, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 64/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 1.8628 - dice_coef: 0.3988 - accuracy: 0.5496 - true_positive_rate: 0.2681 - iou_score: 0.0359 - val_loss: 1.8504 - val_dice_coef: 0.4572 - val_accuracy: 0.5568 - val_true_positive_rate: 0.3255 - val_iou_score: 0.0395\n",
      "\n",
      "Epoch 00064: val_loss improved from 1.86159 to 1.85037, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 65/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 1.8575 - dice_coef: 0.4034 - accuracy: 0.5472 - true_positive_rate: 0.2726 - iou_score: 0.0362 - val_loss: 1.8346 - val_dice_coef: 0.4606 - val_accuracy: 0.5577 - val_true_positive_rate: 0.3285 - val_iou_score: 0.0402\n",
      "\n",
      "Epoch 00065: val_loss improved from 1.85037 to 1.83457, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 66/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 1.8240 - dice_coef: 0.4140 - accuracy: 0.5546 - true_positive_rate: 0.2808 - iou_score: 0.0372 - val_loss: 1.8279 - val_dice_coef: 0.4704 - val_accuracy: 0.5597 - val_true_positive_rate: 0.3391 - val_iou_score: 0.0419\n",
      "\n",
      "Epoch 00066: val_loss improved from 1.83457 to 1.82790, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 67/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 786ms/step - loss: 1.8078 - dice_coef: 0.4196 - accuracy: 0.5555 - true_positive_rate: 0.2863 - iou_score: 0.0375 - val_loss: 1.8164 - val_dice_coef: 0.4715 - val_accuracy: 0.5604 - val_true_positive_rate: 0.3403 - val_iou_score: 0.0414\n",
      "\n",
      "Epoch 00067: val_loss improved from 1.82790 to 1.81639, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 68/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 1.8032 - dice_coef: 0.4173 - accuracy: 0.5564 - true_positive_rate: 0.2849 - iou_score: 0.0375 - val_loss: 1.8022 - val_dice_coef: 0.4784 - val_accuracy: 0.5612 - val_true_positive_rate: 0.3486 - val_iou_score: 0.0422\n",
      "\n",
      "Epoch 00068: val_loss improved from 1.81639 to 1.80216, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 69/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 787ms/step - loss: 1.7849 - dice_coef: 0.4283 - accuracy: 0.5605 - true_positive_rate: 0.2943 - iou_score: 0.0383 - val_loss: 1.8000 - val_dice_coef: 0.4696 - val_accuracy: 0.5613 - val_true_positive_rate: 0.3382 - val_iou_score: 0.0412\n",
      "\n",
      "Epoch 00069: val_loss improved from 1.80216 to 1.79999, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 70/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 87s 852ms/step - loss: 1.7669 - dice_coef: 0.4359 - accuracy: 0.5613 - true_positive_rate: 0.3019 - iou_score: 0.0390 - val_loss: 1.7854 - val_dice_coef: 0.4807 - val_accuracy: 0.5630 - val_true_positive_rate: 0.3520 - val_iou_score: 0.0417\n",
      "\n",
      "Epoch 00070: val_loss improved from 1.79999 to 1.78535, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 71/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 87s 853ms/step - loss: 1.7646 - dice_coef: 0.4317 - accuracy: 0.5599 - true_positive_rate: 0.2989 - iou_score: 0.0387 - val_loss: 1.7745 - val_dice_coef: 0.4804 - val_accuracy: 0.5630 - val_true_positive_rate: 0.3504 - val_iou_score: 0.0418\n",
      "\n",
      "Epoch 00071: val_loss improved from 1.78535 to 1.77449, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 72/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 1.7441 - dice_coef: 0.4390 - accuracy: 0.5629 - true_positive_rate: 0.3049 - iou_score: 0.0393 - val_loss: 1.7660 - val_dice_coef: 0.4871 - val_accuracy: 0.5638 - val_true_positive_rate: 0.3589 - val_iou_score: 0.0424\n",
      "\n",
      "Epoch 00072: val_loss improved from 1.77449 to 1.76599, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 73/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 1.7293 - dice_coef: 0.4410 - accuracy: 0.5634 - true_positive_rate: 0.3068 - iou_score: 0.0394 - val_loss: 1.7594 - val_dice_coef: 0.4912 - val_accuracy: 0.5655 - val_true_positive_rate: 0.3648 - val_iou_score: 0.0427\n",
      "\n",
      "Epoch 00073: val_loss improved from 1.76599 to 1.75943, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 74/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 1.7250 - dice_coef: 0.4449 - accuracy: 0.5653 - true_positive_rate: 0.3113 - iou_score: 0.0397 - val_loss: 1.7468 - val_dice_coef: 0.4883 - val_accuracy: 0.5658 - val_true_positive_rate: 0.3602 - val_iou_score: 0.0431\n",
      "\n",
      "Epoch 00074: val_loss improved from 1.75943 to 1.74677, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 75/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 1.7113 - dice_coef: 0.4516 - accuracy: 0.5658 - true_positive_rate: 0.3168 - iou_score: 0.0403 - val_loss: 1.7387 - val_dice_coef: 0.4840 - val_accuracy: 0.5654 - val_true_positive_rate: 0.3542 - val_iou_score: 0.0429\n",
      "\n",
      "Epoch 00075: val_loss improved from 1.74677 to 1.73866, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 76/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 786ms/step - loss: 1.7046 - dice_coef: 0.4483 - accuracy: 0.5667 - true_positive_rate: 0.3148 - iou_score: 0.0401 - val_loss: 1.7236 - val_dice_coef: 0.4921 - val_accuracy: 0.5663 - val_true_positive_rate: 0.3647 - val_iou_score: 0.0440\n",
      "\n",
      "Epoch 00076: val_loss improved from 1.73866 to 1.72355, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 77/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.6982 - dice_coef: 0.4498 - accuracy: 0.5661 - true_positive_rate: 0.3164 - iou_score: 0.0403 - val_loss: 1.7294 - val_dice_coef: 0.4927 - val_accuracy: 0.5675 - val_true_positive_rate: 0.3650 - val_iou_score: 0.0433\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 1.72355\n",
      "Epoch 78/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 1.6945 - dice_coef: 0.4522 - accuracy: 0.5671 - true_positive_rate: 0.3192 - iou_score: 0.0404 - val_loss: 1.7185 - val_dice_coef: 0.4949 - val_accuracy: 0.5677 - val_true_positive_rate: 0.3680 - val_iou_score: 0.0439\n",
      "\n",
      "Epoch 00078: val_loss improved from 1.72355 to 1.71845, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 79/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 1.6862 - dice_coef: 0.4529 - accuracy: 0.5663 - true_positive_rate: 0.3203 - iou_score: 0.0404 - val_loss: 1.7083 - val_dice_coef: 0.4970 - val_accuracy: 0.5682 - val_true_positive_rate: 0.3706 - val_iou_score: 0.0438\n",
      "\n",
      "Epoch 00079: val_loss improved from 1.71845 to 1.70830, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 80/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 1.6643 - dice_coef: 0.4597 - accuracy: 0.5700 - true_positive_rate: 0.3260 - iou_score: 0.0411 - val_loss: 1.7050 - val_dice_coef: 0.5028 - val_accuracy: 0.5686 - val_true_positive_rate: 0.3772 - val_iou_score: 0.0442\n",
      "\n",
      "Epoch 00080: val_loss improved from 1.70830 to 1.70496, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 81/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 1.6531 - dice_coef: 0.4653 - accuracy: 0.5721 - true_positive_rate: 0.3317 - iou_score: 0.0415 - val_loss: 1.6972 - val_dice_coef: 0.5010 - val_accuracy: 0.5689 - val_true_positive_rate: 0.3748 - val_iou_score: 0.0445\n",
      "\n",
      "Epoch 00081: val_loss improved from 1.70496 to 1.69718, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 82/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.6389 - dice_coef: 0.4691 - accuracy: 0.5745 - true_positive_rate: 0.3350 - iou_score: 0.0418 - val_loss: 1.6913 - val_dice_coef: 0.5076 - val_accuracy: 0.5704 - val_true_positive_rate: 0.3833 - val_iou_score: 0.0444\n",
      "\n",
      "Epoch 00082: val_loss improved from 1.69718 to 1.69134, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 83/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 783ms/step - loss: 1.6390 - dice_coef: 0.4718 - accuracy: 0.5723 - true_positive_rate: 0.3389 - iou_score: 0.0419 - val_loss: 1.6784 - val_dice_coef: 0.5078 - val_accuracy: 0.5706 - val_true_positive_rate: 0.3831 - val_iou_score: 0.0448\n",
      "\n",
      "Epoch 00083: val_loss improved from 1.69134 to 1.67836, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 84/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.6231 - dice_coef: 0.4761 - accuracy: 0.5758 - true_positive_rate: 0.3426 - iou_score: 0.0425 - val_loss: 1.6775 - val_dice_coef: 0.5056 - val_accuracy: 0.5710 - val_true_positive_rate: 0.3805 - val_iou_score: 0.0449\n",
      "\n",
      "Epoch 00084: val_loss improved from 1.67836 to 1.67751, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 85/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 1.6136 - dice_coef: 0.4753 - accuracy: 0.5774 - true_positive_rate: 0.3417 - iou_score: 0.0426 - val_loss: 1.6718 - val_dice_coef: 0.5102 - val_accuracy: 0.5711 - val_true_positive_rate: 0.3866 - val_iou_score: 0.0454\n",
      "\n",
      "Epoch 00085: val_loss improved from 1.67751 to 1.67178, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 86/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.6126 - dice_coef: 0.4747 - accuracy: 0.5781 - true_positive_rate: 0.3421 - iou_score: 0.0425 - val_loss: 1.6593 - val_dice_coef: 0.5086 - val_accuracy: 0.5721 - val_true_positive_rate: 0.3832 - val_iou_score: 0.0457\n",
      "\n",
      "Epoch 00086: val_loss improved from 1.67178 to 1.65933, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 87/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 1.6007 - dice_coef: 0.4785 - accuracy: 0.5778 - true_positive_rate: 0.3457 - iou_score: 0.0429 - val_loss: 1.6516 - val_dice_coef: 0.5142 - val_accuracy: 0.5724 - val_true_positive_rate: 0.3917 - val_iou_score: 0.0459\n",
      "\n",
      "Epoch 00087: val_loss improved from 1.65933 to 1.65157, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 88/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 1.5913 - dice_coef: 0.4825 - accuracy: 0.5780 - true_positive_rate: 0.3492 - iou_score: 0.0430 - val_loss: 1.6495 - val_dice_coef: 0.5099 - val_accuracy: 0.5726 - val_true_positive_rate: 0.3847 - val_iou_score: 0.0455\n",
      "\n",
      "Epoch 00088: val_loss improved from 1.65157 to 1.64948, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 89/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 1.5817 - dice_coef: 0.4846 - accuracy: 0.5803 - true_positive_rate: 0.3519 - iou_score: 0.0434 - val_loss: 1.6484 - val_dice_coef: 0.5176 - val_accuracy: 0.5725 - val_true_positive_rate: 0.3956 - val_iou_score: 0.0462\n",
      "\n",
      "Epoch 00089: val_loss improved from 1.64948 to 1.64838, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 90/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 1.5809 - dice_coef: 0.4860 - accuracy: 0.5804 - true_positive_rate: 0.3537 - iou_score: 0.0436 - val_loss: 1.6428 - val_dice_coef: 0.5196 - val_accuracy: 0.5729 - val_true_positive_rate: 0.3986 - val_iou_score: 0.0465\n",
      "\n",
      "Epoch 00090: val_loss improved from 1.64838 to 1.64279, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 91/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 1.5791 - dice_coef: 0.4865 - accuracy: 0.5797 - true_positive_rate: 0.3548 - iou_score: 0.0435 - val_loss: 1.6376 - val_dice_coef: 0.5192 - val_accuracy: 0.5734 - val_true_positive_rate: 0.3971 - val_iou_score: 0.0462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00091: val_loss improved from 1.64279 to 1.63764, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 92/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 1.5610 - dice_coef: 0.4890 - accuracy: 0.5827 - true_positive_rate: 0.3579 - iou_score: 0.0438 - val_loss: 1.6233 - val_dice_coef: 0.5149 - val_accuracy: 0.5732 - val_true_positive_rate: 0.3912 - val_iou_score: 0.0458\n",
      "\n",
      "Epoch 00092: val_loss improved from 1.63764 to 1.62329, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 93/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 1.5586 - dice_coef: 0.4915 - accuracy: 0.5817 - true_positive_rate: 0.3597 - iou_score: 0.0440 - val_loss: 1.6162 - val_dice_coef: 0.5238 - val_accuracy: 0.5729 - val_true_positive_rate: 0.4037 - val_iou_score: 0.0472\n",
      "\n",
      "Epoch 00093: val_loss improved from 1.62329 to 1.61623, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 94/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 1.5572 - dice_coef: 0.4905 - accuracy: 0.5820 - true_positive_rate: 0.3589 - iou_score: 0.0442 - val_loss: 1.6154 - val_dice_coef: 0.5233 - val_accuracy: 0.5746 - val_true_positive_rate: 0.4023 - val_iou_score: 0.0470\n",
      "\n",
      "Epoch 00094: val_loss improved from 1.61623 to 1.61536, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 95/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 1.5447 - dice_coef: 0.4976 - accuracy: 0.5848 - true_positive_rate: 0.3665 - iou_score: 0.0444 - val_loss: 1.6049 - val_dice_coef: 0.5190 - val_accuracy: 0.5742 - val_true_positive_rate: 0.3975 - val_iou_score: 0.0469\n",
      "\n",
      "Epoch 00095: val_loss improved from 1.61536 to 1.60492, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 96/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 1.5279 - dice_coef: 0.5022 - accuracy: 0.5889 - true_positive_rate: 0.3700 - iou_score: 0.0451 - val_loss: 1.5949 - val_dice_coef: 0.5280 - val_accuracy: 0.5741 - val_true_positive_rate: 0.4087 - val_iou_score: 0.0472\n",
      "\n",
      "Epoch 00096: val_loss improved from 1.60492 to 1.59495, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 97/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 1.5158 - dice_coef: 0.5072 - accuracy: 0.5898 - true_positive_rate: 0.3760 - iou_score: 0.0453 - val_loss: 1.5929 - val_dice_coef: 0.5282 - val_accuracy: 0.5754 - val_true_positive_rate: 0.4096 - val_iou_score: 0.0471\n",
      "\n",
      "Epoch 00097: val_loss improved from 1.59495 to 1.59286, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 98/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 1.5235 - dice_coef: 0.4997 - accuracy: 0.5860 - true_positive_rate: 0.3695 - iou_score: 0.0450 - val_loss: 1.5921 - val_dice_coef: 0.5239 - val_accuracy: 0.5751 - val_true_positive_rate: 0.4053 - val_iou_score: 0.0477\n",
      "\n",
      "Epoch 00098: val_loss improved from 1.59286 to 1.59212, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 99/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 1.5023 - dice_coef: 0.5107 - accuracy: 0.5914 - true_positive_rate: 0.3796 - iou_score: 0.0458 - val_loss: 1.5844 - val_dice_coef: 0.5262 - val_accuracy: 0.5752 - val_true_positive_rate: 0.4059 - val_iou_score: 0.0477\n",
      "\n",
      "Epoch 00099: val_loss improved from 1.59212 to 1.58437, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 100/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 1.5021 - dice_coef: 0.5077 - accuracy: 0.5905 - true_positive_rate: 0.3773 - iou_score: 0.0457 - val_loss: 1.5784 - val_dice_coef: 0.5277 - val_accuracy: 0.5757 - val_true_positive_rate: 0.4084 - val_iou_score: 0.0481\n",
      "\n",
      "Epoch 00100: val_loss improved from 1.58437 to 1.57837, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 101/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 1.4949 - dice_coef: 0.5093 - accuracy: 0.5902 - true_positive_rate: 0.3788 - iou_score: 0.0459 - val_loss: 1.5806 - val_dice_coef: 0.5321 - val_accuracy: 0.5765 - val_true_positive_rate: 0.4140 - val_iou_score: 0.0478\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 1.57837\n",
      "Epoch 102/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 1.4868 - dice_coef: 0.5138 - accuracy: 0.5926 - true_positive_rate: 0.3835 - iou_score: 0.0464 - val_loss: 1.5720 - val_dice_coef: 0.5348 - val_accuracy: 0.5773 - val_true_positive_rate: 0.4185 - val_iou_score: 0.0484\n",
      "\n",
      "Epoch 00102: val_loss improved from 1.57837 to 1.57198, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 103/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 1.4752 - dice_coef: 0.5158 - accuracy: 0.5931 - true_positive_rate: 0.3850 - iou_score: 0.0465 - val_loss: 1.5659 - val_dice_coef: 0.5312 - val_accuracy: 0.5770 - val_true_positive_rate: 0.4131 - val_iou_score: 0.0484\n",
      "\n",
      "Epoch 00103: val_loss improved from 1.57198 to 1.56586, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 104/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.4741 - dice_coef: 0.5174 - accuracy: 0.5927 - true_positive_rate: 0.3876 - iou_score: 0.0465 - val_loss: 1.5648 - val_dice_coef: 0.5319 - val_accuracy: 0.5772 - val_true_positive_rate: 0.4156 - val_iou_score: 0.0483\n",
      "\n",
      "Epoch 00104: val_loss improved from 1.56586 to 1.56483, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 105/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 1.4700 - dice_coef: 0.5181 - accuracy: 0.5932 - true_positive_rate: 0.3889 - iou_score: 0.0468 - val_loss: 1.5597 - val_dice_coef: 0.5341 - val_accuracy: 0.5775 - val_true_positive_rate: 0.4176 - val_iou_score: 0.0483\n",
      "\n",
      "Epoch 00105: val_loss improved from 1.56483 to 1.55970, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 106/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 1.4536 - dice_coef: 0.5198 - accuracy: 0.5964 - true_positive_rate: 0.3900 - iou_score: 0.0474 - val_loss: 1.5548 - val_dice_coef: 0.5322 - val_accuracy: 0.5782 - val_true_positive_rate: 0.4146 - val_iou_score: 0.0483\n",
      "\n",
      "Epoch 00106: val_loss improved from 1.55970 to 1.55479, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 107/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.4612 - dice_coef: 0.5198 - accuracy: 0.5950 - true_positive_rate: 0.3912 - iou_score: 0.0467 - val_loss: 1.5477 - val_dice_coef: 0.5350 - val_accuracy: 0.5778 - val_true_positive_rate: 0.4204 - val_iou_score: 0.0488\n",
      "\n",
      "Epoch 00107: val_loss improved from 1.55479 to 1.54767, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 108/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 1.4501 - dice_coef: 0.5215 - accuracy: 0.5966 - true_positive_rate: 0.3933 - iou_score: 0.0473 - val_loss: 1.5397 - val_dice_coef: 0.5301 - val_accuracy: 0.5777 - val_true_positive_rate: 0.4103 - val_iou_score: 0.0485\n",
      "\n",
      "Epoch 00108: val_loss improved from 1.54767 to 1.53967, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 109/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 80s 785ms/step - loss: 1.4467 - dice_coef: 0.5230 - accuracy: 0.5965 - true_positive_rate: 0.3943 - iou_score: 0.0472 - val_loss: 1.5506 - val_dice_coef: 0.5396 - val_accuracy: 0.5790 - val_true_positive_rate: 0.4262 - val_iou_score: 0.0499\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 1.53967\n",
      "Epoch 110/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 1.4473 - dice_coef: 0.5246 - accuracy: 0.5956 - true_positive_rate: 0.3961 - iou_score: 0.0474 - val_loss: 1.5415 - val_dice_coef: 0.5378 - val_accuracy: 0.5777 - val_true_positive_rate: 0.4234 - val_iou_score: 0.0494\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 1.53967\n",
      "Epoch 111/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 786ms/step - loss: 1.4344 - dice_coef: 0.5274 - accuracy: 0.5982 - true_positive_rate: 0.3993 - iou_score: 0.0479 - val_loss: 1.5337 - val_dice_coef: 0.5384 - val_accuracy: 0.5787 - val_true_positive_rate: 0.4255 - val_iou_score: 0.0488\n",
      "\n",
      "Epoch 00111: val_loss improved from 1.53967 to 1.53375, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 112/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 1.4256 - dice_coef: 0.5272 - accuracy: 0.5991 - true_positive_rate: 0.3995 - iou_score: 0.0479 - val_loss: 1.5346 - val_dice_coef: 0.5408 - val_accuracy: 0.5787 - val_true_positive_rate: 0.4271 - val_iou_score: 0.0497\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 1.53375\n",
      "Epoch 113/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.4280 - dice_coef: 0.5284 - accuracy: 0.5993 - true_positive_rate: 0.4011 - iou_score: 0.0476 - val_loss: 1.5295 - val_dice_coef: 0.5439 - val_accuracy: 0.5795 - val_true_positive_rate: 0.4324 - val_iou_score: 0.0496\n",
      "\n",
      "Epoch 00113: val_loss improved from 1.53375 to 1.52948, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 114/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.4144 - dice_coef: 0.5336 - accuracy: 0.6019 - true_positive_rate: 0.4056 - iou_score: 0.0487 - val_loss: 1.5248 - val_dice_coef: 0.5388 - val_accuracy: 0.5792 - val_true_positive_rate: 0.4240 - val_iou_score: 0.0495\n",
      "\n",
      "Epoch 00114: val_loss improved from 1.52948 to 1.52476, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 115/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 1.4120 - dice_coef: 0.5357 - accuracy: 0.6020 - true_positive_rate: 0.4084 - iou_score: 0.0489 - val_loss: 1.5222 - val_dice_coef: 0.5427 - val_accuracy: 0.5801 - val_true_positive_rate: 0.4304 - val_iou_score: 0.0502\n",
      "\n",
      "Epoch 00115: val_loss improved from 1.52476 to 1.52219, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 116/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.4057 - dice_coef: 0.5357 - accuracy: 0.6025 - true_positive_rate: 0.4097 - iou_score: 0.0487 - val_loss: 1.5154 - val_dice_coef: 0.5428 - val_accuracy: 0.5800 - val_true_positive_rate: 0.4310 - val_iou_score: 0.0505\n",
      "\n",
      "Epoch 00116: val_loss improved from 1.52219 to 1.51538, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 117/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.3974 - dice_coef: 0.5365 - accuracy: 0.6052 - true_positive_rate: 0.4089 - iou_score: 0.0491 - val_loss: 1.5056 - val_dice_coef: 0.5390 - val_accuracy: 0.5815 - val_true_positive_rate: 0.4256 - val_iou_score: 0.0497\n",
      "\n",
      "Epoch 00117: val_loss improved from 1.51538 to 1.50560, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 118/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 1.3982 - dice_coef: 0.5388 - accuracy: 0.6042 - true_positive_rate: 0.4127 - iou_score: 0.0492 - val_loss: 1.4998 - val_dice_coef: 0.5428 - val_accuracy: 0.5815 - val_true_positive_rate: 0.4315 - val_iou_score: 0.0499\n",
      "\n",
      "Epoch 00118: val_loss improved from 1.50560 to 1.49976, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 119/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.3913 - dice_coef: 0.5386 - accuracy: 0.6050 - true_positive_rate: 0.4123 - iou_score: 0.0496 - val_loss: 1.5078 - val_dice_coef: 0.5457 - val_accuracy: 0.5823 - val_true_positive_rate: 0.4348 - val_iou_score: 0.0505\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 1.49976\n",
      "Epoch 120/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.3908 - dice_coef: 0.5397 - accuracy: 0.6041 - true_positive_rate: 0.4136 - iou_score: 0.0494 - val_loss: 1.5052 - val_dice_coef: 0.5438 - val_accuracy: 0.5820 - val_true_positive_rate: 0.4320 - val_iou_score: 0.0502\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 1.49976\n",
      "Epoch 121/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.3753 - dice_coef: 0.5449 - accuracy: 0.6074 - true_positive_rate: 0.4186 - iou_score: 0.0498 - val_loss: 1.4957 - val_dice_coef: 0.5467 - val_accuracy: 0.5819 - val_true_positive_rate: 0.4384 - val_iou_score: 0.0509\n",
      "\n",
      "Epoch 00121: val_loss improved from 1.49976 to 1.49570, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 122/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 786ms/step - loss: 1.3685 - dice_coef: 0.5452 - accuracy: 0.6078 - true_positive_rate: 0.4192 - iou_score: 0.0499 - val_loss: 1.4914 - val_dice_coef: 0.5456 - val_accuracy: 0.5818 - val_true_positive_rate: 0.4344 - val_iou_score: 0.0506\n",
      "\n",
      "Epoch 00122: val_loss improved from 1.49570 to 1.49141, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 123/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 791ms/step - loss: 1.3707 - dice_coef: 0.5457 - accuracy: 0.6072 - true_positive_rate: 0.4199 - iou_score: 0.0502 - val_loss: 1.4987 - val_dice_coef: 0.5469 - val_accuracy: 0.5827 - val_true_positive_rate: 0.4365 - val_iou_score: 0.0508\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 1.49141\n",
      "Epoch 124/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 1.3674 - dice_coef: 0.5452 - accuracy: 0.6091 - true_positive_rate: 0.4200 - iou_score: 0.0501 - val_loss: 1.4966 - val_dice_coef: 0.5475 - val_accuracy: 0.5831 - val_true_positive_rate: 0.4370 - val_iou_score: 0.0510\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 1.49141\n",
      "Epoch 125/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 786ms/step - loss: 1.3673 - dice_coef: 0.5460 - accuracy: 0.6073 - true_positive_rate: 0.4216 - iou_score: 0.0503 - val_loss: 1.4928 - val_dice_coef: 0.5456 - val_accuracy: 0.5840 - val_true_positive_rate: 0.4358 - val_iou_score: 0.0507\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 1.49141\n",
      "Epoch 126/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.3611 - dice_coef: 0.5488 - accuracy: 0.6095 - true_positive_rate: 0.4241 - iou_score: 0.0504 - val_loss: 1.4932 - val_dice_coef: 0.5489 - val_accuracy: 0.5839 - val_true_positive_rate: 0.4406 - val_iou_score: 0.0509\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 1.49141\n",
      "Epoch 127/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 788ms/step - loss: 1.3507 - dice_coef: 0.5485 - accuracy: 0.6109 - true_positive_rate: 0.4238 - iou_score: 0.0508 - val_loss: 1.4814 - val_dice_coef: 0.5505 - val_accuracy: 0.5833 - val_true_positive_rate: 0.4428 - val_iou_score: 0.0512\n",
      "\n",
      "Epoch 00127: val_loss improved from 1.49141 to 1.48137, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 128/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 786ms/step - loss: 1.3406 - dice_coef: 0.5536 - accuracy: 0.6133 - true_positive_rate: 0.4283 - iou_score: 0.0515 - val_loss: 1.4804 - val_dice_coef: 0.5501 - val_accuracy: 0.5836 - val_true_positive_rate: 0.4410 - val_iou_score: 0.0512\n",
      "\n",
      "Epoch 00128: val_loss improved from 1.48137 to 1.48042, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 129/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 788ms/step - loss: 1.3434 - dice_coef: 0.5536 - accuracy: 0.6126 - true_positive_rate: 0.4297 - iou_score: 0.0515 - val_loss: 1.4815 - val_dice_coef: 0.5513 - val_accuracy: 0.5844 - val_true_positive_rate: 0.4438 - val_iou_score: 0.0516\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 1.48042\n",
      "Epoch 130/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.3349 - dice_coef: 0.5571 - accuracy: 0.6139 - true_positive_rate: 0.4331 - iou_score: 0.0517 - val_loss: 1.4666 - val_dice_coef: 0.5508 - val_accuracy: 0.5852 - val_true_positive_rate: 0.4444 - val_iou_score: 0.0516\n",
      "\n",
      "Epoch 00130: val_loss improved from 1.48042 to 1.46661, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 131/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 786ms/step - loss: 1.3354 - dice_coef: 0.5561 - accuracy: 0.6125 - true_positive_rate: 0.4325 - iou_score: 0.0514 - val_loss: 1.4745 - val_dice_coef: 0.5523 - val_accuracy: 0.5851 - val_true_positive_rate: 0.4449 - val_iou_score: 0.0522\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 1.46661\n",
      "Epoch 132/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 783ms/step - loss: 1.3195 - dice_coef: 0.5596 - accuracy: 0.6147 - true_positive_rate: 0.4352 - iou_score: 0.0521 - val_loss: 1.4745 - val_dice_coef: 0.5517 - val_accuracy: 0.5859 - val_true_positive_rate: 0.4458 - val_iou_score: 0.0521\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 1.46661\n",
      "Epoch 133/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 786ms/step - loss: 1.3212 - dice_coef: 0.5613 - accuracy: 0.6165 - true_positive_rate: 0.4385 - iou_score: 0.0519 - val_loss: 1.4575 - val_dice_coef: 0.5497 - val_accuracy: 0.5854 - val_true_positive_rate: 0.4406 - val_iou_score: 0.0521\n",
      "\n",
      "Epoch 00133: val_loss improved from 1.46661 to 1.45747, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 134/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.3149 - dice_coef: 0.5627 - accuracy: 0.6182 - true_positive_rate: 0.4399 - iou_score: 0.0524 - val_loss: 1.4681 - val_dice_coef: 0.5519 - val_accuracy: 0.5867 - val_true_positive_rate: 0.4454 - val_iou_score: 0.0526\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 1.45747\n",
      "Epoch 135/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 782ms/step - loss: 1.3079 - dice_coef: 0.5634 - accuracy: 0.6185 - true_positive_rate: 0.4413 - iou_score: 0.0527 - val_loss: 1.4566 - val_dice_coef: 0.5549 - val_accuracy: 0.5862 - val_true_positive_rate: 0.4494 - val_iou_score: 0.0522\n",
      "\n",
      "Epoch 00135: val_loss improved from 1.45747 to 1.45657, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 136/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 783ms/step - loss: 1.3138 - dice_coef: 0.5616 - accuracy: 0.6179 - true_positive_rate: 0.4383 - iou_score: 0.0523 - val_loss: 1.4544 - val_dice_coef: 0.5542 - val_accuracy: 0.5868 - val_true_positive_rate: 0.4500 - val_iou_score: 0.0523\n",
      "\n",
      "Epoch 00136: val_loss improved from 1.45657 to 1.45444, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 137/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 782ms/step - loss: 1.3023 - dice_coef: 0.5677 - accuracy: 0.6199 - true_positive_rate: 0.4455 - iou_score: 0.0529 - val_loss: 1.4510 - val_dice_coef: 0.5532 - val_accuracy: 0.5864 - val_true_positive_rate: 0.4461 - val_iou_score: 0.0517\n",
      "\n",
      "Epoch 00137: val_loss improved from 1.45444 to 1.45098, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 138/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 782ms/step - loss: 1.3074 - dice_coef: 0.5651 - accuracy: 0.6169 - true_positive_rate: 0.4442 - iou_score: 0.0526 - val_loss: 1.4461 - val_dice_coef: 0.5518 - val_accuracy: 0.5866 - val_true_positive_rate: 0.4440 - val_iou_score: 0.0520\n",
      "\n",
      "Epoch 00138: val_loss improved from 1.45098 to 1.44608, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 139/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.2981 - dice_coef: 0.5684 - accuracy: 0.6206 - true_positive_rate: 0.4466 - iou_score: 0.0532 - val_loss: 1.4562 - val_dice_coef: 0.5528 - val_accuracy: 0.5876 - val_true_positive_rate: 0.4476 - val_iou_score: 0.0518\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 1.44608\n",
      "Epoch 140/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 783ms/step - loss: 1.3017 - dice_coef: 0.5656 - accuracy: 0.6163 - true_positive_rate: 0.4447 - iou_score: 0.0523 - val_loss: 1.4512 - val_dice_coef: 0.5541 - val_accuracy: 0.5863 - val_true_positive_rate: 0.4473 - val_iou_score: 0.0532\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 1.44608\n",
      "Epoch 141/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 781ms/step - loss: 1.2822 - dice_coef: 0.5723 - accuracy: 0.6211 - true_positive_rate: 0.4502 - iou_score: 0.0537 - val_loss: 1.4542 - val_dice_coef: 0.5592 - val_accuracy: 0.5878 - val_true_positive_rate: 0.4561 - val_iou_score: 0.0524\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 1.44608\n",
      "Epoch 142/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.3027 - dice_coef: 0.5643 - accuracy: 0.6177 - true_positive_rate: 0.4431 - iou_score: 0.0526 - val_loss: 1.4462 - val_dice_coef: 0.5533 - val_accuracy: 0.5869 - val_true_positive_rate: 0.4472 - val_iou_score: 0.0524\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 1.44608\n",
      "Epoch 143/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 782ms/step - loss: 1.2749 - dice_coef: 0.5739 - accuracy: 0.6239 - true_positive_rate: 0.4542 - iou_score: 0.0534 - val_loss: 1.4587 - val_dice_coef: 0.5602 - val_accuracy: 0.5876 - val_true_positive_rate: 0.4589 - val_iou_score: 0.0530\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 1.44608\n",
      "Epoch 144/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 782ms/step - loss: 1.2686 - dice_coef: 0.5774 - accuracy: 0.6253 - true_positive_rate: 0.4570 - iou_score: 0.0544 - val_loss: 1.4444 - val_dice_coef: 0.5619 - val_accuracy: 0.5883 - val_true_positive_rate: 0.4603 - val_iou_score: 0.0536\n",
      "\n",
      "Epoch 00144: val_loss improved from 1.44608 to 1.44441, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 145/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 80s 782ms/step - loss: 1.2667 - dice_coef: 0.5743 - accuracy: 0.6246 - true_positive_rate: 0.4539 - iou_score: 0.0544 - val_loss: 1.4385 - val_dice_coef: 0.5569 - val_accuracy: 0.5890 - val_true_positive_rate: 0.4526 - val_iou_score: 0.0528\n",
      "\n",
      "Epoch 00145: val_loss improved from 1.44441 to 1.43853, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 146/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 782ms/step - loss: 1.2670 - dice_coef: 0.5766 - accuracy: 0.6251 - true_positive_rate: 0.4570 - iou_score: 0.0545 - val_loss: 1.4409 - val_dice_coef: 0.5554 - val_accuracy: 0.5891 - val_true_positive_rate: 0.4499 - val_iou_score: 0.0537\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 1.43853\n",
      "Epoch 147/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 782ms/step - loss: 1.2632 - dice_coef: 0.5752 - accuracy: 0.6252 - true_positive_rate: 0.4549 - iou_score: 0.0545 - val_loss: 1.4347 - val_dice_coef: 0.5579 - val_accuracy: 0.5895 - val_true_positive_rate: 0.4540 - val_iou_score: 0.0533\n",
      "\n",
      "Epoch 00147: val_loss improved from 1.43853 to 1.43473, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 148/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 782ms/step - loss: 1.2809 - dice_coef: 0.5686 - accuracy: 0.6204 - true_positive_rate: 0.4492 - iou_score: 0.0536 - val_loss: 1.4400 - val_dice_coef: 0.5657 - val_accuracy: 0.5895 - val_true_positive_rate: 0.4676 - val_iou_score: 0.0541\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 1.43473\n",
      "Epoch 149/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 781ms/step - loss: 1.2573 - dice_coef: 0.5770 - accuracy: 0.6257 - true_positive_rate: 0.4575 - iou_score: 0.0544 - val_loss: 1.4273 - val_dice_coef: 0.5571 - val_accuracy: 0.5899 - val_true_positive_rate: 0.4535 - val_iou_score: 0.0538\n",
      "\n",
      "Epoch 00149: val_loss improved from 1.43473 to 1.42726, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 150/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 783ms/step - loss: 1.2522 - dice_coef: 0.5780 - accuracy: 0.6272 - true_positive_rate: 0.4589 - iou_score: 0.0548 - val_loss: 1.4317 - val_dice_coef: 0.5631 - val_accuracy: 0.5893 - val_true_positive_rate: 0.4607 - val_iou_score: 0.0545\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 1.42726\n",
      "Epoch 151/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 781ms/step - loss: 1.2478 - dice_coef: 0.5811 - accuracy: 0.6278 - true_positive_rate: 0.4617 - iou_score: 0.0547 - val_loss: 1.4287 - val_dice_coef: 0.5606 - val_accuracy: 0.5895 - val_true_positive_rate: 0.4585 - val_iou_score: 0.0533\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 1.42726\n",
      "Epoch 152/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 782ms/step - loss: 1.2373 - dice_coef: 0.5854 - accuracy: 0.6300 - true_positive_rate: 0.4662 - iou_score: 0.0557 - val_loss: 1.4334 - val_dice_coef: 0.5638 - val_accuracy: 0.5899 - val_true_positive_rate: 0.4633 - val_iou_score: 0.0535\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 1.42726\n",
      "Epoch 153/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 782ms/step - loss: 1.2532 - dice_coef: 0.5786 - accuracy: 0.6267 - true_positive_rate: 0.4608 - iou_score: 0.0550 - val_loss: 1.4189 - val_dice_coef: 0.5630 - val_accuracy: 0.5897 - val_true_positive_rate: 0.4626 - val_iou_score: 0.0542\n",
      "\n",
      "Epoch 00153: val_loss improved from 1.42726 to 1.41889, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 154/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 783ms/step - loss: 1.2480 - dice_coef: 0.5762 - accuracy: 0.6262 - true_positive_rate: 0.4565 - iou_score: 0.0552 - val_loss: 1.4220 - val_dice_coef: 0.5586 - val_accuracy: 0.5912 - val_true_positive_rate: 0.4542 - val_iou_score: 0.0534\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 1.41889\n",
      "Epoch 155/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 782ms/step - loss: 1.2332 - dice_coef: 0.5848 - accuracy: 0.6306 - true_positive_rate: 0.4666 - iou_score: 0.0558 - val_loss: 1.4259 - val_dice_coef: 0.5647 - val_accuracy: 0.5918 - val_true_positive_rate: 0.4638 - val_iou_score: 0.0538\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 1.41889\n",
      "Epoch 156/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 92s 900ms/step - loss: 1.2388 - dice_coef: 0.5828 - accuracy: 0.6276 - true_positive_rate: 0.4653 - iou_score: 0.0553 - val_loss: 1.4369 - val_dice_coef: 0.5650 - val_accuracy: 0.5904 - val_true_positive_rate: 0.4684 - val_iou_score: 0.0536\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 1.41889\n",
      "Epoch 157/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 84s 826ms/step - loss: 1.2322 - dice_coef: 0.5848 - accuracy: 0.6313 - true_positive_rate: 0.4665 - iou_score: 0.0558 - val_loss: 1.4142 - val_dice_coef: 0.5647 - val_accuracy: 0.5915 - val_true_positive_rate: 0.4650 - val_iou_score: 0.0550\n",
      "\n",
      "Epoch 00157: val_loss improved from 1.41889 to 1.41421, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 158/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.2362 - dice_coef: 0.5822 - accuracy: 0.6296 - true_positive_rate: 0.4644 - iou_score: 0.0554 - val_loss: 1.4129 - val_dice_coef: 0.5629 - val_accuracy: 0.5909 - val_true_positive_rate: 0.4603 - val_iou_score: 0.0539\n",
      "\n",
      "Epoch 00158: val_loss improved from 1.41421 to 1.41294, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 159/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 783ms/step - loss: 1.2288 - dice_coef: 0.5881 - accuracy: 0.6301 - true_positive_rate: 0.4713 - iou_score: 0.0559 - val_loss: 1.4161 - val_dice_coef: 0.5650 - val_accuracy: 0.5918 - val_true_positive_rate: 0.4668 - val_iou_score: 0.0542\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 1.41294\n",
      "Epoch 160/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.2201 - dice_coef: 0.5895 - accuracy: 0.6325 - true_positive_rate: 0.4721 - iou_score: 0.0561 - val_loss: 1.4174 - val_dice_coef: 0.5654 - val_accuracy: 0.5920 - val_true_positive_rate: 0.4653 - val_iou_score: 0.0544\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 1.41294\n",
      "Epoch 161/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 783ms/step - loss: 1.2109 - dice_coef: 0.5938 - accuracy: 0.6359 - true_positive_rate: 0.4769 - iou_score: 0.0569 - val_loss: 1.4206 - val_dice_coef: 0.5652 - val_accuracy: 0.5911 - val_true_positive_rate: 0.4677 - val_iou_score: 0.0536\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 1.41294\n",
      "Epoch 162/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.2038 - dice_coef: 0.5944 - accuracy: 0.6369 - true_positive_rate: 0.4784 - iou_score: 0.0575 - val_loss: 1.4085 - val_dice_coef: 0.5636 - val_accuracy: 0.5912 - val_true_positive_rate: 0.4635 - val_iou_score: 0.0544\n",
      "\n",
      "Epoch 00162: val_loss improved from 1.41294 to 1.40846, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 163/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.2106 - dice_coef: 0.5909 - accuracy: 0.6348 - true_positive_rate: 0.4750 - iou_score: 0.0567 - val_loss: 1.4048 - val_dice_coef: 0.5641 - val_accuracy: 0.5913 - val_true_positive_rate: 0.4654 - val_iou_score: 0.0547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00163: val_loss improved from 1.40846 to 1.40484, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 164/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 783ms/step - loss: 1.2175 - dice_coef: 0.5908 - accuracy: 0.6340 - true_positive_rate: 0.4759 - iou_score: 0.0565 - val_loss: 1.4080 - val_dice_coef: 0.5671 - val_accuracy: 0.5917 - val_true_positive_rate: 0.4704 - val_iou_score: 0.0553\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 1.40484\n",
      "Epoch 165/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 783ms/step - loss: 1.2082 - dice_coef: 0.5914 - accuracy: 0.6356 - true_positive_rate: 0.4753 - iou_score: 0.0567 - val_loss: 1.4050 - val_dice_coef: 0.5662 - val_accuracy: 0.5915 - val_true_positive_rate: 0.4681 - val_iou_score: 0.0549\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 1.40484\n",
      "Epoch 166/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.1986 - dice_coef: 0.5982 - accuracy: 0.6383 - true_positive_rate: 0.4827 - iou_score: 0.0573 - val_loss: 1.4121 - val_dice_coef: 0.5717 - val_accuracy: 0.5927 - val_true_positive_rate: 0.4764 - val_iou_score: 0.0548\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 1.40484\n",
      "Epoch 167/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 783ms/step - loss: 1.2019 - dice_coef: 0.5962 - accuracy: 0.6362 - true_positive_rate: 0.4818 - iou_score: 0.0572 - val_loss: 1.4056 - val_dice_coef: 0.5667 - val_accuracy: 0.5928 - val_true_positive_rate: 0.4707 - val_iou_score: 0.0544\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 1.40484\n",
      "Epoch 168/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 783ms/step - loss: 1.1960 - dice_coef: 0.5962 - accuracy: 0.6383 - true_positive_rate: 0.4823 - iou_score: 0.0574 - val_loss: 1.4077 - val_dice_coef: 0.5718 - val_accuracy: 0.5928 - val_true_positive_rate: 0.4780 - val_iou_score: 0.0555\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 1.40484\n",
      "Epoch 169/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 783ms/step - loss: 1.1793 - dice_coef: 0.6021 - accuracy: 0.6416 - true_positive_rate: 0.4867 - iou_score: 0.0583 - val_loss: 1.4032 - val_dice_coef: 0.5642 - val_accuracy: 0.5931 - val_true_positive_rate: 0.4657 - val_iou_score: 0.0545\n",
      "\n",
      "Epoch 00169: val_loss improved from 1.40484 to 1.40325, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 170/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 783ms/step - loss: 1.1760 - dice_coef: 0.6060 - accuracy: 0.6438 - true_positive_rate: 0.4917 - iou_score: 0.0591 - val_loss: 1.4093 - val_dice_coef: 0.5706 - val_accuracy: 0.5935 - val_true_positive_rate: 0.4753 - val_iou_score: 0.0552\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 1.40325\n",
      "Epoch 171/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 783ms/step - loss: 1.1909 - dice_coef: 0.5972 - accuracy: 0.6381 - true_positive_rate: 0.4831 - iou_score: 0.0578 - val_loss: 1.4041 - val_dice_coef: 0.5656 - val_accuracy: 0.5930 - val_true_positive_rate: 0.4689 - val_iou_score: 0.0548\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 1.40325\n",
      "Epoch 172/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.1777 - dice_coef: 0.6031 - accuracy: 0.6413 - true_positive_rate: 0.4883 - iou_score: 0.0583 - val_loss: 1.3906 - val_dice_coef: 0.5675 - val_accuracy: 0.5926 - val_true_positive_rate: 0.4683 - val_iou_score: 0.0556\n",
      "\n",
      "Epoch 00172: val_loss improved from 1.40325 to 1.39055, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 173/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 783ms/step - loss: 1.1670 - dice_coef: 0.6077 - accuracy: 0.6453 - true_positive_rate: 0.4936 - iou_score: 0.0590 - val_loss: 1.3979 - val_dice_coef: 0.5677 - val_accuracy: 0.5929 - val_true_positive_rate: 0.4709 - val_iou_score: 0.0544\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 1.39055\n",
      "Epoch 174/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.1762 - dice_coef: 0.6035 - accuracy: 0.6417 - true_positive_rate: 0.4898 - iou_score: 0.0586 - val_loss: 1.4055 - val_dice_coef: 0.5716 - val_accuracy: 0.5937 - val_true_positive_rate: 0.4787 - val_iou_score: 0.0566\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 1.39055\n",
      "Epoch 175/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.1742 - dice_coef: 0.6038 - accuracy: 0.6424 - true_positive_rate: 0.4905 - iou_score: 0.0588 - val_loss: 1.3970 - val_dice_coef: 0.5690 - val_accuracy: 0.5926 - val_true_positive_rate: 0.4741 - val_iou_score: 0.0550\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 1.39055\n",
      "Epoch 176/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.1696 - dice_coef: 0.6058 - accuracy: 0.6422 - true_positive_rate: 0.4923 - iou_score: 0.0589 - val_loss: 1.3985 - val_dice_coef: 0.5733 - val_accuracy: 0.5939 - val_true_positive_rate: 0.4806 - val_iou_score: 0.0559\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 1.39055\n",
      "Epoch 177/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.1756 - dice_coef: 0.6024 - accuracy: 0.6407 - true_positive_rate: 0.4886 - iou_score: 0.0586 - val_loss: 1.4025 - val_dice_coef: 0.5708 - val_accuracy: 0.5931 - val_true_positive_rate: 0.4761 - val_iou_score: 0.0555\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 1.39055\n",
      "Epoch 178/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.1648 - dice_coef: 0.6064 - accuracy: 0.6457 - true_positive_rate: 0.4929 - iou_score: 0.0591 - val_loss: 1.3907 - val_dice_coef: 0.5676 - val_accuracy: 0.5929 - val_true_positive_rate: 0.4724 - val_iou_score: 0.0559\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 1.39055\n",
      "Epoch 179/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.1516 - dice_coef: 0.6117 - accuracy: 0.6480 - true_positive_rate: 0.4999 - iou_score: 0.0600 - val_loss: 1.3872 - val_dice_coef: 0.5685 - val_accuracy: 0.5933 - val_true_positive_rate: 0.4724 - val_iou_score: 0.0554\n",
      "\n",
      "Epoch 00179: val_loss improved from 1.39055 to 1.38719, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 180/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.1640 - dice_coef: 0.6077 - accuracy: 0.6445 - true_positive_rate: 0.4956 - iou_score: 0.0591 - val_loss: 1.3904 - val_dice_coef: 0.5700 - val_accuracy: 0.5931 - val_true_positive_rate: 0.4758 - val_iou_score: 0.0560\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 1.38719\n",
      "Epoch 181/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.1534 - dice_coef: 0.6122 - accuracy: 0.6479 - true_positive_rate: 0.5001 - iou_score: 0.0599 - val_loss: 1.3861 - val_dice_coef: 0.5726 - val_accuracy: 0.5944 - val_true_positive_rate: 0.4791 - val_iou_score: 0.0557\n",
      "\n",
      "Epoch 00181: val_loss improved from 1.38719 to 1.38608, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 182/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 783ms/step - loss: 1.1539 - dice_coef: 0.6126 - accuracy: 0.6471 - true_positive_rate: 0.5021 - iou_score: 0.0596 - val_loss: 1.3991 - val_dice_coef: 0.5740 - val_accuracy: 0.5934 - val_true_positive_rate: 0.4837 - val_iou_score: 0.0567\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 1.38608\n",
      "Epoch 183/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 783ms/step - loss: 1.1509 - dice_coef: 0.6115 - accuracy: 0.6471 - true_positive_rate: 0.5000 - iou_score: 0.0601 - val_loss: 1.3990 - val_dice_coef: 0.5764 - val_accuracy: 0.5937 - val_true_positive_rate: 0.4869 - val_iou_score: 0.0566\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 1.38608\n",
      "Epoch 184/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.1428 - dice_coef: 0.6144 - accuracy: 0.6498 - true_positive_rate: 0.5022 - iou_score: 0.0603 - val_loss: 1.3829 - val_dice_coef: 0.5726 - val_accuracy: 0.5944 - val_true_positive_rate: 0.4802 - val_iou_score: 0.0565\n",
      "\n",
      "Epoch 00184: val_loss improved from 1.38608 to 1.38285, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 185/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.1395 - dice_coef: 0.6132 - accuracy: 0.6501 - true_positive_rate: 0.5020 - iou_score: 0.0603 - val_loss: 1.3851 - val_dice_coef: 0.5759 - val_accuracy: 0.5947 - val_true_positive_rate: 0.4847 - val_iou_score: 0.0569\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 1.38285\n",
      "Epoch 186/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.1284 - dice_coef: 0.6203 - accuracy: 0.6532 - true_positive_rate: 0.5101 - iou_score: 0.0611 - val_loss: 1.3858 - val_dice_coef: 0.5722 - val_accuracy: 0.5944 - val_true_positive_rate: 0.4785 - val_iou_score: 0.0572\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 1.38285\n",
      "Epoch 187/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.1443 - dice_coef: 0.6115 - accuracy: 0.6474 - true_positive_rate: 0.5006 - iou_score: 0.0601 - val_loss: 1.3928 - val_dice_coef: 0.5753 - val_accuracy: 0.5955 - val_true_positive_rate: 0.4840 - val_iou_score: 0.0570\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 1.38285\n",
      "Epoch 188/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 783ms/step - loss: 1.1266 - dice_coef: 0.6194 - accuracy: 0.6538 - true_positive_rate: 0.5076 - iou_score: 0.0611 - val_loss: 1.3937 - val_dice_coef: 0.5689 - val_accuracy: 0.5920 - val_true_positive_rate: 0.4773 - val_iou_score: 0.0553\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 1.38285\n",
      "Epoch 189/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 783ms/step - loss: 1.1332 - dice_coef: 0.6179 - accuracy: 0.6514 - true_positive_rate: 0.5079 - iou_score: 0.0612 - val_loss: 1.3838 - val_dice_coef: 0.5739 - val_accuracy: 0.5934 - val_true_positive_rate: 0.4807 - val_iou_score: 0.0572\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 1.38285\n",
      "Epoch 190/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.1353 - dice_coef: 0.6143 - accuracy: 0.6503 - true_positive_rate: 0.5034 - iou_score: 0.0605 - val_loss: 1.3837 - val_dice_coef: 0.5718 - val_accuracy: 0.5945 - val_true_positive_rate: 0.4783 - val_iou_score: 0.0569\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 1.38285\n",
      "Epoch 191/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.1369 - dice_coef: 0.6171 - accuracy: 0.6515 - true_positive_rate: 0.5077 - iou_score: 0.0609 - val_loss: 1.3795 - val_dice_coef: 0.5749 - val_accuracy: 0.5942 - val_true_positive_rate: 0.4826 - val_iou_score: 0.0570\n",
      "\n",
      "Epoch 00191: val_loss improved from 1.38285 to 1.37949, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 192/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.1329 - dice_coef: 0.6160 - accuracy: 0.6492 - true_positive_rate: 0.5056 - iou_score: 0.0608 - val_loss: 1.3773 - val_dice_coef: 0.5745 - val_accuracy: 0.5968 - val_true_positive_rate: 0.4817 - val_iou_score: 0.0564\n",
      "\n",
      "Epoch 00192: val_loss improved from 1.37949 to 1.37729, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 193/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.1206 - dice_coef: 0.6211 - accuracy: 0.6539 - true_positive_rate: 0.5113 - iou_score: 0.0615 - val_loss: 1.3827 - val_dice_coef: 0.5728 - val_accuracy: 0.5947 - val_true_positive_rate: 0.4829 - val_iou_score: 0.0561\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 1.37729\n",
      "Epoch 194/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.1237 - dice_coef: 0.6173 - accuracy: 0.6516 - true_positive_rate: 0.5062 - iou_score: 0.0615 - val_loss: 1.3791 - val_dice_coef: 0.5724 - val_accuracy: 0.5950 - val_true_positive_rate: 0.4795 - val_iou_score: 0.0577\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 1.37729\n",
      "Epoch 195/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.1162 - dice_coef: 0.6226 - accuracy: 0.6548 - true_positive_rate: 0.5133 - iou_score: 0.0619 - val_loss: 1.3771 - val_dice_coef: 0.5736 - val_accuracy: 0.5941 - val_true_positive_rate: 0.4828 - val_iou_score: 0.0573\n",
      "\n",
      "Epoch 00195: val_loss improved from 1.37729 to 1.37707, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 196/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.1136 - dice_coef: 0.6233 - accuracy: 0.6559 - true_positive_rate: 0.5135 - iou_score: 0.0621 - val_loss: 1.3813 - val_dice_coef: 0.5746 - val_accuracy: 0.5956 - val_true_positive_rate: 0.4841 - val_iou_score: 0.0562\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 1.37707\n",
      "Epoch 197/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.1137 - dice_coef: 0.6258 - accuracy: 0.6555 - true_positive_rate: 0.5181 - iou_score: 0.0626 - val_loss: 1.3827 - val_dice_coef: 0.5772 - val_accuracy: 0.5952 - val_true_positive_rate: 0.4905 - val_iou_score: 0.0573\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 1.37707\n",
      "Epoch 198/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.1137 - dice_coef: 0.6233 - accuracy: 0.6558 - true_positive_rate: 0.5142 - iou_score: 0.0621 - val_loss: 1.4001 - val_dice_coef: 0.5755 - val_accuracy: 0.5919 - val_true_positive_rate: 0.4899 - val_iou_score: 0.0573\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 1.37707\n",
      "Epoch 199/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.1152 - dice_coef: 0.6221 - accuracy: 0.6550 - true_positive_rate: 0.5125 - iou_score: 0.0619 - val_loss: 1.3867 - val_dice_coef: 0.5766 - val_accuracy: 0.5955 - val_true_positive_rate: 0.4884 - val_iou_score: 0.0582\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 1.37707\n",
      "Epoch 200/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.0969 - dice_coef: 0.6306 - accuracy: 0.6605 - true_positive_rate: 0.5217 - iou_score: 0.0628 - val_loss: 1.3791 - val_dice_coef: 0.5773 - val_accuracy: 0.5962 - val_true_positive_rate: 0.4896 - val_iou_score: 0.0570\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 1.37707\n",
      "Epoch 201/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 80s 784ms/step - loss: 1.0987 - dice_coef: 0.6311 - accuracy: 0.6592 - true_positive_rate: 0.5237 - iou_score: 0.0630 - val_loss: 1.3766 - val_dice_coef: 0.5750 - val_accuracy: 0.5943 - val_true_positive_rate: 0.4861 - val_iou_score: 0.0574\n",
      "\n",
      "Epoch 00201: val_loss improved from 1.37707 to 1.37660, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 202/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.0972 - dice_coef: 0.6299 - accuracy: 0.6580 - true_positive_rate: 0.5218 - iou_score: 0.0633 - val_loss: 1.3719 - val_dice_coef: 0.5764 - val_accuracy: 0.5957 - val_true_positive_rate: 0.4868 - val_iou_score: 0.0573\n",
      "\n",
      "Epoch 00202: val_loss improved from 1.37660 to 1.37186, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 203/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 783ms/step - loss: 1.0843 - dice_coef: 0.6351 - accuracy: 0.6634 - true_positive_rate: 0.5282 - iou_score: 0.0641 - val_loss: 1.3836 - val_dice_coef: 0.5771 - val_accuracy: 0.5956 - val_true_positive_rate: 0.4906 - val_iou_score: 0.0578\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 1.37186\n",
      "Epoch 204/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.0923 - dice_coef: 0.6328 - accuracy: 0.6622 - true_positive_rate: 0.5256 - iou_score: 0.0637 - val_loss: 1.3854 - val_dice_coef: 0.5766 - val_accuracy: 0.5954 - val_true_positive_rate: 0.4909 - val_iou_score: 0.0573\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 1.37186\n",
      "Epoch 205/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.0963 - dice_coef: 0.6296 - accuracy: 0.6587 - true_positive_rate: 0.5228 - iou_score: 0.0631 - val_loss: 1.3704 - val_dice_coef: 0.5733 - val_accuracy: 0.5936 - val_true_positive_rate: 0.4842 - val_iou_score: 0.0567\n",
      "\n",
      "Epoch 00205: val_loss improved from 1.37186 to 1.37036, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 206/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.0873 - dice_coef: 0.6345 - accuracy: 0.6622 - true_positive_rate: 0.5280 - iou_score: 0.0638 - val_loss: 1.3745 - val_dice_coef: 0.5774 - val_accuracy: 0.5967 - val_true_positive_rate: 0.4889 - val_iou_score: 0.0578\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 1.37036\n",
      "Epoch 207/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 783ms/step - loss: 1.0861 - dice_coef: 0.6320 - accuracy: 0.6622 - true_positive_rate: 0.5250 - iou_score: 0.0638 - val_loss: 1.3703 - val_dice_coef: 0.5745 - val_accuracy: 0.5962 - val_true_positive_rate: 0.4861 - val_iou_score: 0.0572\n",
      "\n",
      "Epoch 00207: val_loss improved from 1.37036 to 1.37027, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 208/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.0884 - dice_coef: 0.6324 - accuracy: 0.6613 - true_positive_rate: 0.5263 - iou_score: 0.0642 - val_loss: 1.3794 - val_dice_coef: 0.5783 - val_accuracy: 0.5958 - val_true_positive_rate: 0.4919 - val_iou_score: 0.0578\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 1.37027\n",
      "Epoch 209/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 783ms/step - loss: 1.0733 - dice_coef: 0.6366 - accuracy: 0.6665 - true_positive_rate: 0.5301 - iou_score: 0.0642 - val_loss: 1.3738 - val_dice_coef: 0.5770 - val_accuracy: 0.5960 - val_true_positive_rate: 0.4896 - val_iou_score: 0.0577\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 1.37027\n",
      "Epoch 210/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.0792 - dice_coef: 0.6374 - accuracy: 0.6649 - true_positive_rate: 0.5321 - iou_score: 0.0642 - val_loss: 1.3827 - val_dice_coef: 0.5778 - val_accuracy: 0.5957 - val_true_positive_rate: 0.4943 - val_iou_score: 0.0577\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 1.37027\n",
      "Epoch 211/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 783ms/step - loss: 1.0796 - dice_coef: 0.6375 - accuracy: 0.6635 - true_positive_rate: 0.5322 - iou_score: 0.0641 - val_loss: 1.3805 - val_dice_coef: 0.5798 - val_accuracy: 0.5966 - val_true_positive_rate: 0.4940 - val_iou_score: 0.0580\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 1.37027\n",
      "Epoch 212/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.0781 - dice_coef: 0.6345 - accuracy: 0.6630 - true_positive_rate: 0.5286 - iou_score: 0.0640 - val_loss: 1.3663 - val_dice_coef: 0.5741 - val_accuracy: 0.5942 - val_true_positive_rate: 0.4860 - val_iou_score: 0.0570\n",
      "\n",
      "Epoch 00212: val_loss improved from 1.37027 to 1.36630, saving model to seg_model_2_best_weights.hdf5\n",
      "Epoch 213/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.0736 - dice_coef: 0.6395 - accuracy: 0.6653 - true_positive_rate: 0.5333 - iou_score: 0.0650 - val_loss: 1.3765 - val_dice_coef: 0.5782 - val_accuracy: 0.5959 - val_true_positive_rate: 0.4908 - val_iou_score: 0.0581\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 1.36630\n",
      "Epoch 214/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.0642 - dice_coef: 0.6427 - accuracy: 0.6691 - true_positive_rate: 0.5375 - iou_score: 0.0655 - val_loss: 1.3782 - val_dice_coef: 0.5781 - val_accuracy: 0.5954 - val_true_positive_rate: 0.4936 - val_iou_score: 0.0585\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 1.36630\n",
      "Epoch 215/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.0709 - dice_coef: 0.6396 - accuracy: 0.6661 - true_positive_rate: 0.5354 - iou_score: 0.0654 - val_loss: 1.3764 - val_dice_coef: 0.5774 - val_accuracy: 0.5951 - val_true_positive_rate: 0.4920 - val_iou_score: 0.0578\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 1.36630\n",
      "Epoch 216/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.0568 - dice_coef: 0.6403 - accuracy: 0.6691 - true_positive_rate: 0.5354 - iou_score: 0.0653 - val_loss: 1.3785 - val_dice_coef: 0.5787 - val_accuracy: 0.5946 - val_true_positive_rate: 0.4926 - val_iou_score: 0.0585\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 1.36630\n",
      "Epoch 217/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.0596 - dice_coef: 0.6423 - accuracy: 0.6675 - true_positive_rate: 0.5381 - iou_score: 0.0655 - val_loss: 1.3742 - val_dice_coef: 0.5803 - val_accuracy: 0.5969 - val_true_positive_rate: 0.4953 - val_iou_score: 0.0581\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 1.36630\n",
      "Epoch 218/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.0548 - dice_coef: 0.6451 - accuracy: 0.6703 - true_positive_rate: 0.5411 - iou_score: 0.0660 - val_loss: 1.3776 - val_dice_coef: 0.5757 - val_accuracy: 0.5939 - val_true_positive_rate: 0.4904 - val_iou_score: 0.0576\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 1.36630\n",
      "Epoch 219/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 785ms/step - loss: 1.0625 - dice_coef: 0.6423 - accuracy: 0.6681 - true_positive_rate: 0.5387 - iou_score: 0.0654 - val_loss: 1.3766 - val_dice_coef: 0.5786 - val_accuracy: 0.5954 - val_true_positive_rate: 0.4951 - val_iou_score: 0.0587\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 1.36630\n",
      "Epoch 220/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 80s 784ms/step - loss: 1.0609 - dice_coef: 0.6416 - accuracy: 0.6684 - true_positive_rate: 0.5376 - iou_score: 0.0655 - val_loss: 1.3713 - val_dice_coef: 0.5780 - val_accuracy: 0.5946 - val_true_positive_rate: 0.4931 - val_iou_score: 0.0579\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 1.36630\n",
      "Epoch 221/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 783ms/step - loss: 1.0574 - dice_coef: 0.6426 - accuracy: 0.6694 - true_positive_rate: 0.5380 - iou_score: 0.0659 - val_loss: 1.3751 - val_dice_coef: 0.5750 - val_accuracy: 0.5948 - val_true_positive_rate: 0.4909 - val_iou_score: 0.0588\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 1.36630\n",
      "Epoch 222/1000\n",
      "New lr is:  5e-06\n",
      "New lr is:  2.5e-06\n",
      "New lr is:  1e-06\n",
      "New lr is:  5e-06\n",
      "102/102 [==============================] - 80s 784ms/step - loss: 1.0599 - dice_coef: 0.6427 - accuracy: 0.6685 - true_positive_rate: 0.5389 - iou_score: 0.0658 - val_loss: 1.3703 - val_dice_coef: 0.5792 - val_accuracy: 0.5960 - val_true_positive_rate: 0.4951 - val_iou_score: 0.0587\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 1.36630\n"
     ]
    }
   ],
   "source": [
    "from segmentation_models.losses import bce_jaccard_loss\n",
    "from segmentation_models.metrics import precision, iou_score\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001,\n",
    "                               beta_1=0.9,\n",
    "                               beta_2=0.999,\n",
    "                               epsilon=1e-07,\n",
    "                               amsgrad=False,\n",
    "                               name=\"Adam\",\n",
    ")\n",
    "\n",
    "\n",
    "model.compile(optimizer=\"Adam\", loss='categorical_crossentropy', \n",
    "              metrics=[dice_coef, \n",
    "                       'accuracy', \n",
    "                       true_positive_rate, \n",
    "                       iou_score\n",
    "                      ])\n",
    "\n",
    "history = model.fit(train, epochs=1000, verbose=1, validation_data=validation, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a74b300c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA100lEQVR4nO3deXycVb348c93JstkT7N1SdKmGy0tpS2EAsKlLSCyCEUBbV0A5SeKgix6uYjIBa++rhdRccGloiIoVFBBBCp7BbRAQ1u672vS7Gn2TGY7vz/Ok3aytSl0Mkme7/v1mlfmWWae7zydnu+cc57nHDHGoJRSyr088Q5AKaVUfGkiUEopl9NEoJRSLqeJQCmlXE4TgVJKuZwmAqWUcjlNBMoVRKRERIyIJAxg32tF5M3BiEupoUATgRpyRGSPiAREJK/H+jVOYV4Sp9CiY0kXkVYRWR7vWJT6oDQRqKFqN7Cka0FEZgGp8QunlyuATuDDIjJmMA88kFqNUsdCE4Eaqh4Fro5avgZ4JHoHEckSkUdEpFZE9orIXSLicbZ5ReR+EakTkV3AJX289jciUikiFSLyHRHxHkN81wC/BNYBn+nx3meLyL9FpFFE9ovItc76FBH5gRNrk4i86axbICLlPd5jj4ic7zy/R0T+LCJ/EJFm4FoRmSciK51jVIrIz0QkKer1M0XkJRFpEJFqEblTRMaISLuI5Ebtd4pz/hKP4bOrEUYTgRqq3gIyReREp4BeDPyhxz4/BbKAScB8bOL4nLPtC8BHgblAKXBlj9c+DISAKc4+FwD/byCBicgEYAHwR+dxdY9ty53Y8oE5wFpn8/3AqcCHgBzgdiAykGMCi4A/A9nOMcPArUAecCZwHvBlJ4YM4GXgH8A45zO+YoypAlYAn4h6388Cy4wxwQHGoUYiY4w+9DGkHsAe4HzgLuB/gQuBl4AEwAAlgBcIADOiXvdFYIXz/FXgS1HbLnBemwCMxjbrpERtXwK85jy/FnjzCPHdBax1nhdiC+W5zvI3gKf6eI0H6ABm97FtAVDe1zlwnt8DvH6Uc3ZL13Gdz7Kmn/0+CfzLee4FqoB58f4310d8H9rWqIayR4HXgYn0aBbC/hJOBPZGrduLLZjB/hLe32NblwnOaytFpGudp8f+R3I18GsAY0yFiPwT21S0BigGdvbxmjzA18+2gegWm4icAPwQW9tJxSa4d53N/cUA8DfglyIyEZgGNBlj3nmfMakRQpuG1JBljNmL7TS+GPhrj811QBBbqHcZD1Q4zyuxBWL0ti77sTWCPGNMtvPINMbMPFpMIvIhYCrwDRGpEpEq4HTgU04n7n5gch8vrQP8/WxrI6oj3GkKy++xT89hgn8BbAGmGmMygTuBrqy2H9tc1osxxg88ge3X+Cw22SqX00SghrrrgHONMW3RK40xYWyB9l0RyXDa5m/jcD/CE8BXRaRIREYBd0S9thJ4EfiBiGSKiEdEJovI/AHEcw22mWoGtv1/DnASkAJchG2/P19EPiEiCSKSKyJzjDER4LfAD0VknNOZfaaIJAPbAJ+IXOJ02t4FJB8ljgygGWgVkenADVHbngXGisgtIpLsnJ/To7Y/gm3+ugxNBApNBGqIM8bsNMaU9bP5Juyv6V3Am8Bj2MIWbNPNC8B7wGp61yiuBpKATcBBbEfs2CPFIiI+bEfrT40xVVGP3dgC9RpjzD5sDeZrQAO2o3i28xZfB9YDq5xt/wd4jDFN2I7eh7A1mjag21VEffg68Cmgxfmsf+raYIxpAT4MXIrtA9gOLIza/i9sJ/Vqp9alXE6M0YlplHIbEXkVeMwY81C8Y1Hxp4lAKZcRkdOwzVvFTu1BuZw2DSnlIiLye+w9BrdoElBdtEaglFIupzUCpZRyuWF3Q1leXp4pKSmJdxhKKTWsvPvuu3XGmJ73pwDDMBGUlJRQVtbf1YRKKaX6IiL9XiqsTUNKKeVymgiUUsrlNBEopZTLDbs+gr4Eg0HKy8vx+/3xDiXmfD4fRUVFJCbqPCJKqeNjRCSC8vJyMjIyKCkpIWpY4RHHGEN9fT3l5eVMnDgx3uEopUaIEdE05Pf7yc3NHdFJAEBEyM3NdUXNRyk1eEZEIgBGfBLo4pbPqZQaPCMmESil1HATCB2esjoSscP9rNl3kCfL9hMM223tgRB769uI5XBAI6KPIN7q6+s577zzAKiqqsLr9ZKfb2/ge+edd0hKSur3tWVlZTzyyCP85Cc/GZRYlVKDq6bZT2ZKIr5Eb7f1L22q5qbHV3PJrHEkJQhPlpVzyoRRlO1pIGLggZe3k+FLYGdtK8GwYVRqIt/66Aw+fkrRcY9RE8FxkJuby9q1awG45557SE9P5+tf//qh7aFQiISEvk91aWkppaWlgxGmUioG2jpDpCX3/f9744EmPv7zf5OU4GHRnHFccUoRUwrS+dOq/Xxv+RbGZvv465pyjIFLZo1lfUUTH5tbxHknFvBE2X4SPMKCaQUU56Tw3v5Gikal9nmcD0oTQYxce+21+Hw+1qxZw1lnncXixYu5+eab8fv9pKSk8Lvf/Y5p06axYsUK7r//fp599lnuuece9u3bx65du9i3bx+33HILX/3qV+P9UZRSUVo7Q6Q7Bf9z6yq58fHVTMxL40vzJ7NgWj73/WMrB9sC5Gcks3JXPaNSkzhzci5PlpXzh7f2HXqfc6cX8OPFc9hS1UI4YjhjUm6341w8q/uEeZ8+fQKxMuISwb1/38imA83H9T1njMvkvy896rzmvZSXl/Pvf/8br9dLc3Mzb7zxBgkJCbz88svceeed/OUvf+n1mi1btvDaa6/R0tLCtGnTuOGGG/SeAaWGiF/+cyffW76F2cXZnDe9gF+/votpozPwJXq5/c/ryE5NxB8MMzk/nbK9B+kIhHnsC6dTWpLDPZfNZMXWGvY3tDOrKJv5J9jm49NKcuL8qUZgIhhKrrrqKrxe2y7Y1NTENddcw/bt2xERgsFgn6+55JJLSE5OJjk5mYKCAqqrqykqOv5tgkqp/u2sbeWfW2sJRSKkJyfS7A+SmuTl+y9spXTCKALhCD98aRsZvgR+fXUpY7N83Pv3Tby2tYZHPj+Pk4uyiUQMbYEQGT77Qy4rJZFFcwrj/Mn6NuISwfv55R4raWlph55/61vfYuHChTz11FPs2bOHBQsW9Pma5OTkQ8+9Xi+hUCjWYSo1or26pZqOQISLThrD3c9sICctmRvmTyYl6XDnbVN7kFufWMvJRVk0d4T47b929/lehdkp/Oba08hKSaSisQNjzKF2+/+5/CSMMYcu8fZ45FASGOpGXCIYqpqamigstL8GHn744fgGo9QIV9fayfINVWw60MTj7+zHI7aNvauN/o9v7eW0khzWVzSRn5FMoldYva+RV7fUAHDNmRO4fv5kMnwJtDl9Arvr2hid6SMrxRbuhdkpvY47XO/z0UQwSG6//XauueYavvOd73DJJZfEOxylhjVjDM+8d4Dn1lVy+4XTWVfeyEubqpk6OgMBHlm5h4PtQUTg06ePZ8XWWh59ay+nlYziaxdM4w9v7WXNvkZOHJvJhoomqpr9/PATsynOSaXFH+Tc6aMPHSvT+VV/clF2fD7sIBh2cxaXlpaanhPTbN68mRNPPDFOEQ0+t31e5Q77G9oBKM6xTS0PvbGLd/ce5HsfP5ms1MNNLJGI4abH1/Dc+ko8AskJXjqCYfLSk6hrDQAwuzib//3YLKYUpJOU4OHtXfXc+/dNPLB4DieMzuh23LbOELvr2jipMGuQPml8iMi7xpg+r1XXGoFSKq78wTD3/WMrj6zcQ1ZKIi/ceg7L3tnH/S9uA2BLVQu5aUm0B8IUZCaTl57Mc+srue3DJ7BozjhuXraWueOz+ebFJxI2BmMgOcHTrZnm9Em5PH/zf/R5/LTkhBGfBI5GE4FSalD5g2Fe2FjF/BPyae4IcdPjq3mvvImPzy3k2fWVXPzjN6hp6eTyOeO44tQi7v37JkRgXLaPbdWtrNhay6Wzx3HTuVMQEZ7+ylmH3lsLtPdHz5tS6rhrD4R44OXtvL6tluzURL6ycAqnleSwclc9//PsJnbVtpGRnIA/FCbJ6+FXnz2Vj8wcw6yiLO79+ya+et5UbjlvKh6P8PJt8w+9byRi2FTZzAmjM4Ztx+xQpIlAKXVcVTZ18MVH32VDRRMfmpzHjppWPvubdw5tH5fl4/6rZvPPbbVk+hK46dypjMnyAfC5syZy+ZxCRqX1PT6XxyOub8aJBU0ESqmjWr3vIFsqW/jkacV4PcK68kZ+++ZuvrxwCg++toN39x7kilOKaA+EeOztfUQMLP1sKefPGI0/GObVLTVsrmxm6ugMPjJzNMkJXq48te8bJftLAip2NBEopXoxxvDO7gaWb6hic2Uzb+9uAODFTVVceWoRd/9tIw1tAZ5eewCAkwoz+fEr2/F6hIXT8rn7ozMZn2uv/vElerl41theY+eooUMTwXGwcOFC7rjjDj7ykY8cWvfAAw+wdetWfvGLX/Taf8GCBdx///066qiKmze21/LIyr3srGmlcFQKzR1BGjuC5KQl8dMlc7n/ha08vfYAqUlephSkc+v5J5Cdmsh3ntvEiq215KYl8dgXTufRlXs578TRXHlqEQfbAmT4Ekjw6jQnw40mguNgyZIlLFu2rFsiWLZsGffdd18co1Ju1jXUQSAUYU99GyeMzmBHTSs1LX5y05L53O9WkZuexOyibKqa/WSlJDIhN43XttSw6Gf/or4twJfmT+bm86Z2G4rh0tnj2FXbSkleGnnpyXxoct6hbdqkM3xpIjgOrrzySu666y4CgQBJSUns2bOHAwcO8Pjjj3PbbbfR0dHBlVdeyb333hvvUNUIVNHYwQsbqqht7STDl8CBxg7+8m4Fnz59PBsPNLNyVz23nn8Cj6zcQ31bgNGZyWSmJLL85nPI6VF4r9haw+cfXsWCafnc/pFpeDzdr8zJSUsiJy3+o2Wq42vkJYLld0DV+uP7nmNmwUXf63dzTk4O8+bNY/ny5SxatIhly5bxiU98gjvvvJOcnBzC4TDnnXce69at4+STTz6+sSnX2lbdwo9f2c7y9ZVEDCR4hFDEkOgVThk/iofe3I3XI5xUmMmPXrYjZV500hiWb6jigU/O6ZUEABZMK+Cl2+ZTmJ3SKwmokWvkJYI46Woe6koEv/nNb3jiiSdYunQpoVCIyspKNm3apIlAHZNgOMIjK/fyzu56Rmf6eHNHHckJXgqzU3hlSzWpiV6+cM4kPnP6BIpGpdDaGSISgazURFZsrSEl0cvJRdl8b/lmLjl5HKeVjOJAk7/PAdO6TM5PH8RPqIaCkZcIjvDLPZYWLVrErbfeyurVq2lvbycnJ4f777+fVatWMWrUKK699lr8fn9cYlPDgzGGDRXNjM9NJRwxPLpyL39dU87e+nYKs1NYsbWW0pJR+IMRyvY28OUFk/l/Z0/q1jYfPezxgmkFh57fu+ikQ8+PlASUO8U0EYjIhcCPAS/wkDGmVyktIp8A7gEM8J4x5lOxjClW0tPTWbhwIZ///OdZsmQJzc3NpKWlkZWVRXV1NcuXL+93DgLlTvvq2/m/f2xhX0M7KYleWjpDbK5sJi3Ji0eE1kCI0yfmcNclMzj/xAK9k1bFTMwSgYh4gQeBDwPlwCoRecYYsylqn6nAN4CzjDEHRaSg73cbHpYsWcLHPvYxli1bxvTp05k7dy7Tp0+nuLiYs8466+hvoEakqiY/3/rbBnbWtnJCQQb7D7aTk5bExgPNBMMRThk/ivZAiASP8O1FM1lX3kQwHOHGhVOY2mOkTKViIZY1gnnADmPMLgARWQYsAjZF7fMF4EFjzEEAY0xNDOOJucsvv5zoYb37m4BmxYoVgxOQiovalk6+t3wL75U30tge4GB7kCSvh9Mn5bClqpnxuWnUtnQyPieVH31yDhPz0o7+pkrFUCwTQSGwP2q5HDi9xz4nAIjIv7DNR/cYY/4Rw5iUOu5C4QhPlJXzz2017Kpto6Kxg1DEcO60AnLSk8hJTeKKU4u0wFdHF4mAZ/BvyIt3Z3ECMBVYABQBr4vILGNMY/ROInI9cD3A+PHjBzlEpaCmxc/dT2/EHwpTkpvG8g2VtAfCjM704RVha3UL43NSOXFsBvMm5vC5syYypUCvvjnujIG++ko6W6G9DrIn2O3+JmjYBR0HIcEHLZVwcC+Ufg5SRkEkDNUb7Pu9/SvY+QrM+TTkT4PEFMgqhu0vQrAdxs6GmR+H9X+GTU/b957zKWitgbptkJBsj1E8z8by/H+CeCG7GNIKINgGiWnQ2Qz1O+DUa8GbBPvfgfQCyBxnH+318OYDUHI2nHED7F0J2ePBlwUNO2HbP+Csm2HK+cf9tMYyEVQAxVHLRc66aOXA28aYILBbRLZhE8Oq6J2MMUuBpWBnKOvrYNGTRo9kw21GueEgHDHUt3aSn5GMiLC5spnH3t7Hnvo2UpO8JHg9vL2rgdbOILlpyby5vY5zpxcwLjuFvfVtVDb5+dmn5nLJrLGu+A4SDtmCqeMgFJ5qC8u2Oluo1WyB1ipbEI6dDUmpEA5CoM0WnOKxhfKeN6GjwRbggVbobLF/PYmQVWQLRhO2hXfdNnsvT1sd1Gy2hXX6aIiEwN9oj1W1HsKdkOLc7NbR0Hfs7z0ORafZQrW93q7zJMD4M+HNH3bfVzx2WzgAKx+EindhVIld9/QNdp+MsTaOQBu89XO7btxcKJgJTfvg4B5ISrOxexKgYAas+F+7X+5UqCiDttrDxyw+Hba9AFue7R17/nQIxubKw1gmglXAVBGZiE0Ai4GeVwQ9DSwBficiedimol3HeiCfz0d9fT25ubkj+j+iMYb6+np8Pl+8QxnWDrYFeHFTFQca/Xz2zAn84MVtPP7OPvLSkxid6WNLVQvJCR4m56dT1eQnEI5wclEWX79gGieOzaAzFMGX6D36gYa6SMQWVrXbbIHa2WILtEDr4cIpZxKYCAQ77KO9DrY8f7ig9WXZwtyEj+3YiWmQng9JGZCcYZNI0iRb6DaVQ+VaW3BmjIWJ86HyPUhOt7+m67fbOMQLqXn2NaWfg9wpULXO/trOHAd5J0BqLoT8kJxpP9uT18DmZ+GEj8DUC8CbAKNPgryp0LjfvlfHQajfCZPm21/0b9wPr33X1hgu/YlNEPv+DZmFkDPROZdh2PKcTZBnfNnWEvpzYK2tQRRMt8uhgE2OIb9NclXroXoTTP0wtFbb854+GrIKj+0cH4OYzlksIhcDD2Db/39rjPmuiHwbKDPGPCO21P4BcCEQBr5rjFl2pPfsa87iYDBIeXm5K67T9/l8FBUVkZiYePSdVS9VTX4WL13Jnno7P25+RjK1LZ1ccvJYUhO91LZ2Mjk/nZvOnUJ26hAcO8cY+wh32l/HSWn2l/b+tyEtzxbmHY22AAy2Q80mW8BN+JAtYFprbAF0cK99faCl7+Ok5NjC3d90eJ032R5v0nw44UJbmG1/0RZSuZOhpcoWZKNKINBuC+VICLyJdt/0MfZ9klLtr3JvHL7D4aDzWY7x2K219vwO4x+aR5qzeERMXq9Uf9o6Q6QkevF4hA0VTdz42GrqWgMsvfpUEjwernt4FdPGZLDs+jMGb9TMrv9z0YVKOGjbtJvKbRNEazUkpdtmEhFo3AcH1sCB96Czyf4qNZG+3z96W8Y4yBwLFattu3fuZKjbbgvr0TNsU0XBifaXdVKa/dWdmAoer43T33S4IPeMgFqQi+nk9coVguEIb+6ooyMQJjctiVV7GvjRy9tJS/KSl5HMvvp2ctOT+P3n53HqhFEAvH77QlKcfoDjpqtDs70BGnbbKv+W56Buq21GqVpnC35flm0W8STYBBDqcN5AICXb7htxfsF6EmHMSTDrCkjLt/uMnmGbFRJTbAdjZ7NNHr5s29STmAqJTjNiZ6tTwB/D5xQnDjXiaSJQw9K26hbe3t1AVVMH6cmJhCMRnl57gB01rd32u+ikMWSlJNLiD3HBjDF8af6kbk0+fQ6d3HzAthEnp9uO0c4mW6jXbrFtyCmjbDPJ7n/aAr3wVKjeaH89t9fbNmxvclTBzuGCPCEF5n7GFsqdzbYpJxKy7dVjZ9t24NEznStbIrZmIGKbahKO0lQVXWin9hghNFmvYFL900SghoXddW1k+BLoCIT52pPv8Y4zY5ZHIOK0tJTkpvKLT5/CxPw0qpr8eD3C2VPy7AUEHY22Hb26xv4Sb9wPe95wmjwSbIHcuNd2SrZU9h2EJ8EW6F0FfPYE2ym46zXbMZk+2nZYTr/YJojUXNvsgthLC3sWzkfj8dhmHaViTBOBGtJqWvz84IVt/KlsP6lJXlIThPRIE/+7cBwfLjhIbstWQu2NeDqb8UQCyA6BtdVMbz5gC/fkdNv8Ur3Rdp5GS3QubYyE7D5ZRTDxHBh3iu30DHbY9vHkTJs8cibZX+VBv72yJjXX/loPdtjmGaWGKU0EaugJhzDtdfz19TUsf2stJaaCf+WUkdFZhS/cQhIhWHl498QEny2sE5Jt+3x6vi20fVn2qhh/M8y6EmZdBTg3G/ky7bXjHue/wLFcDZLoO9z2DpoE1LCniUANPmOgbhsdBw9Q0RJhf10LoX3vMKP1LbLbdpESasSD4Qrgiq4LVbJmw7jL7S/3zEJ7hUtWkb0MUdu/lfpANBGo2GtvgH1vgQnTdmAz4feeILN5OynAFOcBsDkynjeZiz85jz3+NKZPmcpVC07Fk1Vob9dXSsWEJgJ1fLVUQXmZbZOv20rjwXpSD6wkyXQCkAasj5Twp8h1jJt8EqcXpzE2M5kx089gfHIek7xCcoKXSMToVIlKDRJNBOqD62y1Y6ZsfBrWPGo7XxHa04qoaPGySc7ipYSFVLR78OVP4s4rzuTOsRmkJnX/+kWPzalJQKnBo4lAHbv2BnudfeVaeG+ZvePVhMGTQPXUxTzDfF6sy+HdA53MKsrmD9fN44qkBLbVtFCSmzYyxulRagTRRKC6M8YW9P5GZwAyZxAyf5MdjKt2K6z5w+Fr6UfPgrNvhfFnsi91Buc+uJZEr4c5xencuLCY6/5j0qF5dKePyYzf51JK9UsTwUgXCdt2+667WA/9dS6r7Hre2WQHIaveaIdE6I944eRPwMyP0eIbx3ffidBQEWSmyWJzZSWJXg//vH0BBRk6QqpSw4UmguHGGAh12l/szRX2eWu1Hfe8vcEOD9x+0PnbYO+WPVLBDs5QwOkwaiKUXgfZxRhfNqGEVBJTMiEpnVZPGst3+Pn9miYqN4SYVJ1GW2cj22tamJiXxoubqgH46rlTNAkoNcxoIhgKImE7BEJX4d3RYEeirN9hm2T8zXayj4P77A1S/Y066U22wxik5NixavJPwEw5H3/mRAKJmXhSMnltdwev7unk0+fM5OTJxTSHk2kJRHhk5V6qm/2Mj6TysZJCvvbEe2yrbmFKQQI1zY3Ut9nppGcXZ3PBzFxW7qznQJOfpZ8tZeH0At7Z3cDyDZVcP3/y4J03pdRxocNQx0skDDtfhbV/hB2v2qaZnlJG2ULdl2XHQs+eYO+ITUy16zIL7V2tqbmsaRvFsjUNTB6dTkGGj6fWVJCfkcz68ia2Vncfcz7Tl0CzP9RtnJ4kr4fxuansqWsjFDGkJHq5qrSI3XVtFGanUJKXxuyibM6YlIOIEIkYWjpDZKXovAhKDQc6DPVQ0DXoWfkq+6hYbdvrU/NgxqW207Xr13zqKMgqJuDLY+nrO2kPhCnJSyPRKzz+9n5GZ/m45fypTMxN45UtNSx9aSer9uzHl+jBH7S1haJRKWw80EzhqBT+68LpZPgS8AfDTB2dwbySHH77r90EQhFy05OIRAwXnjSWMVk+dta28tAbu7jy1OJDQzX3xeMRTQJKjRBaI4gVY+DAajs3a/VG2PQ321YvXjuOfNFpdoCzaZccGl54zb6D/PKfO8n0JTJtTAYrd9bzypYaEjxCyPnpXpyTQn1rgPZAmIzkBFo6QxRmp3Dd2RP55GnF7KhppaE9wPyp+XotvlLqEK0RDKb2Bij7Dbz3JzsuPdgmntmL7aBn4+bSFEoi3ZdAWyDE8jWVGAMrttbywqYqcpyx8p98txyAby+ayafmjaeisYO61gCzi7JoaAvw7LpKNlc2c/bUPC6ZNfbQxCqzi7Pj8amVUsOYJoLjIRSAt39p54Td9g/b5DPhLPjQTTD9o5CWe2jXFzdWcePjayjISCYYjlDdbIdeGJWayA3zJ/PlhVNIT06gtqUTfzBMcU4qABNy05iQa++9Lcj08fmzJw7+51RKjUiaCD6IcMi2+7/837bdP2s8TDkPzrndNv8Axhhe3VzNpgPNvFfexGtba5gxNpP05ARCkQgPfuoURmf6KMhMJjnh8B23+RnJ8fpUSimX0URwrIyBmk2w8SlY/ai9rDMpA676Pcy8vNfuP1+xk++/sBWwM2h95vTx3H7hdNKS9dQrpYYGLY2OxY5X4NXv2E5gBKZ+GOZ8D6acb8fJB/zBMM+vr2RPfTt769v429oDXDZ7HP93xcmkJOkYO0qpoUcTwUCtfhSeuQmyx8PF98OJl0HGaAB21LTwraffIislka3VLeyua0MExmb6uGz2OO678mQdaE0pNWRpIhiIPf+CZ26EyefB4j8empowGI7w19XlfOe5zSR6PSR6hZRELw9/7jQ+NDmPpARPnANXSqmj00QwEKt+bS8BdZJAOGL429oKfvzKdvbWtzOnOJuffWouhdkpyLHMfauUUkOAJoKjaW+ALc9B6efZ1Rjm1S27ePydfeysbePEsZn8+upSzj+xQBOAUmrYimkiEJELgR8DXuAhY8z3emy/Fvg+UOGs+pkx5qFYxnTM1j0B4QB/7DyHu3/0OuGI4cSxmfz806dw4cwxeveuUmrYi1kiEBEv8CDwYaAcWCUizxhjNvXY9U/GmBtjFccH5d/wLFXeEr75Flw+Zyy3Xzidcdkp8Q5LKaWOm1jWCOYBO4wxuwBEZBmwCOiZCIasVn+QcPlaypjHT5fM5dLZ4+IdklJKHXexvKylENgftVzurOvpChFZJyJ/FpHivt5IRK4XkTIRKautrY1FrH364Z9fJYsWTjtjviYBpdSIFe/rG/8OlBhjTgZeAn7f107GmKXGmFJjTGl+fv6gBPb0mgr2bXobgAkzzxyUYyqlVDzEMhFUANG/8Is43CkMgDGm3hjT6Sw+BJwaw3gGbF99O3c9vYEPj6rGIDB6ZrxDUkqpmIllIlgFTBWRiSKSBCwGnoneQUTGRi1eBmyOYTwD0toZ4vpHy/AIXDamDsmbCklp8Q5LKaViJmaJwBgTAm4EXsAW8E8YYzaKyLdF5DJnt6+KyEYReQ/4KnBtrOIZqG8+tZ7tNa08+OlTSKnbBGNmxTskpZSKqZjeR2CMeR54vse6u6OefwP4RixjOBb1rZ08u66Sz59Vwn8UJ0PTPij9XLzDUkqpmIp3Z/GQ8vz6SsIRwxWnFkFLlV2Z1eeFTEopNWJoIojyt7UHmDY6g+ljMqG12q5ML4hvUEopFWOaCBz7G9op23uQy+Y49wt0JYKMMfELSimlBoEmAscTZfvxCFw+17nnrbXG/tUagVJqhNNEgJ1XYNmq/SyYVkBh1zhCrdXgTQJfdlxjU0qpWNNEALyyuZralk4+NW/84ZWtNZA+GnR4aaXUCKeJAHhxUzW5aUksmBY1fEVrtTYLKaVcQRMBsOlAM7OKskjwRp2OrhqBUkqNcK5PBJ2hMDtqWpkxNrP7Bq0RKKVcwvWJYHt1K6GIYca4qEQQCUN7ndYIlFKu4PpEsKmyGaB7jaCtFkxEawRKKVfQRHCgmdQkLxNyo0YYPXRXsdYIlFIjnyaCymamj8nAGz0J/aGbyTQRKKVGPtcngq1VLUzvq6MYtGlIKeUKR00EInKpiIzIhOEPhmnqCB6+m7hLmzMvctrgTIuplFLxNJAC/pPAdhG5T0SmxzqgwVTfFgAgNy2p+4b2evAmQ2JqHKJSSqnBddREYIz5DDAX2Ak8LCIrReR6EcmIeXQxVt9qp0vOTU/uvqH9IKTm6PASSilXGFCTjzGmGfgzsAwYC3wMWC0iN8UwtpircxJBXnqPGkFHA6TkxCEipZQafAPpI7hMRJ4CVgCJwDxjzEXAbOBrsQ0vtupabdNQXq8aQYOtESillAsMZM7iK4AfGWNej15pjGkXketiE9bgqHcSQW5fNYL8EdUdopRS/RpIIrgHqOxaEJEUYLQxZo8x5pVYBTYY6lo7SU3ykprU4zRojUAp5SID6SN4EohELYeddcNefWtn79qAMdBxUPsIlFKuMZBEkGCMCXQtOM+TjrD/sFHfFujdP+BvAhPWGoFSyjUGkghqReSyrgURWQTUxS6kwVPb0kluWo9E0NFg/2qNQCnlEgPpI/gS8EcR+RkgwH7g6phGNUjq2wLMKc7uvrL9oP2rNQKllEscNREYY3YCZ4hIurPcGvOoBkEkYmjoq2lIawRKKZcZSI0AEbkEmAn4xLnb1hjz7QG87kLgx4AXeMgY871+9rsCe8PaacaYsoGF/sE0dgQJR0zvzuJ2JxFojUAp5RIDuaHsl9jxhm7CNg1dBUwYwOu8wIPARcAMYImIzOhjvwzgZuDtY4r8A+p3eAmtESilXGYgncUfMsZcDRw0xtwLnAmcMIDXzQN2GGN2OVcaLQMW9bHf/wD/B/gHGPNxcfiu4r5qBAIp2YMZjlJKxc1AEkFXAd0uIuOAIHa8oaMpxHYsdyl31h0iIqcAxcaY5470Rs4gd2UiUlZbWzuAQx9dgzPyaE7PkUc7GsCXBR7vcTmOUkoNdQNJBH8XkWzg+8BqYA/w2Ac9sDPHwQ8ZwHhFxpilxphSY0xpfv7xmSOgLRACIE3vKlZKudwRO4udwvoVY0wj8BcReRbwGWOaBvDeFUBx1HKRs65LBnASsMLpgB4DPCMilw1Gh3FHIAxAWnKPU6AjjyqlXOaINQJjTATb4du13DnAJACwCpgqIhNFJAlYDDwT9V5Nxpg8Y0yJMaYEeAsYlCQAh2sEqUk9moC0RqCUcpmBNA29IiJXiBzbLC3GmBBwI/ACsBl4whizUUS+HX2ncry0d4bxCCQn9DgF/ibwZcclJqWUioeB3EfwReA2ICQifuwlpMYYk3nkl4Ex5nng+R7r7u5n3wUDiOW4aQ+ESUtKoFd+8zfZzmKllHKJgdxZPOynpOxLeyBESs9mIWOgsxl8R81xSik1Yhw1EYjIOX2t7zlRzXDTFgj37igOtIKJQLImAqWUewykaeg/o577sDeKvQucG5OIBklHINS7o9jfbP9q05BSykUG0jR0afSyiBQDD8QqoMHS1hnunQg6uxKB1giUUu4xkKuGeioHTjzegQy29kCo9xSVfufKWK0RKKVcZCB9BD8FjLPoAeZg7zAe1toDYQpH9dM0lKyJQCnlHgPpI4i+wSsEPG6M+VeM4hk07YEwKYlaI1BKqYEkgj8DfmNMGOzw0iKSaoxpj21osdUWCJGW3LOPoCsRaB+BUso9BnRnMZAStZwCvBybcAZPeyDc+z4CvWpIKeVCA0kEvujpKZ3nqbELKfaC4QiBUKT3yKP+JvAkQoIvPoEppVQcDCQRtDnzBgAgIqcCHbELKfbanZFH+7x81JcFxzasklJKDWsD6SO4BXhSRA5gxxkag526ctjqOJQI+qgRaP+AUsplBnJD2SoRmQ5Mc1ZtNcYEYxtWbB2alKZnZ7G/WYeXUEq5zkAmr/8KkGaM2WCM2QCki8iXYx9a7By5RqAdxUopdxlIH8EXnBnKADDGHAS+ELOIBkFbZz+T0ujIo0opFxpIIvBGT0ojIl4g6Qj7D3n9dhb7m7VGoJRynYF0Fv8D+JOI/MpZ/iKwPHYhxV57f/MV+5t0eAmllOsMJBH8F3A98CVneR32yqFhq6uzOCUxqkYQDkGwTWsESinXOWrTkDOB/dvAHuxcBOdi5yAetto7u64aisqDOgS1Usql+q0RiMgJwBLnUQf8CcAYs3BwQoud9mAffQQ64JxSyqWO1DS0BXgD+KgxZgeAiNw6KFHFWHtnGI9AckJUhcjfaP/qfQRKKZc5UtPQx4FK4DUR+bWInIe9s3jYawuESEtKQKKHkmipsn8zxsYnKKWUipN+E4Ex5mljzGJgOvAadqiJAhH5hYhcMEjxxURHXyOPNlfYv1mFgx+QUkrF0UA6i9uMMY85cxcXAWuwVxINW22BcO9LR5sPgCcB0vLjE5RSSsXJMc1ZbIw5aIxZaow5L1YBDYb2zlD3S0fBJoKMseDx9v0ipZQaod7P5PUDJiIXishWEdkhInf0sf1LIrJeRNaKyJsiMiOW8XTpCIZ731XcXAGZ4wbj8EopNaTELBE4Q1E8CFwEzACW9FHQP2aMmWWMmQPcB/wwVvFE8wfD+PqqEWgiUEq5UCxrBPOAHcaYXcaYALAMWBS9gzGmOWoxDTAxjOeQjmCkeyIwBpoqIFM7ipVS7jOQISber0Jgf9RyOXB6z52cYa5vww5kd24M4znEH+xx1VDHQQh1aI1AKeVKMe0jGAhjzIPGmMnYK5Hu6msfEbleRMpEpKy2tvYDH9MfDOOLvpms+YD9q4lAKeVCsUwEFUBx1HKRs64/y4DL+9rgXKlUaowpzc//4Jd3dvSsERxKBNo0pJRyn1gmglXAVBGZKCJJwGLgmegdRGRq1OIlwPYYxnNIr87irpvJtEaglHKhmPURGGNCInIj8ALgBX5rjNkoIt8GyowxzwA3isj5QBA4CFwTq3i6RCIGf8/O4uYDIB5IHx3rwyul1JATy85ijDHPA8/3WHd31PObY3n8vnSGIkCPuQiaym0S8CYOdjhKKRV3ce8sHmx+ZwhqX2LUR2/aD9nj4xSRUkrFl+sSQYeTCLrVCBr3aSJQSrmWexNB11VDkbDtLM4qPsKrlFJq5HJdIuhqGkpOcBJBSyVEQpCtiUAp5U6uTQSHagSNzs3P2jSklHIpFyYCe9XQoTuLG/fZv1maCJRS7uS6RNAR6FEjaOpKBEVxikgppeLLfYmg51VDjfvtrGRJqXGMSiml4sd1ieDwfQRdiWCfXjGklHI1TQR6M5lSyuVclwi63UfQNSGN9g8opVzMdYmg21VDgVY7IU16QZyjUkqp+HFdIugIhkn0CgleD7Q5k9ykffA5DpRSarhyXSKws5M5/QNtdfavJgKllIu5MxF03UNwqEaQF7+AlFIqzlyXCDoC4cP3EGjTkFJKuS8R2NnJnI/dlQhStUaglHIv1yWCjmB0jaAOkjMh0RffoJRSKo5cmQh80U1D2j+glHI51yWCzl6JQPsHlFLu5rpE0KtpSBOBUsrlEuIdwKDZ+RpsfZ4vtB2gIvsi4FRbIyg+Pd6RKaVUXLknEdRtg/VPcmmoDd/eZ+HFrdBerzUCpZTruadp6PQvwn/t4RzzEBtGnQf//imYiCYCpZTruScROA6GEvn3+C8Bxq7Qq4aUUi7nqkQQDEcIhg3+zIkw8Ry7UmsESimXi2kiEJELRWSriOwQkTv62H6biGwSkXUi8oqITIhlPP7oaSrP+Ap4kyBnUiwPqZRSQ17MEoGIeIEHgYuAGcASEZnRY7c1QKkx5mTgz8B9sYoHouYiSPTAtAvhjv2QVRjLQyql1JAXyxrBPGCHMWaXMSYALAMWRe9gjHnNGNPuLL4FxHSqsF7TVOrQEkopFdNEUAjsj1oud9b15zpgeV8bROR6ESkTkbLa2tr3HVCvRKCUUmpodBaLyGeAUuD7fW03xiw1xpQaY0rz899/525HdB+BUkopILY3lFUAxVHLRc66bkTkfOCbwHxjTGcM46EjEDVxvVJKKSC2NYJVwFQRmSgiScBi4JnoHURkLvAr4DJjTE0MYwHAH4rqLFZKKQXEMBEYY0LAjcALwGbgCWPMRhH5tohc5uz2fSAdeFJE1orIM/283XHRVSPQPgKllDospmMNGWOeB57vse7uqOfnx/L4Pfm1j0AppXpxVRuJXjWklFK9uSoR6FVDSinVm6sSweE7izURKKVUF1clgq4aQXKCqz62UkodkatKRH8wjC/Rg8cj8Q5FKaWGDBcmAm0WUkqpaK5KBB2BsHYUK6VUD+5KBEFNBEop1ZOrEoE/GCFZE4FSSnXjskQQJkXHGVJKqW5cVSr6g2EdeVQppXpwVSLoCIbxJWgiUEqpaO5LBFojUEqpblyVCDqDEa0RKKVUD65KBB3BMClJrvrISil1VK4qFfWGMqWU6s01icAYgz+kQ0wopVRPrkkEnaEIxugQ1Eop1ZN7EoEzF4E2DSmlVHeuSQQdOk2lUkr1yXWJQK8aUkqp7lxTKh6auF7vI1BKqW5ckwgONQ3pncVKKdWNaxKBP+A0DWkfgVJKdeOeRBDSzmKllOqLaxJBR0AvH1VKqb7ENBGIyIUislVEdojIHX1sP0dEVotISESujGUsXZ3FmgiUUqq7mCUCEfECDwIXATOAJSIyo8du+4BrgcdiFUeXw/cRuKYSpJRSA5IQw/eeB+wwxuwCEJFlwCJgU9cOxpg9zrZIDOMAoi4f1auGlFKqm1j+PC4E9kctlzvrjpmIXC8iZSJSVltb+76CGZ+TykUnjdGmIaWU6iGWNYLjxhizFFgKUFpaat7Pe1wwcwwXzBxzXONSSqmRIJY1ggqgOGq5yFmnlFJqCIllIlgFTBWRiSKSBCwGnonh8ZRSSr0PMUsExpgQcCPwArAZeMIYs1FEvi0ilwGIyGkiUg5cBfxKRDbGKh6llFJ9i2kfgTHmeeD5Huvujnq+CttkpJRSKk70onqllHI5TQRKKeVymgiUUsrlNBEopZTLiTHv6/6suBGRWmDv+3x5HlB3HMMZCfSc9KbnpDc9J70Nt3MywRiT39eGYZcIPggRKTPGlMY7jqFEz0lvek5603PS20g6J9o0pJRSLqeJQCmlXM5tiWBpvAMYgvSc9KbnpDc9J72NmHPiqj4CpZRSvbmtRqCUUqoHTQRKKeVyrkkEInKhiGwVkR0icke844kXEdkjIutFZK2IlDnrckTkJRHZ7vwdFe84Y0lEfisiNSKyIWpdn+dArJ8435t1InJK/CKPjX7Oxz0iUuF8T9aKyMVR277hnI+tIvKR+EQdWyJSLCKvicgmEdkoIjc760fk98QViUBEvMCDwEXADGCJiMyIb1RxtdAYMyfqGug7gFeMMVOBV5zlkexh4MIe6/o7BxcBU53H9cAvBinGwfQwvc8HwI+c78kcZyRhnP83i4GZzmt+7vz/GmlCwNeMMTOAM4CvOJ99RH5PXJEIgHnADmPMLmNMAFgGLIpzTEPJIuD3zvPfA5fHL5TYM8a8DjT0WN3fOVgEPGKst4BsERk7KIEOkn7OR38WAcuMMZ3GmN3ADuz/rxHFGFNpjFntPG/BzqlSyAj9nrglERQC+6OWy511bmSAF0XkXRG53lk32hhT6TyvAkbHJ7S46u8cuPm7c6PTzPHbqOZC150PESkB5gJvM0K/J25JBOqws40xp2Crsl8RkXOiNxp7PbGrrynWcwDYpo3JwBygEvhBXKOJExFJB/4C3GKMaY7eNpK+J25JBBVAcdRykbPOdYwxFc7fGuApbLW+uqsa6/ytiV+EcdPfOXDld8cYU22MCRtjIsCvOdz845rzISKJ2CTwR2PMX53VI/J74pZEsAqYKiITRSQJ29n1TJxjGnQikiYiGV3PgQuADdhzcY2z2zXA3+ITYVz1dw6eAa52rgo5A2iKahoYsXq0b38M+z0Bez4Wi0iyiEzEdo6+M9jxxZqICPAbYLMx5odRm0bm98QY44oHcDGwDdgJfDPe8cTpHEwC3nMeG7vOA5CLvQJiO/AykBPvWGN8Hh7HNncEsW251/V3DgDBXnG2E1gPlMY7/kE6H486n3cdtpAbG7X/N53zsRW4KN7xx+icnI1t9lkHrHUeF4/U74kOMaGUUi7nlqYhpZRS/dBEoJRSLqeJQCmlXE4TgVJKuZwmAqWUcjlNBEr1ICLhqFE31x7P0WpFpCR6lE+lhoKEeAeg1BDUYYyZE+8glBosWiNQaoCcuRzuc+ZzeEdEpjjrS0TkVWeAtldEZLyzfrSIPCUi7zmPDzlv5RWRXzvj3L8oIilx+1BKoYlAqb6k9Gga+mTUtiZjzCzgZ8ADzrqfAr83xpwM/BH4ibP+J8A/jTGzgVOwd3ODHZbhQWPMTKARuCKmn0apo9A7i5XqQURajTHpfazfA5xrjNnlDEhWZYzJFZE67BAMQWd9pTEmT0RqgSJjTGfUe5QALxk7sQki8l9AojHmO4Pw0ZTqk9YIlDo2pp/nx6Iz6nkY7atTcaaJQKlj88movyud5//GjmgL8GngDef5K8ANYKdLFZGswQpSqWOhv0SU6i1FRNZGLf/DGNN1CekoEVmH/VW/xFl3E/A7EflPoBb4nLP+ZmCpiFyH/eV/A3aUT6WGFO0jUGqAnD6CUmNMXbxjUep40qYhpZRyOa0RKKWUy2mNQCmlXE4TgVJKuZwmAqWUcjlNBEop5XKaCJRSyuX+P764G7PJOrkxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_acc(history)\n",
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36f42960",
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1220/831864409.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx1_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx2_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Test loss:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Test accuracy:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1464\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1465\u001b[0m         \u001b[1;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1466\u001b[1;33m         data_handler = data_adapter.get_data_handler(\n\u001b[0m\u001b[0;32m   1467\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1468\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1381\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"model\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_cluster_coordinator\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1382\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1383\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[0;32m   1136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1138\u001b[1;33m     self._adapter = adapter_cls(\n\u001b[0m\u001b[0;32m   1139\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1140\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    228\u001b[0m                **kwargs):\n\u001b[0;32m    229\u001b[0m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensorLikeDataAdapter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m     \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m     sample_weight_modes = broadcast_sample_weight_modes(\n\u001b[0;32m    232\u001b[0m         sample_weights, sample_weight_modes)\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_process_tensorlike\u001b[1;34m(inputs)\u001b[0m\n\u001b[0;32m   1029\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1030\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1031\u001b[1;33m   \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_convert_numpy_and_scipy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1032\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist_to_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1033\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 869\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 869\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_convert_numpy_and_scipy\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1024\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloating\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1025\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1026\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1027\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0m_is_scipy_sparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_scipy_sparse_to_sparse_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[1;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[0;32m   1428\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtensor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgiven\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1429\u001b[0m   \"\"\"\n\u001b[1;32m-> 1430\u001b[1;33m   return convert_to_tensor_v2(\n\u001b[0m\u001b[0;32m   1431\u001b[0m       value, dtype=dtype, dtype_hint=dtype_hint, name=name)\n\u001b[0;32m   1432\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[1;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[0;32m   1434\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype_hint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1435\u001b[0m   \u001b[1;34m\"\"\"Converts the given `value` to a `Tensor`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1436\u001b[1;33m   return convert_to_tensor(\n\u001b[0m\u001b[0;32m   1437\u001b[0m       \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1438\u001b[0m       \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1565\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1566\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1567\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1568\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m   \u001b[1;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[1;31m# Unused.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    269\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m   \"\"\"\n\u001b[1;32m--> 271\u001b[1;33m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[0;32m    272\u001b[0m                         allow_broadcast=True)\n\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    281\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tf.constant\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m   \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m   \u001b[1;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 308\u001b[1;33m   \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    309\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    104\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "score = model.evaluate([x1_test,x2_test], y_test, verbose = 0) \n",
    "\n",
    "print('Test loss:', score[0]) \n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d855e6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Para pasar la segmentacion a imagen\n",
    "y_pred = model.predict([x1_test,x2_test])\n",
    "y_classes = np.asarray([np.argmax(y, axis=-1) for y in y_pred])\n",
    "label = np.asarray([np.argmax(y, axis=-1) for y in y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864a0e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "number = 3\n",
    "\n",
    "for i in range (number):\n",
    "    fig = plt.figure(\"Labeled Dataset Sample\", figsize=(32, 10))\n",
    "    ax = fig.add_subplot(1, 4, 1)\n",
    "    plot_color(ax, x1_test[i])\n",
    "    \n",
    "    ax = fig.add_subplot(1, 4, 2)\n",
    "    plot_depth(ax, x2_test[i])\n",
    "\n",
    "    ax = fig.add_subplot(1, 4, 3)\n",
    "    plot_label(ax, label[i])\n",
    "\n",
    "    ax = fig.add_subplot(1, 4, 4)\n",
    "    plot_label(ax, y_classes[i])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef540bfe",
   "metadata": {},
   "source": [
    "# Fine tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50de00f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# release all layers for training\n",
    "# set all layers trainable and recompile model\n",
    "for layer in model.layers:\n",
    "    layer.trainable=True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb512b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# continue training\n",
    "history = model.fit(train, epochs=100, verbose=1, validation_data=validation, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9574a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate([x1_test,x2_test], y_test, verbose = 0) \n",
    "\n",
    "print('Test loss:', score[0]) \n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1207818f02c8e106e76b126192fd4af7c5708815ebe301344494fac4b3fd23ae"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
