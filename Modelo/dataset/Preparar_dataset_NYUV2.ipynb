{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7530ab9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "894\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "labels = pd.read_csv('label_names.csv',header=None)\n",
    "label_names = {}\n",
    "for i in labels[0]:\n",
    "    label_names[i.split(';')[0]] = i.split(';')[1].split(\"'\")[1]\n",
    "num_classes = len(label_names)\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d16ad20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numero de clases: 32\n",
      "labels:\n",
      "['book', 'bottle', 'cabinet', 'ceiling', 'chair', 'cone', 'counter', 'dishwasher', 'faucet', 'fire\\xa0extinguisher', 'floor', 'garbage\\xa0bin', 'microwave', 'paper\\xa0towel\\xa0dispenser', 'paper', 'pot', 'refridgerator', 'stove\\xa0burner', 'table', 'unknown', 'wall', 'bowl', 'magnet', 'sink', 'air\\xa0vent', 'box', 'door\\xa0knob', 'door', 'scissor', 'tape\\xa0dispenser', 'telephone\\xa0cord', 'else']\n"
     ]
    }
   ],
   "source": [
    "# Usando los 64 primeros label si no se le pone etiqueta else\n",
    "label_use = []\n",
    "for i in range(1,32):\n",
    "    label_use.append(label_names[str(i)])\n",
    "label_use.append('else')\n",
    "num_classes = len(label_use)\n",
    "print('numero de clases: ' + str(num_classes))\n",
    "print('labels:')\n",
    "print(label_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b952eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from nyuv2 import *\n",
    "from toolbox_nyu_depth_v2 import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import cv2\n",
    "\n",
    "DATASET_DIR = Path('dataset_nyuv2')\n",
    "labeled = LabeledDataset(DATASET_DIR / 'nyu_depth_v2_labeled.mat')\n",
    "# save_dir = 'segmented'\n",
    "# color_dir = save_dir + '/color/'\n",
    "# depth_dir = save_dir + '/depth/'\n",
    "# label_dir = save_dir + '/label/'\n",
    "\n",
    "x1 = []\n",
    "x2 = []\n",
    "y = []\n",
    "x_rgb = []\n",
    "x_dep = []\n",
    "y_res = []\n",
    "\n",
    "for i in range(1449): # valor maximo 1449\n",
    "    color, depth, label = labeled[i]\n",
    "\n",
    "    # x1.append(cv2.resize(img_to_array(color)/255, dsize=(128,96), interpolation=cv2.INTER_CUBIC))\n",
    "    # x2.append(np.resize(cv2.resize(img_to_array(depth)/255, dsize=(128,96), interpolation=cv2.INTER_CUBIC),(96,128,1)))\n",
    "    # y.append(np.resize(cv2.resize(img_to_array(label), dsize=(128,96), interpolation=cv2.INTER_CUBIC),(96,128,1)))\n",
    "    x_rgb.append(img_to_array(color)/255) \n",
    "    x_dep.append(img_to_array(depth)/255)\n",
    "    y_res.append(img_to_array(label))\n",
    "\n",
    "x_rgb = np.array(x_rgb)\n",
    "x_dep = np.array(x_dep)\n",
    "y_res = np.array(y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4b23734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximize_image(imagen, num):\n",
    "    img_aux = np.zeros([imagen.shape[0],imagen.shape[1]],dtype=np.uint8)\n",
    "    for i in range(imagen.shape[0]):\n",
    "        for j in range(imagen.shape[1]):\n",
    "            if imagen[i][j] >= num:\n",
    "                img_aux[i][j] = num\n",
    "                    \n",
    "#     plt.imshow(img_aux)\n",
    "#     plt.show()\n",
    "    return np.array(img_aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23bbb95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binaryze_image(imagen, num):\n",
    "    img_aux = np.zeros([imagen.shape[0],imagen.shape[1]],dtype=np.uint8)\n",
    "    for i in range(imagen.shape[0]):\n",
    "        for j in range(imagen.shape[1]):\n",
    "            if num < 65:\n",
    "                if imagen[i][j] == num:\n",
    "                    img_aux[i][j] = 1\n",
    "            else:\n",
    "                if imagen[i][j] >= num:\n",
    "                    img_aux[i][j] = 1\n",
    "                    \n",
    "#     plt.imshow(img_aux)\n",
    "#     plt.show()\n",
    "    return np.array(img_aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f10029ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "# Preparar el resultado en un array\n",
    "\n",
    "y_res_1 = []\n",
    "\n",
    "for im in range(len(y_res)):\n",
    "    y_res_1.append(list())\n",
    "    y_res_1[im].append(np.array(maximize_image(y_res[im],32)))\n",
    "y_res_1 = np.array(y_res_1)\n",
    "print(y_res_1[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6215e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1449, 1, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "print(y_res_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bdaf57d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 33 is out of bounds for axis 1 with size 32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-cb3df42b128f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mim\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_res\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0my_res_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0my_res_2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_res\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'int32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0my_res_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_res_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\utils\\np_utils.py\u001b[0m in \u001b[0;36mto_categorical\u001b[1;34m(y, num_classes, dtype)\u001b[0m\n\u001b[0;32m     73\u001b[0m   \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m   \u001b[0mcategorical\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m   \u001b[0mcategorical\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m   \u001b[0moutput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m   \u001b[0mcategorical\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcategorical\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 33 is out of bounds for axis 1 with size 32"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Preparar el resultado en diferentes arrays\n",
    "y_res_2 = []\n",
    "\n",
    "for im in range(len(y_res)):\n",
    "    y_res_2.append(list())\n",
    "    y_res_2[im].append(np.array(tf.keras.utils.to_categorical(np.array(y_res[im]), num_classes=32, dtype='int32')))\n",
    "\n",
    "y_res_2 = np.array(y_res_2)\n",
    "print(y_res_2[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e976e648",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('dataset_nyuv2/y_prepared_32', y_res_2, allow_pickle=False, fix_imports=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6ef2409",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('dataset_nyuv2/y_32', y_res_1, allow_pickle=False, fix_imports=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0c9d7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('dataset_nyuv2/x1', x_rgb, allow_pickle=False, fix_imports=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61fbc596",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('dataset_nyuv2/x2', x_dep, allow_pickle=False, fix_imports=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae32ddf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data_dir = np.load('dataset_nyuv2/y_32')\n",
    "\n",
    "tf.keras.utils.to_categorical(\n",
    "    data_dir, num_classes=32, dtype='int'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1207818f02c8e106e76b126192fd4af7c5708815ebe301344494fac4b3fd23ae"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
